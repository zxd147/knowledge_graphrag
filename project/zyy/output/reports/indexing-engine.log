12:39:54,869 graphrag.index.cli INFO Logging enabled at output/reports/indexing-engine.log
12:39:54,871 graphrag.index.cli INFO Starting pipeline run for: 20241125-123954, dryrun=False
12:39:54,871 graphrag.index.cli INFO Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "openai_chat",
        "model": "Qwen2.5-7B-Instruct",
        "max_tokens": 5000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 3000.0,
        "api_base": "http://192.168.0.244:8016/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 2.0,
        "num_threads": 50
    },
    "async_mode": "asyncio",
    "root_dir": ".",
    "reporting": {
        "type": "file",
        "base_dir": "output/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "model": "m3e-large",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://192.168.0.244:8016/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 2.0,
            "num_threads": 50
        },
        "async_mode": "asyncio",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 500,
        "overlap": 200,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "Qwen2.5-7B-Instruct",
            "max_tokens": 5000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 3000.0,
            "api_base": "http://192.168.0.244:8016/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 2.0,
            "num_threads": 50
        },
        "async_mode": "asyncio",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "\u653f\u7b56\u6cd5\u89c4",
            "\u5206\u7c7b\u65b9\u6cd5",
            "\u5904\u7406\u6280\u672f",
            "\u56de\u6536\u6750\u6599",
            "\u8bbe\u65bd\u8bbe\u5907",
            "\u5206\u7c7b\u6807\u51c6",
            "\u7ba1\u7406\u7ec4\u7ec7",
            "\u7ecf\u6d4e\u6a21\u5f0f",
            "\u6559\u80b2\u57f9\u8bad",
            "\u8ba4\u8bc1\u4f53\u7cfb",
            "\u751f\u6d3b\u65b9\u5f0f",
            "\u80fd\u6e90\u7c7b\u578b",
            "\u73af\u5883\u56e0\u7d20",
            "\u8d44\u6e90\u7ba1\u7406",
            "\u73af\u4fdd\u4ea7\u54c1",
            "\u4f01\u4e1a\u673a\u6784",
            "\u91d1\u878d\u6a21\u5f0f",
            "\u79d1\u5b66\u7814\u7a76",
            "\u6d3b\u52a8\u5021\u5bfc",
            "\u610f\u8bc6\u63d0\u5347",
            "\u73af\u5883\u5f71\u54cd",
            "\u6c61\u67d3\u6cbb\u7406",
            "\u8bc4\u4f30\u4f53\u7cfb",
            "\u5faa\u73af\u5229\u7528",
            "\u8d44\u6e90\u5316\u6280\u672f",
            "\u53ef\u6301\u7eed\u53d1\u5c55",
            "\u751f\u6001\u4fdd\u62a4",
            "\u78b3\u7ba1\u7406",
            "\u6c14\u5019\u884c\u52a8",
            "\u521b\u65b0\u5e94\u7528",
            "\u884c\u4e1a\u5b9e\u8df5",
            "\u57ce\u5e02\u89c4\u5212",
            "\u4ea4\u901a\u6a21\u5f0f",
            "\u6d88\u8d39\u6a21\u5f0f",
            "\u73af\u5883\u76d1\u6d4b",
            "\u5e9f\u5f03\u7269\u5904\u7406",
            "\u6c61\u67d3\u6e90\u63a7\u5236",
            "\u751f\u6001\u4fee\u590d",
            "\u7eff\u8272\u5efa\u7b51",
            "\u73af\u4fdd\u6280\u672f",
            "\u751f\u7269\u964d\u89e3",
            "\u80fd\u6e90\u5229\u7528"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "Qwen2.5-7B-Instruct",
            "max_tokens": 5000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 3000.0,
            "api_base": "http://192.168.0.244:8016/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 2.0,
            "num_threads": 50
        },
        "async_mode": "asyncio",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "Qwen2.5-7B-Instruct",
            "max_tokens": 5000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 3000.0,
            "api_base": "http://192.168.0.244:8016/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 3.0,
            "num_threads": 3
        },
        "async_mode": "asyncio",
        "prompt": "prompts/community_report.txt",
        "max_length": 5000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "Qwen2.5-7B-Instruct",
            "max_tokens": 5000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 3000.0,
            "api_base": "http://192.168.0.244:8016/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 2.0,
            "num_threads": 50
        },
        "async_mode": "asyncio",
        "enabled": true,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
12:39:54,871 graphrag.index.create_pipeline_config INFO skipping workflows 
12:39:54,872 graphrag.index.run INFO Running pipeline
12:39:54,872 graphrag.index.storage.file_pipeline_storage INFO Creating file storage at output/artifacts
12:39:54,872 graphrag.index.input.load_input INFO loading input from root_dir=input
12:39:54,872 graphrag.index.input.load_input INFO using file storage for input
12:39:54,872 graphrag.index.storage.file_pipeline_storage INFO search input for files matching .*\.txt$
12:39:54,872 graphrag.index.input.text INFO found text files from input, found [('Guangzhou Zhongyiyong Intelligent Technology Co., Inc._pdf.txt', {}), ('Guangzhou Zhongyiyong Intelligent Technology Co., Inc.-1.txt', {}), ('Guangzhou Zhongyiyong Intelligent Technology Co., Inc.-2.txt', {}), ('Guangzhou Zhongyiyong Intelligent Technology Co., Inc..txt', {}), ('Guangzhou Zhongyiyong Intelligent Technology Co., Inc.-0904.txt', {})]
12:39:54,874 graphrag.index.input.text INFO Found 5 files, loading 5
12:39:54,875 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_final_covariates', 'create_summarized_entities', 'join_text_units_to_covariate_ids', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents']
12:39:54,875 graphrag.index.run INFO Final # of rows loaded: 5
12:39:54,950 graphrag.index.run INFO Running workflow: create_base_text_units...
12:39:54,950 graphrag.index.run INFO dependencies for create_base_text_units: []
12:39:54,952 datashaper.workflow.workflow INFO executing verb orderby
12:39:54,954 datashaper.workflow.workflow INFO executing verb zip
12:39:54,956 datashaper.workflow.workflow INFO executing verb aggregate_override
12:39:54,958 datashaper.workflow.workflow INFO executing verb chunk
12:39:55,49 datashaper.workflow.workflow INFO executing verb select
12:39:55,51 datashaper.workflow.workflow INFO executing verb unroll
12:39:55,54 datashaper.workflow.workflow INFO executing verb rename
12:39:55,56 datashaper.workflow.workflow INFO executing verb genid
12:39:55,59 datashaper.workflow.workflow INFO executing verb unzip
12:39:55,62 datashaper.workflow.workflow INFO executing verb copy
12:39:55,64 datashaper.workflow.workflow INFO executing verb filter
12:39:55,66 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_text_units.parquet
12:39:55,158 graphrag.index.run INFO Running workflow: create_base_extracted_entities...
12:39:55,159 graphrag.index.run INFO dependencies for create_base_extracted_entities: ['create_base_text_units']
12:39:55,159 graphrag.index.run INFO read table from storage: create_base_text_units.parquet
12:39:55,166 datashaper.workflow.workflow INFO executing verb entity_extract
12:39:55,168 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=http://192.168.0.244:8016/v1
12:39:55,180 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for Qwen2.5-7B-Instruct: TPM=0, RPM=0
12:39:55,180 graphrag.index.llm.load_llm INFO create concurrency limiter for Qwen2.5-7B-Instruct: 25
12:40:18,350 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:40:18,353 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 23.141059308312833. input_tokens=2655, output_tokens=969
12:40:28,378 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:40:28,379 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 33.183628199156374. input_tokens=2654, output_tokens=1619
12:40:30,336 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:40:30,337 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 35.11009014537558. input_tokens=2340, output_tokens=1620
12:40:32,67 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:40:32,68 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 36.84810804622248. input_tokens=2351, output_tokens=1796
12:40:34,40 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:40:34,41 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 38.82708483887836. input_tokens=2654, output_tokens=1835
12:40:35,47 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:40:35,48 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 39.84863267140463. input_tokens=2654, output_tokens=1887
12:40:36,401 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:40:36,402 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 41.1920583602041. input_tokens=2654, output_tokens=1914
12:40:37,869 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:40:37,870 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 42.681460646912456. input_tokens=2655, output_tokens=1977
12:40:39,510 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:40:39,511 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 44.30537639185786. input_tokens=2656, output_tokens=2066
12:40:40,833 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:40:40,834 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 45.63061432307586. input_tokens=2655, output_tokens=2152
12:40:41,461 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:40:41,463 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 46.260919739026576. input_tokens=2655, output_tokens=2133
12:40:41,939 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:40:41,940 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 46.710801356006414. input_tokens=2655, output_tokens=2089
12:40:45,430 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:40:45,431 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 50.233887093141675. input_tokens=2655, output_tokens=2384
12:40:46,549 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:40:46,550 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 51.31617575511336. input_tokens=2655, output_tokens=2360
12:40:48,589 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:40:48,591 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 53.3825472346507. input_tokens=2655, output_tokens=2423
12:40:51,558 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:40:51,560 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 56.32806064700708. input_tokens=2655, output_tokens=2523
12:40:52,772 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:40:52,774 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 57.58034050324932. input_tokens=2654, output_tokens=2497
12:40:53,432 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:40:53,433 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 58.19566236110404. input_tokens=2656, output_tokens=2450
12:40:54,168 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:40:54,169 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 58.94782667001709. input_tokens=2654, output_tokens=2531
12:40:56,511 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:40:56,513 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 24.444246829953045. input_tokens=2550, output_tokens=1009
12:40:58,56 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:40:58,57 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 24.01547815417871. input_tokens=2251, output_tokens=1082
12:40:59,429 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:40:59,430 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 41.07635974697769. input_tokens=2655, output_tokens=2081
12:41:02,101 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:41:02,103 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 66.87737666396424. input_tokens=2640, output_tokens=2893
12:41:11,626 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:41:11,628 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 26.195446732919663. input_tokens=2654, output_tokens=1157
12:41:12,56 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:41:12,56 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 20.496103416662663. input_tokens=2422, output_tokens=997
12:41:13,479 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:41:13,481 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 78.26472018286586. input_tokens=2655, output_tokens=3770
12:41:16,761 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:41:16,762 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 34.82121686823666. input_tokens=2654, output_tokens=1544
12:41:23,862 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:41:23,863 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 47.46023526368663. input_tokens=2654, output_tokens=2276
12:41:27,656 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:41:27,657 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 41.10684934584424. input_tokens=2655, output_tokens=1956
12:41:29,865 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:41:29,866 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 13.103765797801316. input_tokens=55, output_tokens=560
12:41:30,514 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:41:30,516 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 55.466703730169684. input_tokens=2655, output_tokens=2539
12:41:33,156 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:41:33,157 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 62.81907347217202. input_tokens=2655, output_tokens=2801
12:41:34,73 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:41:34,74 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 98.83422918384895. input_tokens=2654, output_tokens=4264
12:41:34,563 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:41:34,564 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 36.50645452691242. input_tokens=2655, output_tokens=1611
12:41:37,88 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:41:37,89 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 23.6077113263309. input_tokens=55, output_tokens=1021
12:41:37,866 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:41:37,867 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 45.0924505321309. input_tokens=2655, output_tokens=1999
12:41:38,824 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:41:38,825 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 44.655016446020454. input_tokens=2654, output_tokens=1994
12:41:40,701 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:41:40,702 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 59.23876842483878. input_tokens=2654, output_tokens=2538
12:41:41,354 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:41:41,355 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 63.48399354191497. input_tokens=2655, output_tokens=2956
12:41:49,174 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:41:49,175 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 55.74136655917391. input_tokens=2654, output_tokens=2528
12:41:54,128 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:41:54,129 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 20.054149974137545. input_tokens=55, output_tokens=824
12:41:54,773 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:41:54,773 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 17.68417683476582. input_tokens=55, output_tokens=694
12:41:56,5 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:41:56,6 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 53.901695122011006. input_tokens=2654, output_tokens=2411
12:41:58,594 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:41:58,595 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 25.4370758398436. input_tokens=55, output_tokens=968
12:42:03,511 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:42:03,513 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 84.0007565212436. input_tokens=2655, output_tokens=3702
12:42:03,953 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:42:03,954 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 40.08972216909751. input_tokens=55, output_tokens=1620
12:42:05,285 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:42:05,286 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 27.41846093069762. input_tokens=55, output_tokens=1148
12:42:08,923 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:42:08,925 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 80.33328226208687. input_tokens=2656, output_tokens=3761
12:42:10,417 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:42:10,418 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 42.75961889978498. input_tokens=55, output_tokens=1796
12:42:13,656 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:42:13,656 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 18.88252154085785. input_tokens=55, output_tokens=718
12:42:16,121 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:42:16,123 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 107.74301604367793. input_tokens=2655, output_tokens=4615
12:42:19,673 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:42:19,674 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 49.80679312767461. input_tokens=55, output_tokens=2021
12:42:22,381 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:42:22,381 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 23.7860204577446. input_tokens=55, output_tokens=1064
12:42:24,605 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:42:24,606 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 50.0413705999963. input_tokens=55, output_tokens=2066
12:42:27,216 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:42:27,218 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 90.70427480712533. input_tokens=2654, output_tokens=3660
12:42:28,270 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:42:28,271 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 57.7546675899066. input_tokens=55, output_tokens=2392
12:42:28,986 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:42:28,987 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 20.06181497592479. input_tokens=55, output_tokens=697
12:42:30,356 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:42:30,357 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 51.531132054980844. input_tokens=55, output_tokens=2071
12:42:32,273 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:42:32,274 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 50.91862454125658. input_tokens=55, output_tokens=1930
12:42:34,299 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:42:34,300 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 30.346225095912814. input_tokens=55, output_tokens=1184
12:42:37,543 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:42:37,544 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 85.48677991796285. input_tokens=2655, output_tokens=3415
12:42:39,726 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:42:39,727 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 36.2138650091365. input_tokens=55, output_tokens=1269
12:42:41,776 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:42:41,777 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 28.11995287798345. input_tokens=55, output_tokens=1131
12:42:49,647 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:42:49,648 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 60.471722153015435. input_tokens=55, output_tokens=2423
12:42:54,360 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:42:54,360 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:42:54,361 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:42:54,363 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 179.14393153693527. input_tokens=2652, output_tokens=8422
12:42:54,364 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 179.14009516127408. input_tokens=2654, output_tokens=7603
12:42:54,366 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 179.1295921942219. input_tokens=2655, output_tokens=7835
12:42:58,286 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:42:58,287 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 64.15767115075141. input_tokens=55, output_tokens=2495
12:43:00,2 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:43:00,3 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 54.71684872638434. input_tokens=55, output_tokens=2284
12:43:04,978 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:43:04,980 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 54.5610875505954. input_tokens=55, output_tokens=2020
12:43:07,136 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:43:07,137 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 86.43392528314143. input_tokens=55, output_tokens=3548
12:43:11,196 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:43:11,197 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 43.97862525517121. input_tokens=2654, output_tokens=1581
12:43:12,778 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:43:12,779 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 48.17248057387769. input_tokens=55, output_tokens=1905
12:43:15,320 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:43:15,321 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 17.033273429144174. input_tokens=55, output_tokens=654
12:43:16,605 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:43:16,606 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 47.618460540659726. input_tokens=55, output_tokens=1925
12:43:19,412 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:43:19,413 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 57.03120052488521. input_tokens=55, output_tokens=2245
12:43:20,832 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:43:20,833 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 61.15910559287295. input_tokens=55, output_tokens=2142
12:43:27,507 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:43:27,508 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 14.728093816898763. input_tokens=55, output_tokens=480
12:43:30,666 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:43:30,667 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 53.122710494324565. input_tokens=55, output_tokens=2151
12:43:34,599 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:43:34,600 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 66.32798138074577. input_tokens=55, output_tokens=2539
12:43:46,276 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:43:46,278 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 185.44198497012258. input_tokens=2655, output_tokens=7476
12:43:47,839 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:43:47,840 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 58.19130068970844. input_tokens=55, output_tokens=2384
12:43:47,940 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:43:47,941 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 66.16361038107425. input_tokens=55, output_tokens=2538
12:43:52,346 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:43:52,347 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 72.61897314572707. input_tokens=55, output_tokens=2736
12:43:52,807 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:43:52,808 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 47.82825699588284. input_tokens=55, output_tokens=1855
12:43:54,528 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:43:54,530 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 27.02133052702993. input_tokens=55, output_tokens=1131
12:43:54,752 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:43:54,754 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 98.62966815987602. input_tokens=55, output_tokens=4102
12:43:57,693 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:43:57,694 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 50.556330350693315. input_tokens=55, output_tokens=2158
12:43:59,879 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:43:59,881 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 65.5143637759611. input_tokens=55, output_tokens=2707
12:44:00,631 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:44:00,632 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 45.31004292797297. input_tokens=55, output_tokens=1813
12:44:00,693 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:44:00,694 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 66.32459418708459. input_tokens=2654, output_tokens=2656
12:44:01,609 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:44:01,610 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 61.60644194018096. input_tokens=2447, output_tokens=2415
12:44:04,760 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:44:04,762 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 90.46035873703659. input_tokens=2655, output_tokens=3619
12:44:05,881 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:44:05,882 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 49.27500056428835. input_tokens=55, output_tokens=2085
12:44:06,154 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:44:06,156 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 186.72507630381733. input_tokens=2655, output_tokens=7561
12:44:07,904 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:44:07,906 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 73.53410194069147. input_tokens=2654, output_tokens=2834
12:44:08,550 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:44:08,551 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 47.71739797387272. input_tokens=55, output_tokens=2001
12:44:10,187 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:44:10,188 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 50.774042304139584. input_tokens=55, output_tokens=2288
12:44:19,64 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:44:19,65 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 106.78980077477172. input_tokens=55, output_tokens=4379
12:44:19,469 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:44:19,471 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 187.84205306088552. input_tokens=2655, output_tokens=7766
12:44:19,506 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:44:19,507 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 109.14937216695398. input_tokens=55, output_tokens=4264
12:44:30,48 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:44:30,49 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 43.7701621260494. input_tokens=55, output_tokens=1942
12:44:38,716 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:44:38,717 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 30.810862542130053. input_tokens=55, output_tokens=1644
12:44:43,105 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:44:43,108 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 167.1000667316839. input_tokens=55, output_tokens=7666
12:44:45,40 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:44:45,41 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 38.88377250172198. input_tokens=55, output_tokens=1892
12:44:49,643 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:44:49,644 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 48.03249612823129. input_tokens=55, output_tokens=2345
12:44:54,317 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:44:54,319 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 103.12066878005862. input_tokens=55, output_tokens=4731
12:44:56,269 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:44:56,271 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 36.79801595630124. input_tokens=55, output_tokens=2084
12:45:22,303 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:45:22,304 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 81.60889176512137. input_tokens=55, output_tokens=4452
12:45:48,174 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:45:48,176 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 103.41214789682999. input_tokens=55, output_tokens=6305
12:45:48,185 datashaper.workflow.workflow INFO executing verb merge_graphs
12:45:48,245 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_extracted_entities.parquet
12:45:48,342 graphrag.index.run INFO Running workflow: create_final_covariates...
12:45:48,342 graphrag.index.run INFO dependencies for create_final_covariates: ['create_base_text_units']
12:45:48,343 graphrag.index.run INFO read table from storage: create_base_text_units.parquet
12:45:48,350 datashaper.workflow.workflow INFO executing verb extract_covariates
12:45:53,266 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:45:53,267 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.888815402984619. input_tokens=1959, output_tokens=5
12:45:54,319 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:45:54,320 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.916321144904941. input_tokens=1960, output_tokens=59
12:45:54,640 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:45:54,640 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.256226726807654. input_tokens=1960, output_tokens=62
12:45:54,641 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:45:54,643 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.233142948243767. input_tokens=1959, output_tokens=62
12:45:54,643 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:45:54,646 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.270020614843816. input_tokens=1960, output_tokens=62
12:45:54,672 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:45:54,673 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.284511809237301. input_tokens=1656, output_tokens=67
12:45:55,557 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:45:55,558 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 7.190415035933256. input_tokens=1959, output_tokens=69
12:45:55,832 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:45:55,833 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 7.425016360823065. input_tokens=1961, output_tokens=69
12:45:56,293 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:45:56,294 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 7.907669646199793. input_tokens=1957, output_tokens=103
12:45:56,628 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:45:56,628 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 8.254670778289437. input_tokens=1961, output_tokens=96
12:45:56,659 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:45:56,660 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 8.254228935111314. input_tokens=1960, output_tokens=81
12:45:57,120 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:45:57,121 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.8542491486296058. input_tokens=1960, output_tokens=85
12:45:57,406 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:45:57,407 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 9.009619826916605. input_tokens=1645, output_tokens=114
12:45:57,818 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:45:57,818 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 9.4489383562468. input_tokens=1960, output_tokens=131
12:45:58,120 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:45:58,121 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.4773379312828183. input_tokens=1855, output_tokens=57
12:45:58,196 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:45:58,197 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.555636723060161. input_tokens=1960, output_tokens=65
12:45:58,199 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:45:58,199 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.55332060623914. input_tokens=1556, output_tokens=67
12:45:58,740 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:45:58,741 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 10.33971402933821. input_tokens=1960, output_tokens=135
12:45:58,772 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:45:58,773 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 10.373821169137955. input_tokens=1960, output_tokens=142
12:45:59,215 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:45:59,216 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 10.844378986861557. input_tokens=1960, output_tokens=127
12:45:59,504 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:45:59,505 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.6716407872736454. input_tokens=1960, output_tokens=62
12:45:59,836 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:45:59,837 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.2791222291998565. input_tokens=1959, output_tokens=71
12:46:00,140 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:00,141 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.820928219240159. input_tokens=1960, output_tokens=79
12:46:00,445 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:00,445 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.150947782211006. input_tokens=1960, output_tokens=65
12:46:01,333 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:01,334 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.705047030933201. input_tokens=1960, output_tokens=95
12:46:01,637 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:01,637 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 2.1321513960137963. input_tokens=1960, output_tokens=62
12:46:01,664 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:01,664 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 2.4483441947959363. input_tokens=1959, output_tokens=59
12:46:01,696 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:01,697 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.575397511944175. input_tokens=1959, output_tokens=99
12:46:02,416 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:02,417 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.219881188124418. input_tokens=1727, output_tokens=81
12:46:02,469 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:02,469 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.7276785378344357. input_tokens=1959, output_tokens=84
12:46:02,500 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:02,501 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.379326450172812. input_tokens=1961, output_tokens=76
12:46:02,504 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:02,504 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.7310425899922848. input_tokens=1959, output_tokens=92
12:46:03,336 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:03,337 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.5185765153728426. input_tokens=1960, output_tokens=88
12:46:03,424 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:03,425 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.5876581692136824. input_tokens=1960, output_tokens=69
12:46:04,128 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:04,129 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.721731286961585. input_tokens=1959, output_tokens=111
12:46:04,484 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:04,485 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.03930375399068. input_tokens=1960, output_tokens=80
12:46:04,892 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:04,893 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.751350193750113. input_tokens=1959, output_tokens=102
12:46:04,944 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:04,945 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 8.284483288880438. input_tokens=1959, output_tokens=154
12:46:05,408 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:05,409 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.074973908718675. input_tokens=1960, output_tokens=65
12:46:05,666 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:05,667 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 17.30612081894651. input_tokens=1959, output_tokens=331
12:46:07,306 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:07,307 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 18.924965769052505. input_tokens=1960, output_tokens=362
12:46:13,760 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:13,761 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 25.380903302226216. input_tokens=1960, output_tokens=540
12:46:16,431 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:16,432 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 28.036698890849948. input_tokens=1945, output_tokens=808
12:46:16,709 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:16,709 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 28.34407815290615. input_tokens=1960, output_tokens=924
12:46:17,996 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:17,997 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 29.604210678953677. input_tokens=1959, output_tokens=822
12:46:20,879 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:20,880 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 26.206568711902946. input_tokens=1960, output_tokens=859
12:46:22,337 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:22,338 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 33.979545352980494. input_tokens=1960, output_tokens=1023
12:46:22,670 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:22,671 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 20.973973791114986. input_tokens=32, output_tokens=1186
12:46:24,712 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:24,713 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 22.242902592755854. input_tokens=32, output_tokens=1151
12:46:25,682 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:25,683 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 37.29274239204824. input_tokens=1959, output_tokens=1190
12:46:26,926 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:26,928 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 19.620024119969457. input_tokens=32, output_tokens=904
12:46:28,982 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:28,983 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 40.62002087198198. input_tokens=1959, output_tokens=1243
12:46:30,206 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:30,206 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 16.44503490300849. input_tokens=32, output_tokens=738
12:46:31,264 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:31,266 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 26.320334108080715. input_tokens=32, output_tokens=1147
12:46:32,314 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:32,315 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 34.1148434728384. input_tokens=1960, output_tokens=1148
12:46:35,933 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:35,934 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 32.59595568384975. input_tokens=32, output_tokens=1437
12:46:38,0 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:38,1 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 35.58374982792884. input_tokens=32, output_tokens=1550
12:46:38,618 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:38,619 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 33.209536239970475. input_tokens=32, output_tokens=1388
12:46:41,131 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:41,132 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 37.002640502061695. input_tokens=32, output_tokens=1802
12:46:41,554 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:41,554 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 16.841326616238803. input_tokens=32, output_tokens=664
12:46:43,538 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:43,539 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 41.03415975114331. input_tokens=32, output_tokens=1940
12:46:47,191 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:47,192 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 45.553741639945656. input_tokens=32, output_tokens=1844
12:46:47,611 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:47,612 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 31.17953984020278. input_tokens=32, output_tokens=1307
12:46:48,789 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:48,790 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 47.12473292788491. input_tokens=32, output_tokens=1895
12:46:50,135 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:50,136 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 18.86970171611756. input_tokens=32, output_tokens=862
12:46:50,751 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:50,752 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 32.75419822894037. input_tokens=32, output_tokens=1634
12:46:51,39 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:51,40 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 28.700775909237564. input_tokens=32, output_tokens=1329
12:46:53,65 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:53,65 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 2.9288666071370244. input_tokens=32, output_tokens=103
12:46:57,337 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:46:57,339 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 52.4450690750964. input_tokens=32, output_tokens=2738
12:47:04,611 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:47:04,612 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 32.29641577973962. input_tokens=32, output_tokens=1531
12:47:05,329 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:47:05,330 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 35.12286477629095. input_tokens=32, output_tokens=1690
12:47:06,820 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:47:06,821 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 62.33544615888968. input_tokens=32, output_tokens=3009
12:47:07,405 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:47:07,407 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 50.696410715114325. input_tokens=32, output_tokens=2154
12:47:08,431 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:47:08,432 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 42.747882990166545. input_tokens=32, output_tokens=2000
12:47:08,749 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:47:08,750 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 41.82185311196372. input_tokens=32, output_tokens=1649
12:47:09,703 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:47:09,704 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 28.148782358970493. input_tokens=32, output_tokens=1086
12:47:10,600 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:47:10,601 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.194270412903279. input_tokens=1959, output_tokens=104
12:47:12,857 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:47:12,857 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.1534091141074896. input_tokens=1959, output_tokens=147
12:47:15,104 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:47:15,105 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 2.2474045171402395. input_tokens=1959, output_tokens=107
12:47:15,335 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:47:15,337 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 54.455992420203984. input_tokens=32, output_tokens=2361
12:47:17,663 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:47:17,664 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 48.68032768322155. input_tokens=32, output_tokens=1843
12:47:24,803 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:47:24,804 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 43.67148425290361. input_tokens=32, output_tokens=1895
12:47:28,542 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:47:28,543 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 86.04174603521824. input_tokens=32, output_tokens=3655
12:47:29,499 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:47:29,500 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 38.74726962018758. input_tokens=32, output_tokens=1928
12:47:29,673 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:47:29,674 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 14.568084376864135. input_tokens=1752, output_tokens=646
12:47:30,311 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:47:30,312 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 21.879104499239475. input_tokens=1960, output_tokens=938
12:47:35,775 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:47:35,777 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 48.58408798882738. input_tokens=32, output_tokens=2034
12:47:36,713 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:47:36,715 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 74.04232207406312. input_tokens=32, output_tokens=3466
12:47:39,43 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:47:39,44 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 61.04240989871323. input_tokens=32, output_tokens=2540
12:47:40,684 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:47:40,685 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 43.345716981682926. input_tokens=32, output_tokens=2168
12:47:42,544 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:47:42,545 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 59.005165432579815. input_tokens=32, output_tokens=2828
12:47:44,531 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:47:44,532 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 53.49107062490657. input_tokens=32, output_tokens=2216
12:47:46,498 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:47:46,499 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 53.43273206567392. input_tokens=32, output_tokens=2360
12:47:52,31 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:47:52,32 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 22.356969146057963. input_tokens=32, output_tokens=987
12:47:52,58 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:47:52,59 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 34.394408874213696. input_tokens=32, output_tokens=1648
12:47:55,272 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:47:55,273 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 48.451025350019336. input_tokens=32, output_tokens=2066
12:47:55,357 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:47:55,358 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 50.74518574681133. input_tokens=32, output_tokens=2355
12:47:57,418 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:47:57,420 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 32.61488016694784. input_tokens=32, output_tokens=1597
12:47:59,47 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:47:59,49 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 50.29791356623173. input_tokens=32, output_tokens=2260
12:48:04,509 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:48:04,510 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 85.89053937420249. input_tokens=32, output_tokens=3771
12:48:06,470 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:48:06,471 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 36.158696147147566. input_tokens=32, output_tokens=1739
12:48:12,131 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:48:12,132 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 61.52996878186241. input_tokens=32, output_tokens=2682
12:48:15,778 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:48:15,779 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 47.23489314317703. input_tokens=32, output_tokens=2274
12:48:16,952 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:48:16,954 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 133.52750003989786. input_tokens=32, output_tokens=5168
12:48:21,62 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:48:21,70 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 93.4574221437797. input_tokens=32, output_tokens=3648
12:48:34,951 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:48:34,953 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 149.28409428196028. input_tokens=32, output_tokens=7320
12:48:59,221 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:48:59,223 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 143.28787038708106. input_tokens=32, output_tokens=5338
12:49:08,983 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:08,985 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 140.19407720398158. input_tokens=32, output_tokens=8635
12:49:21,507 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:21,509 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 136.1776344710961. input_tokens=32, output_tokens=6767
12:49:27,881 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:27,884 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 132.54556337790564. input_tokens=32, output_tokens=6431
12:49:27,896 datashaper.workflow.workflow INFO executing verb window
12:49:27,900 datashaper.workflow.workflow INFO executing verb genid
12:49:27,903 datashaper.workflow.workflow INFO executing verb convert
12:49:27,907 datashaper.workflow.workflow INFO executing verb rename
12:49:27,911 datashaper.workflow.workflow INFO executing verb select
12:49:27,912 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_covariates.parquet
12:49:28,8 graphrag.index.run INFO Running workflow: create_summarized_entities...
12:49:28,9 graphrag.index.run INFO dependencies for create_summarized_entities: ['create_base_extracted_entities']
12:49:28,9 graphrag.index.run INFO read table from storage: create_base_extracted_entities.parquet
12:49:28,20 datashaper.workflow.workflow INFO executing verb summarize_descriptions
12:49:30,394 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:30,395 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.325668614823371. input_tokens=414, output_tokens=69
12:49:30,545 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:30,546 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.4693375336937606. input_tokens=401, output_tokens=88
12:49:30,546 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:30,548 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.4493889920413494. input_tokens=331, output_tokens=90
12:49:30,768 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:30,769 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.668178880121559. input_tokens=356, output_tokens=79
12:49:30,890 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:30,890 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.8157657529227436. input_tokens=341, output_tokens=81
12:49:31,30 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:31,31 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.96736341714859. input_tokens=392, output_tokens=96
12:49:31,31 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:31,34 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.9665083452127874. input_tokens=333, output_tokens=95
12:49:31,61 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:31,62 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.9783375705592334. input_tokens=397, output_tokens=116
12:49:31,109 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:31,110 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.04983389377594. input_tokens=369, output_tokens=94
12:49:31,377 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:31,378 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.2967017577029765. input_tokens=425, output_tokens=93
12:49:31,577 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:31,577 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.471549698151648. input_tokens=506, output_tokens=115
12:49:31,739 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:31,739 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.637107932008803. input_tokens=339, output_tokens=104
12:49:31,867 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:31,868 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.789784855209291. input_tokens=481, output_tokens=132
12:49:31,897 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:31,898 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.832037129905075. input_tokens=400, output_tokens=139
12:49:32,188 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:32,189 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.108739315066487. input_tokens=443, output_tokens=137
12:49:32,336 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:32,337 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.25150998076424. input_tokens=624, output_tokens=136
12:49:32,365 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:32,366 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.2778376010246575. input_tokens=421, output_tokens=156
12:49:32,540 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:32,540 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.467674298211932. input_tokens=602, output_tokens=171
12:49:32,569 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:32,570 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.507883522193879. input_tokens=477, output_tokens=180
12:49:32,765 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:32,766 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.734356036875397. input_tokens=286, output_tokens=84
12:49:32,845 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:32,846 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.8116204971447587. input_tokens=326, output_tokens=87
12:49:32,993 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:32,994 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.61516291834414. input_tokens=325, output_tokens=72
12:49:33,1 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:33,2 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.910764139611274. input_tokens=671, output_tokens=177
12:49:33,45 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:33,46 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.8569165398366749. input_tokens=253, output_tokens=28
12:49:33,375 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:33,376 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 5.271882112137973. input_tokens=378, output_tokens=188
12:49:33,449 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:33,450 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.112494976259768. input_tokens=282, output_tokens=50
12:49:33,525 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:33,526 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.9794787168502808. input_tokens=471, output_tokens=130
12:49:33,526 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:33,528 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.6377096846699715. input_tokens=323, output_tokens=132
12:49:33,805 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:33,806 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.4110446549020708. input_tokens=474, output_tokens=137
12:49:33,885 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:33,886 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.017482107039541. input_tokens=486, output_tokens=92
12:49:34,37 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:34,38 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 5.940501924138516. input_tokens=473, output_tokens=226
12:49:34,109 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:34,110 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.5319874272681773. input_tokens=450, output_tokens=103
12:49:34,110 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:34,110 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:34,113 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.0027223280631006. input_tokens=482, output_tokens=133
12:49:34,113 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.3469868185929954. input_tokens=298, output_tokens=61
12:49:34,410 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:34,410 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:34,410 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.6414363840594888. input_tokens=494, output_tokens=158
12:49:34,411 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.840818892698735. input_tokens=292, output_tokens=89
12:49:34,457 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:34,458 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.9091869317926466. input_tokens=488, output_tokens=209
12:49:34,641 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:34,642 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.1014540549367666. input_tokens=372, output_tokens=94
12:49:34,852 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:34,853 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 6.760027946904302. input_tokens=778, output_tokens=287
12:49:34,865 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:34,865 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.9674294302240014. input_tokens=558, output_tokens=141
12:49:35,73 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:35,74 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.7080850172787905. input_tokens=357, output_tokens=119
12:49:35,149 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:35,150 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.087903442326933. input_tokens=825, output_tokens=180
12:49:35,373 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:35,374 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.6342123481445014. input_tokens=438, output_tokens=165
12:49:35,401 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:35,402 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.8754647956229746. input_tokens=300, output_tokens=84
12:49:35,666 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:35,666 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:35,666 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.6204898860305548. input_tokens=370, output_tokens=108
12:49:35,667 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.8210396794602275. input_tokens=338, output_tokens=110
12:49:35,689 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:35,690 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.239670088980347. input_tokens=339, output_tokens=91
12:49:35,933 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:35,934 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.5578285148367286. input_tokens=317, output_tokens=105
12:49:35,957 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:35,957 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4996898537501693. input_tokens=287, output_tokens=58
12:49:36,222 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:36,222 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.220134891103953. input_tokens=374, output_tokens=116
12:49:36,245 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:36,245 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.834219896234572. input_tokens=316, output_tokens=83
12:49:36,258 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:36,259 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.1435586381703615. input_tokens=287, output_tokens=99
12:49:36,273 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:36,273 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.159489555284381. input_tokens=335, output_tokens=105
12:49:36,301 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:36,302 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.3075529700145125. input_tokens=416, output_tokens=148
12:49:36,629 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:36,630 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.1015801881439984. input_tokens=284, output_tokens=122
12:49:36,638 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:36,638 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 8.567300245165825. input_tokens=1422, output_tokens=334
12:49:36,861 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:36,862 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.4488012925721705. input_tokens=282, output_tokens=96
12:49:37,9 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:37,10 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.3673305748961866. input_tokens=295, output_tokens=104
12:49:37,89 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:37,90 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.203999775927514. input_tokens=372, output_tokens=136
12:49:37,265 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:37,266 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.8916337336413562. input_tokens=432, output_tokens=71
12:49:37,462 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:37,462 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.3121850951574743. input_tokens=365, output_tokens=93
12:49:37,485 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:37,485 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.6790228788740933. input_tokens=504, output_tokens=152
12:49:37,537 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:37,538 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.6843206486664712. input_tokens=312, output_tokens=125
12:49:37,538 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:37,540 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.9098562030121684. input_tokens=291, output_tokens=39
12:49:37,974 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:37,974 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:37,974 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.1122727552428842. input_tokens=290, output_tokens=49
12:49:37,975 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.5730696259997785. input_tokens=424, output_tokens=125
12:49:37,997 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:37,997 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.3301958427764475. input_tokens=412, output_tokens=105
12:49:38,21 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:38,21 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.9834608398377895. input_tokens=380, output_tokens=172
12:49:38,337 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:38,338 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.064720478374511. input_tokens=400, output_tokens=105
12:49:38,338 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:38,341 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.7021121908910573. input_tokens=302, output_tokens=72
12:49:38,361 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:38,361 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.495868458878249. input_tokens=449, output_tokens=167
12:49:38,543 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:38,544 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 10.448678885120898. input_tokens=1747, output_tokens=363
12:49:38,585 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:38,586 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.916417902801186. input_tokens=372, output_tokens=125
12:49:38,805 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:38,806 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.5470611001364887. input_tokens=405, output_tokens=106
12:49:38,853 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:38,854 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.608090622816235. input_tokens=364, output_tokens=100
12:49:39,38 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:39,38 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.348398143891245. input_tokens=426, output_tokens=131
12:49:39,257 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:39,258 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.035566410049796. input_tokens=391, output_tokens=124
12:49:39,437 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:39,438 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.5034033260308206. input_tokens=502, output_tokens=149
12:49:39,461 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:39,461 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.975889434106648. input_tokens=265, output_tokens=88
12:49:39,463 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:39,464 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4888403178192675. input_tokens=283, output_tokens=56
12:49:39,689 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:39,690 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.1492434348911047. input_tokens=283, output_tokens=84
12:49:39,690 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:39,692 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.3905745977535844. input_tokens=401, output_tokens=127
12:49:39,737 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:39,738 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.727503655012697. input_tokens=315, output_tokens=114
12:49:39,998 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:39,998 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.5357216019183397. input_tokens=333, output_tokens=100
12:49:40,45 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:40,46 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 5.934856238774955. input_tokens=689, output_tokens=273
12:49:40,77 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:40,78 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.9876464740373194. input_tokens=334, output_tokens=128
12:49:40,78 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:40,78 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:40,81 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.122921316884458. input_tokens=511, output_tokens=174
12:49:40,81 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.542853605002165. input_tokens=296, output_tokens=105
12:49:40,413 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:40,414 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.0525367772206664. input_tokens=428, output_tokens=77
12:49:40,437 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:40,437 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 5.362894830759615. input_tokens=622, output_tokens=203
12:49:40,493 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:40,494 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.2276277178898454. input_tokens=509, output_tokens=130
12:49:40,786 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:40,786 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.4453183878213167. input_tokens=301, output_tokens=97
12:49:40,833 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:40,834 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.8125343159772456. input_tokens=317, output_tokens=111
12:49:41,17 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:41,18 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.0193725251592696. input_tokens=260, output_tokens=27
12:49:41,41 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:41,41 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.002935593947768. input_tokens=323, output_tokens=73
12:49:41,93 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:41,94 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.7550280541181564. input_tokens=333, output_tokens=109
12:49:41,294 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:41,294 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.2966990447603166. input_tokens=461, output_tokens=131
12:49:41,341 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:41,342 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.364688371308148. input_tokens=308, output_tokens=113
12:49:41,494 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:41,494 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.0303087909705937. input_tokens=331, output_tokens=74
12:49:41,521 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:41,522 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.7151137879118323. input_tokens=316, output_tokens=98
12:49:41,573 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:41,574 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.835927786771208. input_tokens=295, output_tokens=65
12:49:41,765 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:41,766 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.221843152772635. input_tokens=574, output_tokens=135
12:49:41,813 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:41,814 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.7678216719068587. input_tokens=262, output_tokens=59
12:49:41,989 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:41,990 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.5282924342900515. input_tokens=373, output_tokens=77
12:49:42,13 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:42,13 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.7550662392750382. input_tokens=323, output_tokens=88
12:49:42,41 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:42,41 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.1875565061345696. input_tokens=339, output_tokens=114
12:49:42,361 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:42,362 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.8677914631552994. input_tokens=337, output_tokens=85
12:49:42,385 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:42,386 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.947596144862473. input_tokens=362, output_tokens=96
12:49:42,396 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:42,397 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.31559257209301. input_tokens=309, output_tokens=80
12:49:42,753 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:42,754 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.967269906308502. input_tokens=429, output_tokens=74
12:49:42,901 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:42,902 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.315889606252313. input_tokens=449, output_tokens=167
12:49:42,925 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:42,925 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.8415771583095193. input_tokens=414, output_tokens=93
12:49:43,97 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:43,98 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.407400930300355. input_tokens=372, output_tokens=124
12:49:43,173 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:43,174 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.3395916176959872. input_tokens=447, output_tokens=94
12:49:43,249 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:43,250 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.9553451919928193. input_tokens=302, output_tokens=77
12:49:43,425 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:43,426 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4119386202655733. input_tokens=311, output_tokens=69
12:49:43,601 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:43,602 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.5600524907931685. input_tokens=313, output_tokens=109
12:49:43,602 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:43,604 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.5625828602351248. input_tokens=338, output_tokens=83
12:49:43,681 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:43,682 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.9891935721971095. input_tokens=820, output_tokens=143
12:49:43,682 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:43,682 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:43,683 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:43,685 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.6668294509872794. input_tokens=408, output_tokens=106
12:49:43,685 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.69527143612504. input_tokens=316, output_tokens=82
12:49:43,686 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.3437745277769864. input_tokens=298, output_tokens=95
12:49:43,993 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:43,994 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.419670464936644. input_tokens=353, output_tokens=88
12:49:44,69 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:44,70 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.6319372695870697. input_tokens=404, output_tokens=135
12:49:44,217 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:44,218 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.1242696112021804. input_tokens=357, output_tokens=128
12:49:44,245 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:44,245 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.47892985958606. input_tokens=390, output_tokens=96
12:49:44,269 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:44,270 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.190999916289002. input_tokens=641, output_tokens=157
12:49:44,481 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:44,482 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.7277859798632562. input_tokens=273, output_tokens=69
12:49:44,753 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:44,754 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.339458718895912. input_tokens=605, output_tokens=167
12:49:44,801 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:44,802 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.439569295849651. input_tokens=344, output_tokens=125
12:49:44,957 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:44,958 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.436185299884528. input_tokens=349, output_tokens=127
12:49:45,5 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:45,6 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.5111683951690793. input_tokens=374, output_tokens=132
12:49:45,189 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:45,190 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.264038930181414. input_tokens=299, output_tokens=110
12:49:45,190 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:45,192 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.806543421931565. input_tokens=304, output_tokens=118
12:49:45,265 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:45,266 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.1677768188528717. input_tokens=285, output_tokens=91
12:49:45,437 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:45,438 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.6241667079739273. input_tokens=319, output_tokens=177
12:49:45,513 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:45,514 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.1167087657377124. input_tokens=353, output_tokens=157
12:49:45,593 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:45,594 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.1677527730353177. input_tokens=321, output_tokens=97
12:49:45,594 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:45,597 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.3464704169891775. input_tokens=338, output_tokens=92
12:49:45,669 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:45,670 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.0674737691879272. input_tokens=287, output_tokens=105
12:49:45,837 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:45,837 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:45,838 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.1501721586100757. input_tokens=373, output_tokens=88
12:49:45,838 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.6639200183562934. input_tokens=311, output_tokens=88
12:49:46,21 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:46,22 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.027691427618265. input_tokens=278, output_tokens=82
12:49:46,45 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:46,45 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2434688182547688. input_tokens=316, output_tokens=32
12:49:46,207 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:46,208 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.521702680271119. input_tokens=388, output_tokens=89
12:49:46,449 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:46,450 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.204143475741148. input_tokens=286, output_tokens=94
12:49:46,452 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:46,452 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.769467390142381. input_tokens=282, output_tokens=114
12:49:46,497 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:46,498 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.595698026008904. input_tokens=392, output_tokens=167
12:49:46,525 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:46,525 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.255575496237725. input_tokens=311, output_tokens=108
12:49:46,528 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:46,528 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.9234924502670765. input_tokens=295, output_tokens=144
12:49:46,769 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:46,770 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.015771185979247. input_tokens=273, output_tokens=74
12:49:46,849 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:46,850 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.36775054782629. input_tokens=310, output_tokens=100
12:49:47,4 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:47,4 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.3147694137878716. input_tokens=301, output_tokens=135
12:49:47,77 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:47,78 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.237115393858403. input_tokens=327, output_tokens=45
12:49:47,225 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:47,226 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.180612325668335. input_tokens=334, output_tokens=47
12:49:47,249 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:47,249 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.0415903870016336. input_tokens=344, output_tokens=51
12:49:47,273 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:47,273 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.2033275491558015. input_tokens=322, output_tokens=154
12:49:47,301 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:47,301 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.7070396640338004. input_tokens=274, output_tokens=56
12:49:47,517 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:47,518 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.6794049059972167. input_tokens=313, output_tokens=59
12:49:47,565 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:47,565 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:47,566 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.8959838598966599. input_tokens=286, output_tokens=80
12:49:47,566 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.127944335807115. input_tokens=304, output_tokens=82
12:49:47,790 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:47,790 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:47,791 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.572053608018905. input_tokens=314, output_tokens=143
12:49:47,791 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.524936913046986. input_tokens=309, output_tokens=100
12:49:47,813 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:47,813 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.6230453778989613. input_tokens=319, output_tokens=112
12:49:47,814 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:47,816 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.3019673177041113. input_tokens=322, output_tokens=80
12:49:47,869 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:47,870 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.863348259124905. input_tokens=307, output_tokens=105
12:49:47,872 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:47,872 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.850471690762788. input_tokens=295, output_tokens=74
12:49:48,201 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:48,202 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.243405238725245. input_tokens=303, output_tokens=111
12:49:48,249 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:48,250 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.6528660370968282. input_tokens=430, output_tokens=105
12:49:48,529 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:48,530 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.031681227032095. input_tokens=300, output_tokens=70
12:49:48,753 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:48,754 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.3011194481514394. input_tokens=300, output_tokens=81
12:49:48,756 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:48,757 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.5639273007400334. input_tokens=361, output_tokens=121
12:49:48,934 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:48,934 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.684680467005819. input_tokens=295, output_tokens=56
12:49:48,957 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:48,957 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.1073521142825484. input_tokens=376, output_tokens=84
12:49:48,960 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:48,960 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.0873415940441191. input_tokens=300, output_tokens=46
12:49:49,221 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:49,222 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.9486571531742811. input_tokens=280, output_tokens=85
12:49:49,245 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:49,245 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.1675123861059546. input_tokens=287, output_tokens=86
12:49:49,301 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:49,302 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.0518259829841554. input_tokens=337, output_tokens=49
12:49:49,481 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:49,482 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.9563600490801036. input_tokens=400, output_tokens=120
12:49:49,505 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:49,506 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.055594091769308. input_tokens=317, output_tokens=107
12:49:49,713 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:49,714 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:49,714 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.4128423808142543. input_tokens=398, output_tokens=111
12:49:49,715 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.4884945801459253. input_tokens=309, output_tokens=78
12:49:49,715 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:49,715 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:49,719 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.517134684138. input_tokens=346, output_tokens=62
12:49:49,720 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.2013525082729757. input_tokens=294, output_tokens=74
12:49:49,737 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:49,737 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2074599750339985. input_tokens=337, output_tokens=48
12:49:49,789 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:49,790 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.9984208978712559. input_tokens=353, output_tokens=83
12:49:50,113 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:50,114 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.3211631402373314. input_tokens=354, output_tokens=91
12:49:50,114 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:50,117 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.3628114010207355. input_tokens=307, output_tokens=43
12:49:50,193 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:50,194 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.6272165840491652. input_tokens=380, output_tokens=104
12:49:50,194 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:50,197 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.628311394713819. input_tokens=373, output_tokens=84
12:49:50,197 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:50,197 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:50,200 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.6714736740104854. input_tokens=340, output_tokens=100
12:49:50,200 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.195779657922685. input_tokens=279, output_tokens=128
12:49:50,485 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:50,486 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.7159450920298696. input_tokens=266, output_tokens=85
12:49:50,565 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:50,566 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.7495717187412083. input_tokens=408, output_tokens=105
12:49:50,641 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:50,642 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.8278174051083624. input_tokens=641, output_tokens=113
12:49:50,793 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:50,794 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:50,794 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.9244174952618778. input_tokens=367, output_tokens=93
12:49:50,795 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.5723065598867834. input_tokens=280, output_tokens=44
12:49:51,278 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:51,278 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.3205283228307962. input_tokens=347, output_tokens=89
12:49:51,353 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:51,354 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.1082415422424674. input_tokens=283, output_tokens=86
12:49:51,578 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:51,578 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.7884755809791386. input_tokens=320, output_tokens=86
12:49:51,657 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:51,658 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.9378638812340796. input_tokens=318, output_tokens=79
12:49:51,854 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:51,854 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.212222236674279. input_tokens=304, output_tokens=62
12:49:51,877 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:51,877 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.916998967062682. input_tokens=323, output_tokens=134
12:49:51,905 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:51,906 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.6035032840445638. input_tokens=315, output_tokens=106
12:49:51,906 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:51,908 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.151144057046622. input_tokens=308, output_tokens=129
12:49:52,111 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:52,111 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.9086834569461644. input_tokens=336, output_tokens=97
12:49:52,129 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:52,130 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.1949133719317615. input_tokens=329, output_tokens=130
12:49:52,181 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:52,181 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:52,182 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.6996160252019763. input_tokens=313, output_tokens=107
12:49:52,182 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.6766250119544566. input_tokens=334, output_tokens=104
12:49:52,410 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:52,410 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:52,411 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.2958218711428344. input_tokens=304, output_tokens=82
12:49:52,411 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.6955260299146175. input_tokens=276, output_tokens=91
12:49:52,416 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:52,416 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.6987696662545204. input_tokens=279, output_tokens=95
12:49:52,654 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:52,654 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.91671233298257. input_tokens=302, output_tokens=118
12:49:52,677 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:52,678 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.5604842607863247. input_tokens=337, output_tokens=101
12:49:52,885 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:52,886 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.164181828033179. input_tokens=365, output_tokens=111
12:49:53,26 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:53,26 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.4603662719018757. input_tokens=340, output_tokens=110
12:49:53,53 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:53,53 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.858744792174548. input_tokens=360, output_tokens=127
12:49:53,345 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:53,346 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4376736357808113. input_tokens=329, output_tokens=47
12:49:53,393 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:53,394 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.1930719492956996. input_tokens=356, output_tokens=128
12:49:53,425 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:53,426 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.93916930584237. input_tokens=344, output_tokens=135
12:49:53,580 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:53,581 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.383082734886557. input_tokens=359, output_tokens=119
12:49:53,621 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:53,621 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.0429436708800495. input_tokens=314, output_tokens=62
12:49:53,653 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:53,654 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.9956153011880815. input_tokens=292, output_tokens=72
12:49:53,656 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:53,656 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.0018145060166717. input_tokens=274, output_tokens=41
12:49:53,941 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:53,942 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.5878579202108085. input_tokens=351, output_tokens=89
12:49:53,961 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:53,961 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.1663299687206745. input_tokens=352, output_tokens=153
12:49:54,141 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:54,142 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.255900664255023. input_tokens=283, output_tokens=51
12:49:54,165 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:54,165 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.3106952193193138. input_tokens=303, output_tokens=69
12:49:54,397 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:54,398 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.601295873057097. input_tokens=396, output_tokens=181
12:49:54,417 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:54,417 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.5112184532918036. input_tokens=305, output_tokens=86
12:49:54,441 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:54,442 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.163061309605837. input_tokens=323, output_tokens=124
12:49:54,629 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:54,630 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.9733023140579462. input_tokens=257, output_tokens=32
12:49:54,657 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:54,658 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.7800364391878247. input_tokens=326, output_tokens=86
12:49:54,814 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:54,814 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:54,814 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.401341523975134. input_tokens=360, output_tokens=76
12:49:54,815 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.7035321625880897. input_tokens=338, output_tokens=94
12:49:54,815 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:54,819 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.1415369361639023. input_tokens=276, output_tokens=87
12:49:54,833 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:54,833 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.8064212901517749. input_tokens=267, output_tokens=69
12:49:55,117 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:55,118 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.7068110550753772. input_tokens=367, output_tokens=96
12:49:55,274 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:55,274 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.9278791947290301. input_tokens=269, output_tokens=60
12:49:55,426 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:55,426 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.3725886535830796. input_tokens=282, output_tokens=88
12:49:55,449 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:55,450 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.8279170081950724. input_tokens=257, output_tokens=63
12:49:55,702 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:55,702 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.3082959819585085. input_tokens=259, output_tokens=80
12:49:55,725 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:55,726 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.7834874629043043. input_tokens=290, output_tokens=70
12:49:55,886 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:55,886 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.7036401499062777. input_tokens=371, output_tokens=131
12:49:55,965 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:55,966 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.8359798048622906. input_tokens=418, output_tokens=157
12:49:56,41 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:56,42 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.3878375720232725. input_tokens=279, output_tokens=96
12:49:56,77 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:56,77 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2601875183172524. input_tokens=297, output_tokens=51
12:49:56,80 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:56,80 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.6637745536863804. input_tokens=335, output_tokens=133
12:49:56,293 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:56,294 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.151919597759843. input_tokens=318, output_tokens=73
12:49:56,369 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:56,370 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.185339413117617. input_tokens=389, output_tokens=165
12:49:56,521 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:56,522 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.891683413181454. input_tokens=317, output_tokens=76
12:49:56,549 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:56,549 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:56,550 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.5882766149006784. input_tokens=348, output_tokens=103
12:49:56,550 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.124342770781368. input_tokens=257, output_tokens=94
12:49:56,601 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:56,602 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.2032019277103245. input_tokens=299, output_tokens=80
12:49:56,885 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:56,886 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:56,886 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.444286494050175. input_tokens=325, output_tokens=93
12:49:56,887 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.053236766718328. input_tokens=378, output_tokens=79
12:49:57,125 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:57,126 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.4679874619469047. input_tokens=329, output_tokens=106
12:49:57,173 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:57,174 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.7560499091632664. input_tokens=328, output_tokens=117
12:49:57,353 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:57,354 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.538297933060676. input_tokens=318, output_tokens=105
12:49:57,354 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:57,356 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.238007999956608. input_tokens=373, output_tokens=106
12:49:57,433 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:57,434 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.268120216205716. input_tokens=354, output_tokens=149
12:49:57,689 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:57,690 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.9874935117550194. input_tokens=329, output_tokens=75
12:49:57,690 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:57,693 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.966911822091788. input_tokens=332, output_tokens=68
12:49:57,693 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:57,695 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.2686675381846726. input_tokens=326, output_tokens=77
12:49:57,737 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:57,738 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.1872017597779632. input_tokens=312, output_tokens=44
12:49:57,998 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:57,998 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.4174512242898345. input_tokens=315, output_tokens=121
12:49:58,77 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:58,78 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.6279816599562764. input_tokens=324, output_tokens=90
12:49:58,149 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:58,150 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.548152999021113. input_tokens=286, output_tokens=91
12:49:58,358 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:58,358 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.538621549960226. input_tokens=333, output_tokens=139
12:49:58,522 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:58,522 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.480188555084169. input_tokens=447, output_tokens=111
12:49:58,545 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:58,545 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.5793425417505205. input_tokens=396, output_tokens=110
12:49:58,569 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:58,570 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.4891616152599454. input_tokens=314, output_tokens=93
12:49:58,570 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:58,572 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.2778603597544134. input_tokens=315, output_tokens=117
12:49:58,572 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:58,573 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:58,575 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.3004752066917717. input_tokens=420, output_tokens=122
12:49:58,575 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.053260067012161. input_tokens=282, output_tokens=72
12:49:58,965 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:58,966 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:58,966 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.41417478909716. input_tokens=358, output_tokens=111
12:49:58,967 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.5966316568665206. input_tokens=335, output_tokens=104
12:49:59,45 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:59,45 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:59,46 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:59,46 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.9684891309589148. input_tokens=418, output_tokens=138
12:49:59,47 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.6924200439825654. input_tokens=277, output_tokens=48
12:49:59,47 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.8732514888979495. input_tokens=294, output_tokens=69
12:49:59,285 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:59,286 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.1596327740699053. input_tokens=285, output_tokens=68
12:49:59,333 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:59,334 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.4452565000392497. input_tokens=332, output_tokens=87
12:49:59,550 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:59,550 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.859517885837704. input_tokens=278, output_tokens=54
12:49:59,597 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:59,598 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.241163043770939. input_tokens=329, output_tokens=77
12:49:59,829 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:59,830 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.3959151529707015. input_tokens=302, output_tokens=78
12:49:59,864 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:59,864 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.1709281569346786. input_tokens=308, output_tokens=82
12:49:59,877 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:59,877 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.990626201964915. input_tokens=347, output_tokens=121
12:49:59,879 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:49:59,880 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.184350247029215. input_tokens=297, output_tokens=86
12:50:00,162 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:00,162 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.275679104030132. input_tokens=322, output_tokens=129
12:50:00,185 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:00,186 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2187052071094513. input_tokens=267, output_tokens=49
12:50:00,186 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:00,188 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.4504670719616115. input_tokens=292, output_tokens=93
12:50:00,481 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:00,482 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.403717725072056. input_tokens=308, output_tokens=94
12:50:00,637 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:00,638 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.2793498230166733. input_tokens=420, output_tokens=85
12:50:00,685 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:00,686 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.7170343361794949. input_tokens=269, output_tokens=66
12:50:00,686 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:00,686 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:00,689 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.0907929348759353. input_tokens=296, output_tokens=44
12:50:00,689 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.143599361181259. input_tokens=393, output_tokens=68
12:50:00,713 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:00,713 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.833236513659358. input_tokens=280, output_tokens=34
12:50:01,9 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:01,10 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.0110272238962352. input_tokens=285, output_tokens=105
12:50:01,33 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:01,33 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:01,34 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.16948486212641. input_tokens=283, output_tokens=41
12:50:01,34 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.511843997053802. input_tokens=424, output_tokens=91
12:50:01,261 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:01,262 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.2147174328565598. input_tokens=267, output_tokens=70
12:50:01,337 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:01,338 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.1753237061202526. input_tokens=280, output_tokens=35
12:50:01,460 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:01,461 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.4100735490210354. input_tokens=359, output_tokens=90
12:50:01,501 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:01,502 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.928822671994567. input_tokens=297, output_tokens=97
12:50:01,502 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:01,504 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.3541732509620488. input_tokens=382, output_tokens=123
12:50:01,741 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:01,742 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.1910923910327256. input_tokens=377, output_tokens=86
12:50:01,871 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:01,872 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.2942801010794938. input_tokens=299, output_tokens=116
12:50:02,21 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:02,22 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.4464286700822413. input_tokens=288, output_tokens=117
12:50:02,65 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:02,66 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.0166651005856693. input_tokens=291, output_tokens=141
12:50:02,66 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:02,69 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.191772764082998. input_tokens=283, output_tokens=71
12:50:02,257 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:02,258 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.971527968067676. input_tokens=403, output_tokens=126
12:50:02,258 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:02,258 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:02,261 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.072184890974313. input_tokens=282, output_tokens=53
12:50:02,261 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.43098186282441. input_tokens=295, output_tokens=88
12:50:02,333 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:02,334 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.999617860186845. input_tokens=368, output_tokens=117
12:50:02,553 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:02,554 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.071968447882682. input_tokens=314, output_tokens=68
12:50:02,701 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:02,702 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.131990499794483. input_tokens=369, output_tokens=144
12:50:02,749 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:02,750 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.0630074068903923. input_tokens=308, output_tokens=59
12:50:02,933 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:02,934 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.747917339671403. input_tokens=316, output_tokens=101
12:50:02,983 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:02,983 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.2937906878069043. input_tokens=315, output_tokens=64
12:50:03,137 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:03,138 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.4996614321134984. input_tokens=291, output_tokens=67
12:50:03,161 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:03,161 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.094968840945512. input_tokens=293, output_tokens=33
12:50:03,217 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:03,218 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.5040657250210643. input_tokens=302, output_tokens=74
12:50:03,385 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:03,386 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.3756215716712177. input_tokens=327, output_tokens=93
12:50:03,433 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:03,434 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.399185363203287. input_tokens=362, output_tokens=87
12:50:03,599 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:03,599 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.3362060161307454. input_tokens=385, output_tokens=48
12:50:03,621 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:03,621 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.360132351052016. input_tokens=369, output_tokens=43
12:50:03,641 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:03,641 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.3031276911497116. input_tokens=361, output_tokens=88
12:50:03,643 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:03,644 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.3812419679015875. input_tokens=353, output_tokens=85
12:50:03,669 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:03,669 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.6470316490158439. input_tokens=317, output_tokens=58
12:50:03,941 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:03,942 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.4369599232450128. input_tokens=364, output_tokens=87
12:50:03,989 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:03,990 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.4872055328451097. input_tokens=350, output_tokens=83
12:50:03,992 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:03,992 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.9560155062936246. input_tokens=350, output_tokens=112
12:50:04,213 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:04,214 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.75220910878852. input_tokens=340, output_tokens=79
12:50:04,237 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:04,237 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.9788598092272878. input_tokens=299, output_tokens=62
12:50:04,405 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:04,405 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.7141393339261413. input_tokens=378, output_tokens=132
12:50:04,621 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:04,622 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4040105328895152. input_tokens=338, output_tokens=43
12:50:04,673 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:04,674 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:04,674 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.932037841062993. input_tokens=484, output_tokens=93
12:50:04,675 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.802489809691906. input_tokens=301, output_tokens=116
12:50:04,942 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:04,942 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.2397613688372076. input_tokens=370, output_tokens=82
12:50:05,17 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:05,18 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.6836457811295986. input_tokens=350, output_tokens=94
12:50:05,169 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:05,170 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.7361364313401282. input_tokens=328, output_tokens=56
12:50:05,217 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:05,218 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.663399287033826. input_tokens=291, output_tokens=97
12:50:05,218 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:05,220 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.1506404178217053. input_tokens=290, output_tokens=104
12:50:05,245 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:05,246 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.107567569706589. input_tokens=284, output_tokens=60
12:50:05,609 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:05,610 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.860249435994774. input_tokens=316, output_tokens=92
12:50:05,633 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:05,634 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:05,634 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:05,634 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.6508310101926327. input_tokens=323, output_tokens=84
12:50:05,635 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.700471004936844. input_tokens=324, output_tokens=99
12:50:05,635 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.4733989778906107. input_tokens=321, output_tokens=81
12:50:05,889 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:05,890 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.9475097740069032. input_tokens=297, output_tokens=24
12:50:05,890 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:05,893 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.2228664471767843. input_tokens=318, output_tokens=71
12:50:05,969 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:05,970 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.583908670116216. input_tokens=336, output_tokens=86
12:50:06,142 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:06,142 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:06,142 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.8966611651703715. input_tokens=288, output_tokens=25
12:50:06,143 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.49899296509102. input_tokens=328, output_tokens=85
12:50:06,143 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:06,147 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.5251979818567634. input_tokens=321, output_tokens=55
12:50:06,165 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:06,165 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.5657998202368617. input_tokens=325, output_tokens=86
12:50:06,189 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:06,189 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.196758702863008. input_tokens=321, output_tokens=74
12:50:06,217 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:06,218 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.9970620051026344. input_tokens=296, output_tokens=40
12:50:06,521 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:06,522 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:06,522 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.845610274001956. input_tokens=304, output_tokens=66
12:50:06,523 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.8813268397934735. input_tokens=348, output_tokens=98
12:50:06,545 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:06,545 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.1397629478015006. input_tokens=350, output_tokens=83
12:50:06,548 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:06,548 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.8733909968286753. input_tokens=289, output_tokens=53
12:50:06,569 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:06,569 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.627480369992554. input_tokens=320, output_tokens=90
12:50:06,601 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:06,601 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.5836169589310884. input_tokens=276, output_tokens=50
12:50:06,938 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:06,938 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.3166333292610943. input_tokens=324, output_tokens=80
12:50:06,961 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:06,961 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.971628602128476. input_tokens=322, output_tokens=94
12:50:07,194 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:07,194 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.9804498702287674. input_tokens=310, output_tokens=89
12:50:07,217 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:07,218 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.979923781938851. input_tokens=343, output_tokens=90
12:50:07,438 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:07,438 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.799246072769165. input_tokens=291, output_tokens=43
12:50:07,438 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:07,441 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.8304380825720727. input_tokens=288, output_tokens=44
12:50:07,705 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:07,706 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.0686646262183785. input_tokens=317, output_tokens=57
12:50:07,850 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:07,850 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.6605871333740652. input_tokens=339, output_tokens=60
12:50:07,873 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:07,874 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.7032723329029977. input_tokens=317, output_tokens=93
12:50:08,6 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:08,6 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.8589476682245731. input_tokens=291, output_tokens=73
12:50:08,73 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:08,73 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:08,74 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.4387138509191573. input_tokens=302, output_tokens=64
12:50:08,74 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.9090726459398866. input_tokens=300, output_tokens=69
12:50:08,75 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:08,79 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.8610664340667427. input_tokens=361, output_tokens=61
12:50:08,398 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:08,398 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.1799840200692415. input_tokens=326, output_tokens=110
12:50:08,421 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:08,422 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.85193304810673. input_tokens=359, output_tokens=69
12:50:08,473 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:08,474 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.9508417528122663. input_tokens=357, output_tokens=68
12:50:08,786 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:08,786 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.816182300914079. input_tokens=289, output_tokens=81
12:50:08,833 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:08,834 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.6159985340200365. input_tokens=423, output_tokens=71
12:50:08,834 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:08,837 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.946058908943087. input_tokens=374, output_tokens=112
12:50:08,865 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:08,866 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.722077000886202. input_tokens=296, output_tokens=80
12:50:09,105 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:09,106 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.560119402129203. input_tokens=370, output_tokens=84
12:50:09,125 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:09,125 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.5769516485743225. input_tokens=388, output_tokens=87
12:50:09,325 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:09,326 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.8848168370313942. input_tokens=427, output_tokens=80
12:50:09,326 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:09,329 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.1832208926789463. input_tokens=316, output_tokens=97
12:50:09,353 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:09,353 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.3916464778594673. input_tokens=431, output_tokens=98
12:50:09,355 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:09,356 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.161240526009351. input_tokens=411, output_tokens=86
12:50:09,580 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:09,580 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.50112975994125. input_tokens=340, output_tokens=55
12:50:09,621 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:09,622 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.7713892911560833. input_tokens=345, output_tokens=59
12:50:09,653 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:09,654 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.0519562368281186. input_tokens=342, output_tokens=102
12:50:09,886 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:09,886 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:09,886 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.993703327141702. input_tokens=373, output_tokens=138
12:50:09,887 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.94846069207415. input_tokens=356, output_tokens=107
12:50:09,933 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:09,934 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.4949263678863645. input_tokens=386, output_tokens=82
12:50:09,965 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:09,966 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.491600267123431. input_tokens=341, output_tokens=49
12:50:10,249 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:10,250 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.543800919316709. input_tokens=378, output_tokens=102
12:50:10,329 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:10,330 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.804899523034692. input_tokens=381, output_tokens=131
12:50:10,406 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:10,406 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:10,407 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.5696805380284786. input_tokens=325, output_tokens=51
12:50:10,407 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.533285546116531. input_tokens=357, output_tokens=90
12:50:10,629 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:10,630 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.623330359812826. input_tokens=349, output_tokens=85
12:50:10,677 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:10,678 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:10,678 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.6029186258092523. input_tokens=351, output_tokens=90
12:50:10,678 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.601509931962937. input_tokens=352, output_tokens=94
12:50:10,878 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:10,878 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.0124024841934443. input_tokens=318, output_tokens=63
12:50:10,925 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:10,926 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.5272303372621536. input_tokens=382, output_tokens=91
12:50:11,109 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:11,110 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2206725128926337. input_tokens=320, output_tokens=39
12:50:11,185 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:11,186 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.6052578217349946. input_tokens=372, output_tokens=54
12:50:11,510 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:11,510 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.088365979027003. input_tokens=358, output_tokens=113
12:50:11,511 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:11,513 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.8589963698759675. input_tokens=464, output_tokens=99
12:50:11,533 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:11,533 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.2068810728378594. input_tokens=318, output_tokens=86
12:50:11,535 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:11,536 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.4101566411554813. input_tokens=376, output_tokens=94
12:50:11,797 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:11,798 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.0112170199863613. input_tokens=390, output_tokens=121
12:50:11,925 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:11,926 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.0386919719167054. input_tokens=331, output_tokens=82
12:50:11,949 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:11,950 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.6207867320626974. input_tokens=387, output_tokens=102
12:50:12,121 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:12,122 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.499794241040945. input_tokens=373, output_tokens=98
12:50:12,124 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:12,125 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.7684827353805304. input_tokens=334, output_tokens=127
12:50:12,201 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:12,202 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.571295295841992. input_tokens=315, output_tokens=65
12:50:12,369 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:12,370 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.0162461888976395. input_tokens=388, output_tokens=116
12:50:12,605 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:12,606 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:12,606 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.7717129583470523. input_tokens=406, output_tokens=116
12:50:12,607 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.356517930049449. input_tokens=315, output_tokens=79
12:50:12,845 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:12,846 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.880122016184032. input_tokens=321, output_tokens=127
12:50:12,873 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:12,874 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.939655807800591. input_tokens=317, output_tokens=110
12:50:12,893 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:12,894 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.5637373230420053. input_tokens=310, output_tokens=95
12:50:13,117 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:13,118 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:13,119 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.7095586699433625. input_tokens=341, output_tokens=98
12:50:13,119 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.4389387350529432. input_tokens=299, output_tokens=115
12:50:13,165 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:13,166 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.487105750013143. input_tokens=451, output_tokens=109
12:50:13,389 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:13,390 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.283918816130608. input_tokens=427, output_tokens=166
12:50:13,709 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:13,710 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.1991675500757992. input_tokens=374, output_tokens=108
12:50:13,761 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:13,762 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.9637544131837785. input_tokens=379, output_tokens=85
12:50:13,789 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:13,790 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.1830812338739634. input_tokens=355, output_tokens=55
12:50:13,997 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:13,998 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.048056830186397. input_tokens=345, output_tokens=97
12:50:13,998 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:13,998 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:14,1 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.464656258933246. input_tokens=354, output_tokens=96
12:50:14,1 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.891041912138462. input_tokens=333, output_tokens=136
12:50:14,21 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:14,21 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.5084108100272715. input_tokens=301, output_tokens=119
12:50:14,41 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:14,41 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.1153511232696474. input_tokens=391, output_tokens=89
12:50:14,43 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:14,44 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.1654422567225993. input_tokens=313, output_tokens=134
12:50:14,73 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:14,73 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2272410849109292. input_tokens=303, output_tokens=63
12:50:14,585 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:14,586 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.215756074991077. input_tokens=335, output_tokens=99
12:50:14,761 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:14,762 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.5757684600539505. input_tokens=350, output_tokens=185
12:50:14,805 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:14,806 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4154692688025534. input_tokens=298, output_tokens=54
12:50:14,969 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:14,970 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.4363112011924386. input_tokens=383, output_tokens=140
12:50:15,45 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:15,46 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.9262405908666551. input_tokens=287, output_tokens=86
12:50:15,125 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:15,126 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.9238316169939935. input_tokens=325, output_tokens=117
12:50:15,301 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:15,302 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.693242796231061. input_tokens=375, output_tokens=121
12:50:15,349 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:15,350 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.2279711002483964. input_tokens=332, output_tokens=117
12:50:15,377 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:15,378 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.2116815019398928. input_tokens=309, output_tokens=78
12:50:15,380 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:15,381 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.5068815844133496. input_tokens=318, output_tokens=110
12:50:15,645 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:15,646 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.523032795637846. input_tokens=325, output_tokens=112
12:50:15,646 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:15,648 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.858361829072237. input_tokens=300, output_tokens=73
12:50:15,697 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:15,698 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 5.290473238099366. input_tokens=285, output_tokens=148
12:50:15,941 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:15,942 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 5.015968624968082. input_tokens=357, output_tokens=162
12:50:15,969 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:15,969 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.0754847428761423. input_tokens=335, output_tokens=125
12:50:15,972 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:15,972 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.847112842835486. input_tokens=351, output_tokens=170
12:50:15,975 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:15,976 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.9726313203573227. input_tokens=292, output_tokens=63
12:50:16,225 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:16,226 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.181599739007652. input_tokens=293, output_tokens=73
12:50:16,273 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:16,274 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.512054214719683. input_tokens=313, output_tokens=71
12:50:16,305 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:16,306 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.3044188120402396. input_tokens=294, output_tokens=82
12:50:16,561 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:16,562 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.5402785167098045. input_tokens=302, output_tokens=93
12:50:16,733 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:16,734 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.971839013043791. input_tokens=322, output_tokens=71
12:50:16,809 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:16,810 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.2237250809557736. input_tokens=307, output_tokens=71
12:50:16,833 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:16,834 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.8349403999745846. input_tokens=292, output_tokens=98
12:50:16,857 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:16,858 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.147994559723884. input_tokens=307, output_tokens=114
12:50:16,881 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:16,882 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.840042411815375. input_tokens=341, output_tokens=112
12:50:16,997 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:16,998 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.9245794252492487. input_tokens=318, output_tokens=120
12:50:17,25 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:17,26 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.7197620770893991. input_tokens=281, output_tokens=34
12:50:17,46 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:17,46 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.073934426996857. input_tokens=287, output_tokens=55
12:50:17,46 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:17,47 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.0773987411521375. input_tokens=283, output_tokens=56
12:50:17,69 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:17,70 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.6917160637676716. input_tokens=293, output_tokens=73
12:50:17,93 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:17,94 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.4449949101544917. input_tokens=301, output_tokens=75
12:50:17,189 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:17,190 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.491927222814411. input_tokens=286, output_tokens=79
12:50:17,237 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:17,238 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6757091912440956. input_tokens=295, output_tokens=40
12:50:17,261 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:17,262 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.6154297478497028. input_tokens=307, output_tokens=80
12:50:17,262 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:17,263 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.9885551310144365. input_tokens=294, output_tokens=47
12:50:17,309 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:17,310 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.5037491163238883. input_tokens=298, output_tokens=111
12:50:17,477 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:17,478 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.5356904221698642. input_tokens=284, output_tokens=85
12:50:17,593 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:17,594 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.2917997702024877. input_tokens=293, output_tokens=83
12:50:17,806 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:17,807 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.5805678791366518. input_tokens=327, output_tokens=87
12:50:17,829 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:17,830 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.4487389121204615. input_tokens=352, output_tokens=118
12:50:17,945 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:17,946 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.9704360137693584. input_tokens=304, output_tokens=110
12:50:17,969 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:17,970 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.99972193967551. input_tokens=405, output_tokens=162
12:50:18,202 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:18,203 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.0764656802639365. input_tokens=298, output_tokens=133
12:50:18,269 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:18,270 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.223903817124665. input_tokens=297, output_tokens=138
12:50:18,270 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:50:18,271 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.9206861560232937. input_tokens=1020, output_tokens=181
12:50:18,298 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_summarized_entities.parquet
12:50:18,391 graphrag.index.run INFO Running workflow: join_text_units_to_covariate_ids...
12:50:18,391 graphrag.index.run INFO dependencies for join_text_units_to_covariate_ids: ['create_final_covariates']
12:50:18,391 graphrag.index.run INFO read table from storage: create_final_covariates.parquet
12:50:18,402 datashaper.workflow.workflow INFO executing verb select
12:50:18,407 datashaper.workflow.workflow INFO executing verb aggregate_override
12:50:18,409 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_covariate_ids.parquet
12:50:18,509 graphrag.index.run INFO Running workflow: create_base_entity_graph...
12:50:18,510 graphrag.index.run INFO dependencies for create_base_entity_graph: ['create_summarized_entities']
12:50:18,510 graphrag.index.run INFO read table from storage: create_summarized_entities.parquet
12:50:18,522 datashaper.workflow.workflow INFO executing verb cluster_graph
12:50:18,867 datashaper.workflow.workflow INFO executing verb select
12:50:18,869 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_entity_graph.parquet
12:50:18,976 graphrag.index.run INFO Running workflow: create_final_entities...
12:50:18,977 graphrag.index.run INFO dependencies for create_final_entities: ['create_base_entity_graph']
12:50:18,977 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
12:50:18,995 datashaper.workflow.workflow INFO executing verb unpack_graph
12:50:19,105 datashaper.workflow.workflow INFO executing verb rename
12:50:19,110 datashaper.workflow.workflow INFO executing verb select
12:50:19,116 datashaper.workflow.workflow INFO executing verb dedupe
12:50:19,121 datashaper.workflow.workflow INFO executing verb rename
12:50:19,127 datashaper.workflow.workflow INFO executing verb filter
12:50:19,137 datashaper.workflow.workflow INFO executing verb text_split
12:50:19,146 datashaper.workflow.workflow INFO executing verb drop
12:50:19,153 datashaper.workflow.workflow INFO executing verb merge
12:50:19,207 datashaper.workflow.workflow INFO executing verb text_embed
12:50:19,207 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=http://192.168.0.244:8016/v1
12:50:19,219 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for m3e-large: TPM=0, RPM=0
12:50:19,219 graphrag.index.llm.load_llm INFO create concurrency limiter for m3e-large: 25
12:50:19,240 graphrag.index.verbs.text.embed.strategies.openai INFO embedding 653 inputs via 653 snippets using 41 batches. max_batch_size=16, max_tokens=8191
12:50:24,32 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:24,98 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 4.851988311391324. input_tokens=1076, output_tokens=0
12:50:24,107 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:24,108 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:24,108 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:24,108 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:24,173 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 4.927538990974426. input_tokens=2644, output_tokens=0
12:50:24,238 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 4.994415084831417. input_tokens=2255, output_tokens=0
12:50:24,303 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 5.055829904973507. input_tokens=1387, output_tokens=0
12:50:24,367 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 5.1197409220039845. input_tokens=1361, output_tokens=0
12:50:24,611 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:24,672 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 5.421539661008865. input_tokens=1389, output_tokens=0
12:50:24,681 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:24,682 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:24,682 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:24,682 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:24,682 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:24,682 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:24,683 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:24,683 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:24,683 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:24,683 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:24,683 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:24,684 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:24,684 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:24,684 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:24,684 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:24,685 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:24,767 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 5.5086987731046975. input_tokens=1100, output_tokens=0
12:50:24,833 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 5.58404636522755. input_tokens=1779, output_tokens=0
12:50:24,895 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 5.634878108743578. input_tokens=1536, output_tokens=0
12:50:24,958 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 5.709612464997917. input_tokens=1415, output_tokens=0
12:50:25,21 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 5.762049059849232. input_tokens=1156, output_tokens=0
12:50:25,88 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 5.8331583850085735. input_tokens=1069, output_tokens=0
12:50:25,95 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:25,96 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:25,97 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:25,169 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 5.915413142181933. input_tokens=1507, output_tokens=0
12:50:25,230 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 5.976160680409521. input_tokens=1432, output_tokens=0
12:50:25,294 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 6.033423468936235. input_tokens=697, output_tokens=0
12:50:25,358 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 6.108448856975883. input_tokens=809, output_tokens=0
12:50:25,421 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 6.164696170948446. input_tokens=1173, output_tokens=0
12:50:25,484 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 6.228226157836616. input_tokens=1724, output_tokens=0
12:50:25,546 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 6.288951520808041. input_tokens=1069, output_tokens=0
12:50:25,608 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 6.3556964211165905. input_tokens=1722, output_tokens=0
12:50:25,671 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 6.41121139517054. input_tokens=1700, output_tokens=0
12:50:25,734 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 6.48223170498386. input_tokens=1445, output_tokens=0
12:50:25,818 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.7115928013809025. input_tokens=925, output_tokens=0
12:50:25,830 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:25,831 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:25,888 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 6.625578391365707. input_tokens=736, output_tokens=0
12:50:25,950 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 6.688454085029662. input_tokens=1216, output_tokens=0
12:50:26,23 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.8433353900909424. input_tokens=833, output_tokens=0
12:50:26,31 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:26,87 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 6.82410465599969. input_tokens=676, output_tokens=0
12:50:26,164 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.3910540151409805. input_tokens=826, output_tokens=0
12:50:26,184 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:26,244 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.564855181146413. input_tokens=1075, output_tokens=0
12:50:26,552 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:26,615 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.58569646300748. input_tokens=937, output_tokens=0
12:50:26,737 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:26,738 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:26,739 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:26,741 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:26,741 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:26,742 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:26,798 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.7702145259827375. input_tokens=990, output_tokens=0
12:50:26,862 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 2.552571031730622. input_tokens=1165, output_tokens=0
12:50:26,924 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.6229522502981126. input_tokens=573, output_tokens=0
12:50:26,986 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 2.740617056377232. input_tokens=1020, output_tokens=0
12:50:27,48 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.8097947929054499. input_tokens=631, output_tokens=0
12:50:27,109 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 2.735260335262865. input_tokens=1726, output_tokens=0
12:50:27,598 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:27,599 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:27,600 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:27,603 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:27,648 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.8986711259931326. input_tokens=530, output_tokens=0
12:50:27,655 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/embeddings "HTTP/1.1 200 OK"
12:50:27,712 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 2.6811918560415506. input_tokens=776, output_tokens=0
12:50:27,774 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 2.7445161743089557. input_tokens=525, output_tokens=0
12:50:27,838 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 2.740788308903575. input_tokens=539, output_tokens=0
12:50:27,901 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 2.1520433728583157. input_tokens=565, output_tokens=0
12:50:27,925 datashaper.workflow.workflow INFO executing verb drop
12:50:27,932 datashaper.workflow.workflow INFO executing verb filter
12:50:27,938 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_entities.parquet
12:50:28,85 graphrag.index.run INFO Running workflow: create_final_nodes...
12:50:28,85 graphrag.index.run INFO dependencies for create_final_nodes: ['create_base_entity_graph']
12:50:28,85 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
12:50:28,108 datashaper.workflow.workflow INFO executing verb layout_graph
12:50:28,662 datashaper.workflow.workflow INFO executing verb unpack_graph
12:50:28,866 datashaper.workflow.workflow INFO executing verb unpack_graph
12:50:29,72 datashaper.workflow.workflow INFO executing verb drop
12:50:29,79 datashaper.workflow.workflow INFO executing verb filter
12:50:29,100 datashaper.workflow.workflow INFO executing verb select
12:50:29,107 datashaper.workflow.workflow INFO executing verb rename
12:50:29,115 datashaper.workflow.workflow INFO executing verb join
12:50:29,126 datashaper.workflow.workflow INFO executing verb convert
12:50:29,134 datashaper.workflow.workflow INFO executing verb rename
12:50:29,136 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_nodes.parquet
12:50:29,243 graphrag.index.run INFO Running workflow: create_final_communities...
12:50:29,251 graphrag.index.run INFO dependencies for create_final_communities: ['create_base_entity_graph']
12:50:29,251 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
12:50:29,276 datashaper.workflow.workflow INFO executing verb unpack_graph
12:50:29,391 datashaper.workflow.workflow INFO executing verb unpack_graph
12:50:29,597 datashaper.workflow.workflow INFO executing verb aggregate_override
12:50:29,607 datashaper.workflow.workflow INFO executing verb join
12:50:29,625 datashaper.workflow.workflow INFO executing verb join
12:50:29,643 datashaper.workflow.workflow INFO executing verb concat
12:50:29,652 datashaper.workflow.workflow INFO executing verb filter
12:50:30,12 datashaper.workflow.workflow INFO executing verb aggregate_override
12:50:30,27 datashaper.workflow.workflow INFO executing verb join
12:50:30,39 datashaper.workflow.workflow INFO executing verb filter
12:50:30,51 datashaper.workflow.workflow INFO executing verb fill
12:50:30,60 datashaper.workflow.workflow INFO executing verb merge
12:50:30,78 datashaper.workflow.workflow INFO executing verb copy
12:50:30,88 datashaper.workflow.workflow INFO executing verb select
12:50:30,89 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_communities.parquet
12:50:30,197 graphrag.index.run INFO Running workflow: join_text_units_to_entity_ids...
12:50:30,198 graphrag.index.run INFO dependencies for join_text_units_to_entity_ids: ['create_final_entities']
12:50:30,198 graphrag.index.run INFO read table from storage: create_final_entities.parquet
12:50:30,234 datashaper.workflow.workflow INFO executing verb select
12:50:30,245 datashaper.workflow.workflow INFO executing verb unroll
12:50:30,256 datashaper.workflow.workflow INFO executing verb aggregate_override
12:50:30,269 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_entity_ids.parquet
12:50:30,377 graphrag.index.run INFO Running workflow: create_final_relationships...
12:50:30,377 graphrag.index.run INFO dependencies for create_final_relationships: ['create_final_nodes', 'create_base_entity_graph']
12:50:30,377 graphrag.index.run INFO read table from storage: create_final_nodes.parquet
12:50:30,380 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
12:50:30,407 datashaper.workflow.workflow INFO executing verb unpack_graph
12:50:30,526 datashaper.workflow.workflow INFO executing verb filter
12:50:30,551 datashaper.workflow.workflow INFO executing verb rename
12:50:30,562 datashaper.workflow.workflow INFO executing verb filter
12:50:30,594 datashaper.workflow.workflow INFO executing verb drop
12:50:30,606 datashaper.workflow.workflow INFO executing verb compute_edge_combined_degree
12:50:30,619 datashaper.workflow.workflow INFO executing verb convert
12:50:30,630 datashaper.workflow.workflow INFO executing verb convert
12:50:30,632 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_relationships.parquet
12:50:30,742 graphrag.index.run INFO Running workflow: join_text_units_to_relationship_ids...
12:50:30,743 graphrag.index.run INFO dependencies for join_text_units_to_relationship_ids: ['create_final_relationships']
12:50:30,743 graphrag.index.run INFO read table from storage: create_final_relationships.parquet
12:50:30,768 datashaper.workflow.workflow INFO executing verb select
12:50:30,780 datashaper.workflow.workflow INFO executing verb unroll
12:50:30,793 datashaper.workflow.workflow INFO executing verb aggregate_override
12:50:30,807 datashaper.workflow.workflow INFO executing verb select
12:50:30,808 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_relationship_ids.parquet
12:50:30,925 graphrag.index.run INFO Running workflow: create_final_community_reports...
12:50:30,925 graphrag.index.run INFO dependencies for create_final_community_reports: ['create_final_relationships', 'create_final_nodes', 'create_final_covariates']
12:50:30,925 graphrag.index.run INFO read table from storage: create_final_relationships.parquet
12:50:30,928 graphrag.index.run INFO read table from storage: create_final_nodes.parquet
12:50:30,931 graphrag.index.run INFO read table from storage: create_final_covariates.parquet
12:50:30,957 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
12:50:30,982 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
12:50:31,1 datashaper.workflow.workflow INFO executing verb prepare_community_reports_claims
12:50:31,15 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
12:50:31,33 datashaper.workflow.workflow INFO executing verb prepare_community_reports
12:50:31,33 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=3 => 653
12:50:31,61 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=2 => 653
12:50:31,145 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=1 => 653
12:50:31,261 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 653
12:50:31,350 datashaper.workflow.workflow INFO executing verb create_community_reports
12:51:36,872 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:51:36,873 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI-SEED', 'summary': 'AI-SEEDAIAIAIAIGCVRAI-SEEDAI', 'rating': 8.5, 'rating_explanation': 'AI-SEEDAI', 'findings': [{'summary': '', 'explanation': 'AI-SEEDAI-SEEDAIAIGCAI[records: Relationships (23)]'}, {'summary': 'AI-SEED', 'explanation': 'AI-SEEDAIVRAI-SEEDAIAI[records: Relationships (772, 755, 1055, 1084)]'}, {'summary': 'AI-SEED', 'explanation': 'AI-SEEDAIGCAIAI[records: Relationships (193)]'}, {'summary': '', 'explanation': 'AI-SEEDAIAI[records: Relationships (155, 1084)]'}, {'summary': 'AI-SEED', 'explanation': 'AI-SEEDVRAI-SEEDAIAI[records: Relationships (772, 755, 1055)]'}]}
12:51:36,873 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 65.29442260274664. input_tokens=2336, output_tokens=1112
12:51:51,890 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:51:51,891 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI-SEED', 'summary': 'AI-SEEDAIAIAIAI-SEEDAIAI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'AI-SEED', 'explanation': 'AI-SEEDAIAIAIAIAIAIAI[records: Entities (470, 471, 472, 473, 474, 475), Relationships (1050, 1051, 1052, 1053, 1054, 1056, 1057, 1058, 1059, 1060, 1061, 1062)]'}, {'summary': 'AI-SEED', 'explanation': 'AI-SEEDAI-SEED[records: Relationships (363)]'}, {'summary': '', 'explanation': 'AI-SEEDAI[records: Relationships (566, 567, 568, 569, 570, 571)]'}, {'summary': 'AI-SEED', 'explanation': 'AI-SEEDAI-Seed[records: Relationships (1057)]'}, {'summary': 'AI-SEED', 'explanation': 'AI-SEED[records: Relationships (1052, 1053, 1054, 1058, 1059, 1060, 1061, 1062)]'}]}
12:51:51,891 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 80.30977929476649. input_tokens=3782, output_tokens=1299
12:51:54,431 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:51:54,432 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AI585234AI[records: Entities (289, 293), Relationships (136, 141, 427, 901, 902, 903, 900)]'}, {'summary': 'AI5', 'explanation': 'AI5AI[records: Entities (289, 293), Relationships (136, 141, 427, 901, 902, 903, 900)]'}, {'summary': 'AI8', 'explanation': 'AI8AI[records: Entities (289, 293), Relationships (136, 141, 427, 901, 902, 903, 900)]'}, {'summary': 'AI52', 'explanation': 'AI52AI[records: Entities (289, 293), Relationships (136, 141, 427, 901, 902, 903, 900)]'}, {'summary': 'AI34', 'explanation': 'AI34AI[records: Entities (289, 293), Relationships (136, 141, 427, 901, 902, 903, 900)]'}, {'summary': 'AI11', 'explanation': 'AI11AI[records: Entities (289, 293), Relationships (136, 141, 427, 901, 902, 903, 900)]'}]}
12:51:54,432 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 82.85679402435198. input_tokens=2430, output_tokens=1287
12:52:52,227 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:52:52,227 graphrag.llm.openai.utils INFO success load json in step 1{'title': ' - ', 'summary': 'IP', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': 'AI[records: Entities (463), Relationships (1040, 1041, 1042, 1039)]'}, {'summary': 'IP', 'explanation': 'IP[records: Entities (337), Relationships (1008)]'}, {'summary': '', 'explanation': '[records: Entities (340), Relationships (1014)]'}, {'summary': '', 'explanation': '[records: Entities (556), Relationships (1038)]'}, {'summary': '', 'explanation': '[records: Entities (578), Relationships (1039)]'}]}
12:52:52,228 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 57.779318732209504. input_tokens=5140, output_tokens=1095
12:59:08,682 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:59:08,683 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
12:59:08,683 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title" 	: 	" - " 	,      	"summary" 	: 	"AI" 	,      	"rating" 	: 	8.5 	,      	"rating_explanation" 	: 	"" 	,      	"findings" 	: 	[              	{                      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AI[records: Relationships (1002, 475, 999, 939)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (999, 1000, 1001)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (1000)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AI[records: Relationships (877)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (475)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (1000)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (1000)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AI[records: Relationships (1002, 475, 999, 939)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (999)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AI[records: Relationships (1002, 475, 999, 939)]" 	,      	"findings" 	: 	[              	{                      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AI[records: Relationships (1002, 475, 999, 939)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (999, 1000, 1001)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (1000)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AI[records: Relationships (877)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (475)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (1000)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (1000)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AI[records: Relationships (1002, 475, 999, 939)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (999)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AI[records: Relationships (1002, 475, 999, 939)]" 	,      	"findings" 	: 	[              	{                      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AI[records: Relationships (1002, 475, 999, 939)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (999, 1000, 1001)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (1000)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AI[records: Relationships (877)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (475)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (1000)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (1000)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AI[records: Relationships (1002, 475, 999, 939)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (999)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AI[records: Relationships (1002, 475, 999, 939)]" 	,      	"findings" 	: 	[              	{                      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AI[records: Relationships (1002, 475, 999, 939)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (999, 1000, 1001)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (1000)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AI[records: Relationships (877)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (475)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (1000)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (1000)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AI[records: Relationships (1002, 475, 999, 939)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (999)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AI[records: Relationships (1002, 475, 999, 939)]" 	,      	"findings" 	: 	[              	{                      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AI[records: Relationships (1002, 475, 999, 939)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (999, 1000, 1001)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (1000)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AI[records: Relationships (877)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (475)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (1000)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (1000)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AI[records: Relationships (1002, 475, 999, 939)]" 	,              	"summary" 	: 	"
12:59:08,686 graphrag.llm.openai.utils INFO success load json in step 3{'title': ' - ', 'summary': 'AI', 'rating': 8.5, 'rating_explanation': '', 'findings': [{'summary': '', 'explanation': 'AI[records: Relationships (1002, 475, 999, 939)]', 'findings': [{'summary': '', 'explanation': 'AI[records: Relationships (1002, 475, 999, 939)]', 'findings': [{'summary': '', 'explanation': 'AI[records: Relationships (1002, 475, 999, 939)]', 'findings': [{'summary': '', 'explanation': 'AI[records: Relationships (1002, 475, 999, 939)]', 'findings': [{'summary': '', 'explanation': 'AI[records: Relationships (1002, 475, 999, 939)]'}]}]}]}]}]}
12:59:08,687 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 451.79789943108335. input_tokens=2453, output_tokens=2496
12:59:30,706 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
12:59:30,706 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
12:59:30,706 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title" 	: 	" - " 	,      	"summary" 	: 	"AI" 	,      	"rating" 	: 	8.5 	,      	"rating_explanation" 	: 	"AI" 	,      	"findings" 	: 	[              	{                  	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Entities (342), Relationships (1017, 481, 896, 999, 1003, 1009, 1006, 1013, 990, 991, 986, 988, 989, 1012, 987, 1016)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (1016)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (999)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (1009)]" 	,              	"summary" 	: 	"IP" 	,                  	"explanation" 	: 	"IPIPIP[records: Relationships (1006)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (1017)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (481)]" 	,              	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAIAI[records: Relationships (896)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (990)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (991)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (986)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (988)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (989)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (1012)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (987)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (1016)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (481)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAIAI[records: Relationships (896)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (990)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (991)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (986)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (988)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (989)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (1012)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (987)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (1016)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (1017)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (481)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAIAI[records: Relationships (896)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (990)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (991)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (986)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (988)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (989)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (1012)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (987)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (1016)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (1017)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (481)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAIAI[records: Relationships (896)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (990)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (991)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (986)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (988)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (989)]" 	,      	"summary" 	: 	"
12:59:30,709 graphrag.llm.openai.utils INFO success load json in step 3{'title': ' - ', 'summary': 'AI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': 'AI[records: Relationships (989)]'}]}
12:59:30,709 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 458.80241028312594. input_tokens=2755, output_tokens=946
13:00:41,910 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
13:00:41,910 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': '60', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'AI', 'explanation': '60[records: Entities (245, 4), Relationships (173, 40, 3, 854, 39, 32, 35, 38, 41)]'}, {'summary': 'AI', 'explanation': 'AI5AI[records: Relationships (40, 3, 39, 41)]'}, {'summary': 'AI', 'explanation': 'AIAI[records: Relationships (32)]'}, {'summary': 'AI', 'explanation': 'AIAI[records: Relationships (35)]'}, {'summary': 'AI', 'explanation': 'AIAI[records: Relationships (38)]'}]}
13:00:41,911 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 71.186712061055. input_tokens=2512, output_tokens=1159
13:00:48,640 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
13:00:48,641 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
13:00:48,641 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title" 	: 	"AI - " 	,      	"summary" 	: 	"AIAIAIAI" 	,      	"rating" 	: 	8.5 	,      	"rating_explanation" 	: 	"AIAI" 	,      	"findings" 	: 	[          	{              	"summary" 	: 	"AI" 	,              	"explanation" 	: 	"AIAI[records: Relationships (118, 455)]" 	,              	"data_records" 	: 	[                  	{                      	"source" 	: 	"Relationships" 	,                      	"ids" 	: 	[118, 455] 	,                      	"reference" 	: 	"AIAIAIAI" 	,                  	"source" 	: 	"Entities" 	,                  	"ids" 	: 	[66, 448, 444, 446, 447] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Relationships" 	,                  	"ids" 	: 	[456, 465, 461, 463, 464] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Entities" 	,                  	"ids" 	: 	[66, 448, 444, 446, 447] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Relationships" 	,                  	"ids" 	: 	[456, 465, 461, 463, 464] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Entities" 	,                  	"ids" 	: 	[66, 448, 444, 446, 447] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Relationships" 	,                  	"ids" 	: 	[456, 465, 461, 463, 464] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Entities" 	,                  	"ids" 	: 	[66, 448, 444, 446, 447] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Relationships" 	,                  	"ids" 	: 	[456, 465, 461, 463, 464] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Entities" 	,                  	"ids" 	: 	[66, 448, 444, 446, 447] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Relationships" 	,                  	"ids" 	: 	[456, 465, 461, 463, 464] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Entities" 	,                  	"ids" 	: 	[66, 448, 444, 446, 447] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Relationships" 	,                  	"ids" 	: 	[456, 465, 461, 463, 464] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Entities" 	,                  	"ids" 	: 	[66, 448, 444, 446, 447] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Relationships" 	,                  	"ids" 	: 	[456, 465, 461, 463, 464] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Entities" 	,                  	"ids" 	: 	[66, 448, 444, 446, 447] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Relationships" 	,                  	"ids" 	: 	[456, 465, 461, 463, 464] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Entities" 	,                  	"ids" 	: 	[66, 448, 444, 446, 447] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Relationships" 	,                  	"ids" 	: 	[456, 465, 461, 463, 464] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Entities" 	,                  	"ids" 	: 	[66, 448, 444, 446, 447] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Relationships" 	,                  	"ids" 	: 	[456, 465, 461, 463, 464] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Entities" 	,                  	"ids" 	: 	[66, 448, 444, 446, 447] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Relationships" 	,                  	"ids" 	: 	[456, 465, 461, 463, 464] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Entities" 	,                  	"ids" 	: 	[66, 448, 444, 446, 447] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Relationships" 	,                  	"ids" 	: 	[456, 465, 461, 463, 464] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Entities" 	,                  	"ids" 	: 	[66, 448, 444, 446, 447] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Relationships" 	,                  	"ids" 	: 	[456, 465, 461, 463, 464] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Entities" 	,                  	"ids" 	: 	[66, 448, 444, 446, 447] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Relationships" 	,                  	"ids" 	: 	[456, 465, 461, 463, 464] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Entities" 	,                  	"ids" 	: 	[66, 448, 444, 446, 447] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Relationships" 	,                  	"ids" 	: 	[456, 465, 461, 463, 464] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Entities" 	,                  	"ids" 	: 	[66, 448, 444, 446, 447] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Relationships" 	,                  	"ids" 	: 	[456, 465, 461, 463, 464] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Entities" 	,                  	"ids" 	: 	[66, 448, 444, 446, 447] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Relationships" 	,                  	"ids" 	: 	[456, 465, 461, 463, 464] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Entities" 	,                  	"ids" 	: 	[66, 448, 444, 446, 447] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Relationships" 	,                  	"ids" 	: 	[456, 465, 461, 463, 464] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Entities" 	,                  	"ids" 	: 	[66, 448, 444, 446, 447] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Relationships" 	,                  	"ids" 	: 	[456, 465, 461, 463, 464] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Entities" 	,                  	"ids" 	: 	[66, 448, 444, 446, 447] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Relationships" 	,                  	"ids" 	: 	[456, 465, 461, 463, 464] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Entities" 	,                  	"ids" 	: 	[66, 448, 444, 446, 447] 	,                  	"reference" 	: 	"" 	,                  	"source" 	: 	"Relationships" 	,                  	"ids" 	: 	[456, 465, 461, 463, 464] 	,                  	"reference" 	: 	"" 	,                  	"source" 	:
13:00:48,643 graphrag.llm.openai.utils INFO success load json in step 3{'title': 'AI - ', 'summary': 'AIAIAIAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AIAI[records: Relationships (118, 455)]', 'data_records': [{'source': '', 'ids': [456, 465, 461, 463, 464], 'reference': ''}]}]}
13:00:48,644 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 476.40076612168923. input_tokens=3669, output_tokens=1368
13:04:32,728 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
13:04:32,729 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
13:04:32,729 graphrag.llm.openai.utils INFO success load json in step 2{'title': 'AI', 'summary': 'AIAIAIAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AIAIAIAI[records: Relationships (64, 109, 114, 115, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 3, 31, 37 30, 3, 3, 3399, 37, 33701, 370,  ] ... ...  ]]', ']...]summary] ]]': ']]'}], ']]': ']...)...]...]]'}
13:04:32,730 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 230.80221790028736. input_tokens=9818, output_tokens=1774
13:04:56,915 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
13:04:56,916 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
13:04:56,916 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title" 	: 	"" 	,      	"summary" 	: 	"AI" 	,      	"rating" 	: 	8.5 	,      	"rating_explanation" 	: 	"AI" 	,      	"findings" 	: 	[              	{                  	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAIAI[records: Entities (70, 355), Relationships (122, 119)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Entities (82, 449, 445, 580), Relationships (356, 355, 517, 460, 467, 462, 492, 483, 458, 516, 493, 494, 497, 498, 499, 490, 485, 495, 496, 1023, 1021, 518)]" 	,              	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AI[records: Entities (449), Relationships (467, 460, 1023)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Entities (445), Relationships (462, 494, 1021)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Entities (580), Relationships (518)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Entities (70, 458)]" 	,              	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAI[records: Entities (516), Relationships (467, 460, 492, 483, 458, 493, 494, 497, 498, 499, 490, 485, 495, 496, 1023, 1021, 518)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Entities (70, 493, 494), Relationships (493, 494, 497, 498, 499, 490, 485, 495, 496)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Entities (70, 497), Relationships (497, 498, 499, 490, 485, 495, 496)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Entities (70, 498), Relationships (497, 498, 499, 490, 485, 495, 496)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Entities (70, 499), Relationships (497, 498, 499, 490, 485, 495, 496)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Entities (580, 485), Relationships (485, 495, 496)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Entities (82, 449, 445, 580), Relationships (356, 355, 517, 460, 467, 462, 492, 483, 458, 516, 493, 494, 497, 498, 499, 490, 485, 495, 496, 1023, 1021, 518)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAI[records: Entities (82, 449, 445, 580), Relationships (356, 355, 517, 460, 467, 462, 492, 483, 458, 516, 493, 494, 497, 498, 499, 490, 485, 495, 496, 1023, 1021, 518)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Entities (70, 497, 498, 499, 490, 485, 495, 496), Relationships (497, 498, 499, 490, 485, 495, 496)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Entities (580), Relationships (518)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Entities (82, 449, 445, 580), Relationships (356, 355, 517, 460, 467, 462, 492, 483, 458, 516, 493, 494, 497, 498, 499, 490, 485, 495, 496, 1023, 1021, 518)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Entities (82, 449, 445, 580), Relationships (356, 355, 517, 460, 467, 462, 492, 483, 458, 516, 493, 494, 497, 498, 499, 490, 485, 495, 496, 1023, 1021, 518)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Entities (70, 458)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAI[records: Entities (82, 449, 445, 580), Relationships (356, 355, 517, 460, 467, 462, 492, 483, 458, 516, 493, 494, 497, 498, 499, 490, 485, 495, 496, 1023, 1021, 518)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Entities (70, 497, 498, 499, 490, 485, 495, 496), Relationships (497, 498, 499, 490, 485, 495, 496)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Entities (580), Relationships (518)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Entities (82, 449, 445, 580), Relationships (356, 355, 517, 460, 467, 462, 492, 483, 458, 516, 493, 494, 497, 498, 499, 490, 485, 495, 496, 1023, 1021, 518)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Entities (82, 449, 445, 580), Relationships (356, 355, 517, 460, 467, 462, 492, 483, 458, 516, 493, 494, 497, 498, 499, 490, 485, 495, 496, 1023, 1021, 518)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Entities (70, 458)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAI[records: Entities (82, 449, 445, 580), Relationships (356, 355, 517, 460, 467, 462, 492, 483, 458, 516, 493, 494, 497, 498, 499, 490, 485, 495, 496, 1023, 1021, 518)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Entities (70, 497, 498, 499, 490, 485, 495, 496), Relationships (497, 498, 499, 490, 485, 495, 496)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Entities (580), Relationships (518)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Entities (82, 449, 445, 580), Relationships (356, 355, 517, 460, 467, 462, 492, 483, 458, 516, 493, 494, 497, 498, 499, 490, 485, 495, 496, 1023, 1021, 518)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Entities (82, 449, 445, 580), Relationships (356, 355, 517, 460, 467, 462, 492, 483, 458, 516, 493, 494, 497, 498, 499, 490, 485, 495, 496, 1023, 1021, 518)]" 	,
13:04:56,919 graphrag.llm.openai.utils INFO success load json in step 3{'title': '', 'summary': 'AI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': 'AI[records: Entities (82, 449, 445, 580), Relationships (356, 355, 517, 460, 467, 462, 492, 483, 458, 516, 493, 494, 497, 498, 499, 490, 485, 495, 496, 1023, 1021, 518)]'}]}
13:04:56,919 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 348.2153835189529. input_tokens=3549, output_tokens=1170
13:05:59,180 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
13:05:59,181 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': '985985', 'rating': 8.5, 'rating_explanation': '', 'findings': [{'summary': '985', 'explanation': '985[records: Entities (55, 79), Relationships (79, 272)]'}, {'summary': '', 'explanation': '985[records: Relationships (443)]'}, {'summary': '985', 'explanation': '985[records: Relationships (79, 272, 443)]'}, {'summary': '', 'explanation': '985[records: Entities (55, 79), Relationships (79, 272)]'}, {'summary': '', 'explanation': '[records: Relationships (443)]'}]}
13:05:59,181 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 62.00553639000282. input_tokens=2061, output_tokens=1068
13:06:21,105 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
13:06:21,105 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'AI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'AI', 'explanation': 'AIAI[records: Entities (19), Relationships (57, 367, 369, 370, 371, 372, 373, 374, 368, 270)]'}, {'summary': 'AI', 'explanation': 'AIAR[records: Entities (27), Relationships (61, 222, 223, 388, 390, 387, 389, 396, 394)]'}, {'summary': 'AI', 'explanation': 'AIAIAI[records: Entities (28), Relationships (62, 391, 393, 381, 383, 384, 386, 396, 394)]'}, {'summary': 'AI', 'explanation': 'AI[records: Entities (25), Relationships (59, 222, 223, 382, 383, 384, 386, 396, 394)]'}, {'summary': 'AI', 'explanation': 'AI[records: Entities (26), Relationships (60, 222, 223, 385, 386, 384, 386, 396, 394)]'}]}
13:06:21,106 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 83.93305959366262. input_tokens=4703, output_tokens=1351
13:07:34,424 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
13:07:34,424 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'AIAIGCAIAI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': 'AIAI[records: Entities (9, 267, 268, 269, 270), Relationships (50, 204, 205, 206, 209, 212, 215, 861, 862, 863, 864, 865, 866)]'}, {'summary': '', 'explanation': 'AIAIAI[records: Entities (267), Relationships (315, 316, 317, 318)]'}, {'summary': 'AI', 'explanation': 'AIAIAIAIAIAI[records: Entities (269), Relationships (317)]'}, {'summary': 'AIGC', 'explanation': 'AIGCAIAIGCAIGCAI[records: Entities (270), Relationships (318)]'}, {'summary': 'AI', 'explanation': 'AIAIAIAIAI[records: Entities (268), Relationships (316)]'}]}
13:07:34,425 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 73.30283354315907. input_tokens=3283, output_tokens=1409
13:13:10,582 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
13:13:10,582 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
13:13:10,582 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title" 	: 	" - " 	,      	"summary" 	: 	"AIAIAI" 	,      	"rating" 	: 	8.5 	,      	"rating_explanation" 	: 	"AI" 	,      	"findings" 	: 	[              	{                  	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AIAIAIAI[records: Entities (14, 216), Relationships (216, 217, 218)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (221)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (224)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (222)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (223)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (225)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (226)]" 	,              	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAIAIAI[records: Relationships (219)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (12, 216)]" 	,              	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAIAIAI[records: Relationships (55, 216)]" 	,          	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (218)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AIAI[records: Entities (14, 216)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AIAI[records: Relationships (221, 222, 223, 224, 225, 226)]" 	,      	"summary" 	: 	"AIAI" 	,                  	"explanation" 	: 	"AIAIAIAI[records: Entities (14, 216), Relationships (55, 216)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AIAI[records: Relationships (221, 222, 223, 224, 225, 226)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAIAIAI[records: Relationships (219)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (12, 216)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAIAI[records: Entities (14, 216), Relationships (55, 216)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AIAI[records: Relationships (221, 222, 223, 224, 225, 226)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAIAIAI[records: Relationships (219)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (12, 216)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAIAI[records: Entities (14, 216), Relationships (55, 216)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AIAI[records: Relationships (221, 222, 223, 224, 225, 226)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAIAIAI[records: Relationships (219)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (12, 216)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAIAI[records: Entities (14, 216), Relationships (55, 216)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AIAI[records: Relationships (221, 222, 223, 224, 225, 226)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAIAIAI[records: Relationships (219)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (12, 216)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAIAI[records: Entities (14, 216), Relationships (55, 216)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AIAI[records: Relationships (221, 222, 223, 224, 225, 226)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAIAIAI[records: Relationships (219)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (12, 216)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAIAI[records: Entities (14, 216), Relationships (55, 216)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AIAI[records: Relationships (221, 222, 223, 224, 225, 226)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAIAIAI[records: Relationships (219)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (12, 216)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAIAI[records: Entities (14, 216), Relationships (55, 216)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AIAI[records: Relationships (221, 222, 223, 224, 225, 226)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAIAIAI[records: Relationships (219)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (12, 216)]" 	,      	"summary" 	: 	"
13:13:10,585 graphrag.llm.openai.utils INFO success load json in step 3{'title': ' - ', 'summary': 'AIAIAI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': 'AI[records: Relationships (12, 216)]'}]}
13:13:10,585 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 493.41539026703686. input_tokens=2583, output_tokens=978
13:14:33,109 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
13:14:33,110 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
13:14:33,110 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title" 	: 	"" 	,      	"summary" 	: 	"CGAI" 	,      	"rating" 	: 	8.5 	,      	"rating_explanation" 	: 	"" 	,      	"findings" 	: 	[              	{                  	"summary" 	: 	"CGAI" 	,                  	"explanation" 	: 	"CGCGAI[records: Entities (56), Relationships (80)]" 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (80)" 	: 	[                  	"56,CG,CG,3" 	,                  	"80,AI,CG,AICG,152" 	] 	,              	"records: Entities (56), Relationships (
13:14:33,113 graphrag.llm.openai.utils INFO success load json in step 3{'title': '', 'summary': 'CGAI', 'rating': 8.5, 'rating_explanation': '', 'findings': [{'summary': 'CGAI', 'explanation': 'CGCGAI[records: Entities (56), Relationships (80)]', 'records: Entities (56), Relationships (80)': ['56,CG,CG,3', '80,AI,CG,AICG,152']}]}
13:14:33,114 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 513.9174517621286. input_tokens=2695, output_tokens=1217
13:14:49,647 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
13:14:49,647 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIAIAIAIGCAIAIAIAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AIAIAIAIGCAIAIAIAIAI[records: Entities (173, 488, 508, 641, 581, 642, 643, 644), Relationships (773, 291, 777, 774, 778, 779, 780, 781, 782)]'}, {'summary': 'AI', 'explanation': 'AIAIAIAIAI[records: Entities (488, 508), Relationships (776, 774, 778, 779, 780, 781, 782)]'}, {'summary': 'AI', 'explanation': 'AIAIGCAIAIAI[records: Entities (641), Relationships (777)]'}, {'summary': 'AI', 'explanation': 'AIAI[records: Entities (643), Relationships (781)]'}, {'summary': 'AI', 'explanation': 'AIAIAI[records: Entities (644), Relationships (782)]'}]}
13:14:49,648 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 99.04651241702959. input_tokens=3506, output_tokens=1181
13:15:48,383 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
13:15:48,383 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AIGC', 'summary': 'AIGCAIGCAIAI', 'rating': 7.5, 'rating_explanation': '', 'findings': [{'summary': 'AIGC', 'explanation': 'AIGCAIAI[records: Entities (63), Relationships (292)]'}, {'summary': '', 'explanation': 'AIGC[records: Entities (62, 60), Relationships (448, 447, 449)]'}, {'summary': 'AIGCAI', 'explanation': 'AIAIGCAI[records: Relationships (451)]'}, {'summary': '', 'explanation': '985CG[records: Entities (60)]'}, {'summary': '', 'explanation': '[records: Relationships (448)]'}]}
13:15:48,385 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 75.25025060586631. input_tokens=2441, output_tokens=1138
13:16:52,152 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
13:16:52,153 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
13:16:52,153 graphrag.llm.openai.utils INFO Error: JSONDecodeError
13:16:52,153 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
13:17:21,360 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
13:17:21,360 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI-SEED', 'summary': 'AI-SEEDAI-SEEDAIAIAIGCAI-SEEDAI-SEEDAIAI', 'rating': 8.5, 'rating_explanation': 'AI-SEEDAI', 'findings': [{'summary': 'AI-SEED', 'explanation': 'AI-SEEDAIAIAIAIGCAI[records: Entities (500), Relationships (155, 20, 1058, 1059, 1060, 1056, 1057, 1050, 1051, 1052, 1053, 1054, 1058, 1059, 1060, 1056, 1057, 1050, 1051, 1052, 1053, 1054)]'}, {'summary': 'AI-SEED', 'explanation': 'AI-SEEDAIAIAIAI-SEEDAI[records: Entities (470), Relationships (363, 190, 1047, 1048, 1049, 1052, 1053, 1054, 1058, 1059, 1060, 1056, 1057, 1050, 1051, 1052, 1053, 1054)]'}, {'summary': '', 'explanation': 'AI-Seed[records: Entities (473, 474, 475), Relationships (1052, 1053, 1054, 1058, 1059, 1060, 1056, 1057, 1050, 1051, 1052, 1053, 1054)]'}, {'summary': 'AI', 'explanation': 'AI-SeedAIAIAI-SeedAIAIAI[records: Entities (471, 472), Relationships (1050, 1051, 1052, 1053, 1054, 1056, 1057, 1058, 1059, 1060, 1056, 1057, 1050, 1051, 1052, 1053, 1054)]'}, {'summary': 'AI-SEED', 'explanation': 'AI-SEEDAI-SeedAI-Seed[records: Entities (513, 649), Relationships (1057, 1056, 1058, 1059, 1060, 1056, 1057, 1050, 1051, 1052, 1053, 1054)]'}]}
13:17:21,361 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 151.6975146313198. input_tokens=4165, output_tokens=1486
13:19:02,429 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
13:19:02,429 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIAIAIAIAIAI-SeedAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AIAIAIAIAIAIAIAI[records: Entities (511, 584, 507)]'}, {'summary': '', 'explanation': 'AIAIAIAI[records: Relationships (1032, 1087)]'}, {'summary': 'AI-Seed', 'explanation': 'AIAI-SeedAIAI-SeedAIAIAIAI[records: Relationships (1048)]'}, {'summary': '', 'explanation': 'AIAIAIAI[records: Relationships (1086)]'}, {'summary': '', 'explanation': 'AIAIAIAIAI[records: Entities (511, 507)]'}]}
13:19:02,430 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 101.05401936685666. input_tokens=2334, output_tokens=1038
13:21:09,946 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
13:21:09,946 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI-Seed', 'summary': 'AI-SeedAIAIAI', 'rating': 8.5, 'rating_explanation': 'AI-SeedAI', 'findings': [{'summary': 'AI-Seed', 'explanation': 'AI-SeedAIAIAIAIAIAIAIAIAI[records: Entities (482, 502, 483, 484, 485)]'}, {'summary': 'AI-Seed', 'explanation': 'AI-SeedAI-SeedAI[records: Relationships (261, 1061, 1062, 1063, 1064, 1065, 1058, 1069, 1083, 1070, 1071, 1072)]'}, {'summary': 'AI', 'explanation': 'AIAI-SeedAIAIAI[records: Entities (502)]'}, {'summary': 'AI', 'explanation': 'AIGCAIAI-SeedAIAI[records: Entities (485)]'}, {'summary': 'AIGCAI-Seed', 'explanation': 'AIGCAI-SeedAI[records: Relationships (187, 1070, 1071, 1072)]'}]}
13:21:09,947 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 127.50168453296646. input_tokens=2741, output_tokens=1391
13:26:46,625 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
13:26:46,625 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
13:26:46,626 graphrag.llm.openai.utils INFO Error: JSONDecodeError
13:26:46,626 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
13:28:13,306 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
13:28:13,307 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
13:28:13,307 graphrag.llm.openai.utils INFO Error: JSONDecodeError
13:28:13,307 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
13:28:54,149 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
13:28:54,150 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
13:28:54,150 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title"   	: 	"AIGC" 	,      	"summary" 	: 	"AIGCAIGCAIGCAI" 	,      	"rating" 	: 	8.5 	,      	"rating_explanation" 	: 	"AIGCAI" 	,      	"findings" 	: 	[          	{              	"summary" 	: 	"" 	,              	"explanation" 	: 	"[records: Entities (85, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 	]" 	    	 	 	       	 	 	 	 	       	    	    	 	 	       	          	   , 	 	       	   "]   ]" 	 	 	      	 	   	 		   	 	 	 	 	               	 	 	 	 	 	 	 	 	   		 	                                	                                   	   		 	 	                                                           	                                                                               	 	                                                                                     	 	 	 	 	 	 	 	                                                         	 	                                                                       	 	 	 	               	 	 	 	 	 	 	 	 	               	                             	 	 	 	 	                               		 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	                                                         	 	 	 	 	 	                             	 	 	                     	 	             	 	 	 	 	 	 	 	 	 	 	                  	 	 	 	 	 	               	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	                      	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 		 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	    	    	 	               	            	                  		 	 	 	 	 	 	 	 	 	 	    	 	 	 	       	    		: 	"]... 	]" 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 , 	 		 	"] records<tool_call> ]   ...... records<tool_call><tool_call> ,<tool_call> , 	],"             	                        			 	 	 	 	 	 	 	    	 	 	 	 	 	 	 	 	 	 		             	 	 	 	 	 	 				 	           									 	 	 	 	 	 	 	               	 	 	 		 	 		 	 	 	 	 	 	 	 			 		 	 	 	 	 			            		 	 			 	 		 		   			 	 	 	 	 	 	 	 	 	               	 		                                            		 	 	 	 		 	 		 	 	 	 	 								      		    					 			 		 										                			 	 	 	 					 	 	 	 	              						 		:"] NONE ......   ...    NONE NONE 	]" 	 				 		 		 				 			 	 											                 	 	 	 		 		 	            				 	 		 			 	 									          				 	   } 	] 	 	    	}
13:28:54,151 graphrag.llm.openai.utils INFO success load json in step 3{'title': 'AIGC', 'summary': 'AIGCAIGCAIGCAI', 'rating': 8.5, 'rating_explanation': 'AIGCAI', 'findings': [{'summary': '', 'explanation': '[records: Entities (85, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, \t]', ']   ]': ']... \t]', '] records<tool_call> ]   ...... records<tool_call><tool_call> ,<tool_call> , \t],': '] NONE ......   ...    NONE NONE \t]'}]}
13:28:54,152 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 464.1879392871633. input_tokens=9699, output_tokens=2622
13:30:34,264 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
13:30:34,265 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'VR', 'rating': 8.0, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': '[records: Entities (454), Relationships (555, 761, 1028)]'}, {'summary': '', 'explanation': '[records: Relationships (555)]'}, {'summary': 'VR', 'explanation': 'VRVR[records: Relationships (761)]'}, {'summary': '', 'explanation': '[records: Relationships (882, 1028)]'}, {'summary': '', 'explanation': '[records: Relationships (555)]'}]}
13:30:34,265 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 100.09863805910572. input_tokens=2286, output_tokens=1088
13:32:59,170 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
13:32:59,171 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': '', 'rating': 8.0, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': '[records: Entities (118, 462, 119, 97, 1035, 649, 648, 650, 578), Relationships (342, 537, 538, 542, 532, 582, 583, 1035, 649, 648, 650, 578)]'}, {'summary': '', 'explanation': '[records: Relationships (537, 538, 542, 532, 582, 583)]'}, {'summary': '', 'explanation': '[records: Relationships (542, 583)]'}, {'summary': '', 'explanation': '[records: Relationships (532, 578)]'}, {'summary': '', 'explanation': '[records: Relationships (1035, 649, 648, 650, 578)]'}]}
13:32:59,172 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 144.890900332015. input_tokens=3554, output_tokens=1567
13:35:36,161 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
13:35:36,162 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'VR', 'summary': 'VRVRAI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'VR', 'explanation': 'VRVRVRAIVRAIGCAI[records: Entities (170, 627, 587, 628, 762, 763, 764, 765, 766, 767, 768, 770, 771, 772, 760, 761, 769, 757, 758, 759, 769)]'}, {'summary': '', 'explanation': 'VRVRVR[records: Entities (169, 25, 757, 758, 759)]'}, {'summary': '', 'explanation': 'VR[records: Entities (594, 628, 769, 758, 759)]'}, {'summary': 'VRAIGC', 'explanation': 'VRAIGCAIGCVRVRAIGC[records: Entities (763, 764)]'}, {'summary': 'VR', 'explanation': 'VRVR[records: Entities (594, 762)]'}]}
13:35:36,162 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 156.97493622312322. input_tokens=3728, output_tokens=1311
13:40:52,372 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
13:40:52,373 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
13:40:52,373 graphrag.llm.openai.utils INFO Error: JSONDecodeError
13:40:52,373 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
13:42:38,442 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
13:42:38,443 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
13:42:38,443 graphrag.llm.openai.utils INFO Error: JSONDecodeError
13:42:38,443 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
13:53:16,701 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
13:53:16,702 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
13:53:16,702 graphrag.llm.openai.utils INFO Error: JSONDecodeError
13:53:16,702 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
13:58:39,925 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
13:58:39,925 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
13:58:39,926 graphrag.llm.openai.utils INFO Error: JSONDecodeError
13:58:39,926 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
14:00:16,889 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
14:00:16,890 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
14:00:16,890 graphrag.llm.openai.utils INFO Error: JSONDecodeError
14:00:16,890 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
14:00:16,890 graphrag.index.graph.extractors.community_reports.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/index/graph/extractors/community_reports/community_reports_extractor.py", line 58, in __call__
    await self._llm(
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/base_llm.py", line 48, in __call__
    return await self._invoke_json(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_chat_llm.py", line 90, in _invoke_json
    raise RuntimeError(error_msg)
RuntimeError: Failed to generate valid JSON output - Faulty JSON: {}
14:00:16,890 graphrag.index.reporting.file_workflow_callbacks INFO Community Report Extraction Error details=None
14:00:16,891 graphrag.index.verbs.graph.report.strategies.graph_intelligence.run_graph_intelligence WARNING No report found for community: 72
14:09:02,958 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
14:09:02,959 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
14:09:02,959 graphrag.llm.openai.utils INFO Error: JSONDecodeError
14:09:02,959 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
14:13:08,660 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
14:13:08,661 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
14:13:08,661 graphrag.llm.openai.utils INFO Error: JSONDecodeError
14:13:08,661 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
14:13:08,661 graphrag.index.graph.extractors.community_reports.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/index/graph/extractors/community_reports/community_reports_extractor.py", line 58, in __call__
    await self._llm(
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/base_llm.py", line 48, in __call__
    return await self._invoke_json(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_chat_llm.py", line 90, in _invoke_json
    raise RuntimeError(error_msg)
RuntimeError: Failed to generate valid JSON output - Faulty JSON: {}
14:13:08,661 graphrag.index.reporting.file_workflow_callbacks INFO Community Report Extraction Error details=None
14:13:08,661 graphrag.index.verbs.graph.report.strategies.graph_intelligence.run_graph_intelligence WARNING No report found for community: 76
14:14:10,795 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
14:14:10,796 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
14:14:10,796 graphrag.llm.openai.utils INFO Error: JSONDecodeError
14:14:10,796 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
14:19:56,209 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
14:19:56,210 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
14:19:56,210 graphrag.llm.openai.utils INFO Error: JSONDecodeError
14:19:56,210 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
14:23:59,490 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
14:23:59,490 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
14:23:59,490 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title" 	: 	" - " 	,      	"summary" 	: 	"IP" 	,      	"rating" 	: 	8.5 	,      	"rating_explanation" 	: 	"AI" 	,      	"findings" 	: 	[          	{              	"summary" 	: 	"" 	,              	"explanation" 	: 	"AIAI[records: Entities (463, 342, 335, 337, 340, 556, 578, 577, 329, 341, 538, 569, 571, 622, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573,  records records records records records records    records records    records],    records records records records records records], NONE records records records, NONE records records records records, NONE records records records    NONE records records records records records records       NONE records records records records] 	]" 	                                               	         , 	                                   	                  	                  	              "] NONE records records records]"
14:23:59,491 graphrag.llm.openai.utils INFO success load json in step 3{'title': ' - ', 'summary': 'IP', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': 'AIAI[records: Entities (463, 342, 335, 337, 340, 556, 578, 577, 329, 341, 538, 569, 571, 622, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573,  records records records records records records    records records    records],    records records records records records records], NONE records records records, NONE records records records records, NONE records records records    NONE records records records records records records       NONE records records records records] \t]'}]}
14:23:59,492 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 650.8146147350781. input_tokens=6326, output_tokens=3348
14:25:04,609 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
14:25:04,610 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
14:25:04,610 graphrag.llm.openai.utils INFO Error: JSONDecodeError
14:25:04,610 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
14:31:18,173 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
14:31:18,173 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
14:31:18,173 graphrag.llm.openai.utils INFO Error: JSONDecodeError
14:31:18,173 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
14:31:18,173 graphrag.index.graph.extractors.community_reports.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/index/graph/extractors/community_reports/community_reports_extractor.py", line 58, in __call__
    await self._llm(
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/base_llm.py", line 48, in __call__
    return await self._invoke_json(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_chat_llm.py", line 90, in _invoke_json
    raise RuntimeError(error_msg)
RuntimeError: Failed to generate valid JSON output - Faulty JSON: {}
14:31:18,174 graphrag.index.reporting.file_workflow_callbacks INFO Community Report Extraction Error details=None
14:31:18,174 graphrag.index.verbs.graph.report.strategies.graph_intelligence.run_graph_intelligence WARNING No report found for community: 83
14:33:51,490 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
14:33:51,490 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
14:33:51,490 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title" 	: 	" - " 	,      	"summary" 	: 	"" 	,      	"rating" 	: 	8.5 	,      	"rating_explanation" 	: 	"" 	,      	"findings" 	: 	[              	{                  	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Entities (336, 570), Relationships (1005, 476, 878, 1003, 994, 941, 1004)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (476, 1004)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (994)]" 	,              	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAI[records: Relationships (941)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (878)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (1003)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AIAIGC[records: Relationships (1005, 878)]" 	,          	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (941, 878)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (1005, 476, 878, 1003, 994, 941, 1004)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (1005, 476, 878, 1003, 994, 941, 1004)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (1005, 476, 878, 1003, 994, 941, 1004)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (1005, 476, 878, 1003, 994, 941, 1004)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (1005, 476, 878, 1003, 994, 941, 1004)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Relationships (1005, 476, 878, 1003, 994, 941, 1004)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (1005, 476, 878, 1003, 994, 941, 1004)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (1005, 476, 878, 1003, 994, 941, 1004)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (1005, 476, 878, 1003, 994, 941, 1004)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (1005, 476, 878, 1003, 994, 941, 1004)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (1005, 476, 878, 1003, 994, 941, 1004)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (1005, 476, 878, 1003, 994, 941, 1004)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (1005, 476, 878, 1003, 994, 941, 1004)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (1005, 476, 878, 1003, 994, 941, 1004)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (1005, 476, 878, 1003, 994, 941, 1004)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (1005, 476, 878, 1003, 994, 941, 1004)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (1005, 476, 878, 1003, 994, 941, 1004)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (1005, 476, 878, 1003, 994, 941, 1004)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (1005, 476, 878, 1003, 994, 941, 1004)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (1005, 476, 878, 1003, 994, 941, 1004)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (1005, 476, 878, 1003, 994, 941, 1004)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (1005, 476, 878, 1003, 994, 941, 1004)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (1005, 476, 878, 1003, 994, 941, 1004)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (1005, 476, 878, 1003, 994, 941, 1004)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (1005, 476, 878, 1003, 994, 941, 1004)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (1005, 476, 878, 1003, 994, 941, 1004)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (1005, 476, 878, 1003, 994, 941, 1004)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (1005, 476, 878, 1003, 994, 941, 1004)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (1005, 476, 878, 1003, 994, 941, 1004)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (1005, 476, 878, 1003, 994, 941, 1004)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (1005, 476, 878, 1003, 994, 941, 1004)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"
14:33:51,492 graphrag.llm.openai.utils INFO success load json in step 3{'title': ' - ', 'summary': '', 'rating': 8.5, 'rating_explanation': '', 'findings': [{'summary': '', 'explanation': ''}]}
14:33:51,493 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 591.9856510073878. input_tokens=2458, output_tokens=949
14:34:35,960 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
14:34:35,960 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
14:34:35,960 graphrag.llm.openai.utils INFO Error: JSONDecodeError
14:34:35,961 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
14:35:24,607 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
14:35:24,607 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI - ', 'summary': 'AIAI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'AI', 'explanation': 'AIAIAI[records: Entities (70, 69), Relationships (122, 121, 355, 354, 356)]'}, {'summary': 'AI', 'explanation': 'AIAI[records: Entities (66), Relationships (118)]'}, {'summary': 'AI', 'explanation': 'AIAI[records: Entities (82), Relationships (356, 458, 457)]'}, {'summary': 'AI', 'explanation': 'AIAI[records: Entities (445, 446, 447, 448, 449, 444, 443), Relationships (460, 465, 467, 462, 461, 463, 464, 461, 463, 464)]'}, {'summary': 'AIAI', 'explanation': 'AIAIAI[records: Entities (66, 82), Relationships (118, 356, 458, 457)]'}]}
14:35:24,608 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 93.09952971199527. input_tokens=4983, output_tokens=1373
14:37:22,880 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
14:37:22,881 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': '', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': '[records: Entities (68, 332, 333, 331, 330, 339, 328, 552), Relationships (120, 353, 468, 481, 474, 460, 475, 476, 478, 477, 480, 456, 466, 461, 462, 465, 467, 473, 463, 464, 482, 472, 471, 479, 469, 470, 990, 991, 989, 988, 1012, 986, 489, 498, 992)]'}, {'summary': '', 'explanation': 'AI: 466: 473[records: Relationships (466, 473)]'}, {'summary': '', 'explanation': ': 472: 477[records: Relationships (472, 477)]'}, {'summary': '', 'explanation': 'AI: 469: 470[records: Relationships (469, 470)]'}, {'summary': '', 'explanation': ': 482[records: Relationships (482)]'}]}
14:37:22,882 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 118.25779039692134. input_tokens=4394, output_tokens=1504
14:39:10,398 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
14:39:10,398 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': '', 'explanation': 'AI[records: Entities (45), Relationships (421, 422, 423)]'}, {'summary': '', 'explanation': 'NYITMITAIAI[records: Entities (528, 529, 530), Relationships (421, 422, 423)]'}, {'summary': '', 'explanation': 'CSIGMVII  [records: Entities (533, 534, 535, 536, 537, 538, 539, 540), Relationships (430, 431, 432, 433, 434, 435, 436, 437, 438)]'}, {'summary': 'AI', 'explanation': 'AIAIAIAI[records: Entities (533), Relationships (439)]'}, {'summary': '', 'explanation': 'AI[records: Entities (531, 532), Relationships (437, 438)]'}]}
14:39:10,399 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 107.501995368395. input_tokens=3384, output_tokens=1327
14:39:57,887 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
14:39:57,888 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
14:39:57,888 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title" 	: 	"" 	,      	"summary" 	: 	"AI" 	,      	"rating" 	: 	8.5 	,      	"rating_explanation" 	: 	"" 	,      	"findings" 	: 	[              	{                  	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Entities (338), Relationships (1011, 478, 872, 880, 232, 876, 1009, 899, 994, 996, 995, 997, 993, 998, 946, 999, 1010)]" 	,              		"explanation" 	: 	"[records: Entities (338), Relationships (1011, 478, 872, 880, 232, 876, 1009, 899, 994, 996, 995, 997, 993, 998, 946, 999, 1010)]" 	,              		"explanation" 	: 	"[records: Entities (338), Relationships (1011, 478, 872, 880, 232, 876, 1009, 899, 994, 996, 995, 997, 993, 998, 946, 999, 1010)]" 	,              		"explanation" 	: 	"[records: Entities (338), Relationships (1011, 478, 872, 880, 232, 876, 1009, 899, 994, 996, 995, 997, 993, 998, 946, 999, 1010)]" 	,              		"explanation" 	: 	"[records: Entities (338), Relationships (1011, 478, 872, 880, 232, 876, 1009, 899, 994, 996, 995, 997, 993, 998, 946, 999, 1010)]" 	,              		"explanation" 	: 	"[records: Entities (338), Relationships (1011, 478, 872, 880, 232, 876, 1009, 899, 994, 996, 995, 997, 993, 998, 946, 999, 1010)]" 	,              		"explanation" 	: 	"[records: Entities (338), Relationships (1011, 478, 872, 880, 232, 876, 1009, 899, 994, 996, 995, 997, 993, 998, 946, 999, 1010)]" 	,              		"explanation" 	: 	"[records: Entities (338), Relationships (1011, 478, 872, 880, 232, 876, 1009, 899, 994, 996, 995, 997, 993, 998, 946, 999, 1010)]" 	,              		"explanation" 	: 	"[records: Entities (338), Relationships (1011, 478, 872, 880, 232, 876, 1009, 899, 994, 996, 995, 997, 993, 998, 946, 999, 1010)]" 	,              		"explanation" 	: 	"[records: Entities (338), Relationships (1011, 478, 872, 880, 232, 876, 1009, 899, 994, 996, 995, 997, 993, 998, 946, 999, 1010)]" 	,              		"explanation" 	: 	"[records: Entities (338), Relationships (1011, 478, 872, 880, 232, 876, 1009, 899, 994, 996, 995, 997, 993, 998, 946, 999, 1010)]" 	,              		"explanation" 	: 	"[records: Entities (338), Relationships (1011, 478, 872, 880, 232, 876, 1009, 899, 994, 996, 995, 997, 993, 998, 946, 999, 1010)]" 	,              		"explanation" 	: 	"[records: Entities (338), Relationships (1011, 478, 872, 880, 232, 876, 1009, 899, 994, 996, 995, 997, 993, 998, 946, 999, 1010)]" 	,              		"explanation" 	: 	"[records: Entities (338), Relationships (1011, 478, 872, 880, 232, 876, 1009, 899, 994, 996, 995, 997, 993, 998, 946, 999, 1010)]" 	,              		"explanation" 	: 	"[records: Entities (338), Relationships (1011, 478, 872, 880, 232, 876, 1009, 899, 994, 996, 995, 997, 993, 998, 946, 999, 1010)]" 	,              		"explanation" 	: 	"[records: Entities (338), Relationships (1011, 478, 872, 880, 232, 876, 1009, 899, 994, 996, 995, 997, 993, 998, 946, 999, 1010)]" 	,              		"explanation" 	: 	"[records: Entities (338), Relationships (1011, 478, 872, 880, 232, 876, 1009, 899, 994, 996, 995, 997, 993, 998, 946, 999, 1010)]" 	,              		"explanation" 	: 	"[records: Entities (338), Relationships (1011, 478, 872, 880, 232, 876, 1009, 899, 994, 996, 995, 997, 993, 998, 946, 999, 1010)]" 	,              		"explanation" 	: 	"[records: Entities (338), Relationships (1011, 478, 872, 880, 232, 876, 1009, 899, 994, 996, 995, 997, 993, 998, 946, 999, 1010)]" 	,              		"explanation" 	: 	"[records: Entities (338), Relationships (1011, 478, 872, 880, 232, 876, 1009, 899, 994, 996, 995, 997, 993, 998, 946, 999, 1010)]" 	,              		"explanation" 	: 	"[records: Entities (338), Relationships (1011, 478, 872, 880, 232, 876, 1009, 899, 994, 996, 995, 997, 993, 998, 946, 999, 1010)]" 	,              		"explanation" 	: 	"[records: Entities (338), Relationships (1011, 478, 872, 880, 232, 876, 1009, 899, 994, 996, 995, 997, 993, 998, 946, 999, 1010)]" 	,              		"explanation" 	: 	"[records: Entities (338), Relationships (1011, 478, 872, 880, 232, 876, 1009, 899, 994, 996, 995, 997, 993, 998, 946, 999, 1010)]" 	,              		"explanation" 	: 	"[records: Entities (338), Relationships (1011, 478, 872, 880, 232, 876, 1009, 899, 994, 996, 995, 997, 993, 998, 946, 999, 1010)]" 	,              		"explanation" 	: 	"[records: Entities (338), Relationships (1011, 478, 872, 880, 232, 876, 1009, 899, 994, 996, 995, 997, 993, 998, 946, 999, 1010)]" 	,              		"explanation" 	: 	"[records: Entities (338), Relationships (1011, 478, 872, 880, 232, 876, 1009, 899, 994, 996, 995, 997, 993, 998, 946, 999, 1010)]" 	,              		"explanation" 	: 	"[records: Entities (338), Relationships (1011, 478, 872, 880, 232, 876, 1009, 899, 994, 996, 995, 997, 993, 998, 946, 999, 1010)]" 	,              		"explanation" 	: 	"[records: Entities (338), Relationships (1011, 478, 872, 880, 232, 876, 1009, 899, 994, 996, 995, 997, 993, 998, 946, 999, 1010)]" 	,              		"explanation" 	: 	"[records: Entities (338), Relationships (1011, 478, 872, 880, 232, 876, 1009, 899, 994, 996, 995, 997, 993, 998, 946, 999, 1010)]" 	,
14:39:57,889 graphrag.llm.openai.utils INFO success load json in step 3{'title': '', 'summary': 'AI', 'rating': 8.5, 'rating_explanation': '', 'findings': [{'summary': '', 'explanation': '[records: Entities (338), Relationships (1011, 478, 872, 880, 232, 876, 1009, 899, 994, 996, 995, 997, 993, 998, 946, 999, 1010)]'}]}
14:39:57,890 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 519.7005927530117. input_tokens=2919, output_tokens=1133
14:40:53,706 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
14:40:53,707 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AICSIGMVIIAIAIAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AICSIG', 'explanation': 'AICSIGAIAICSIGAI[records: Relationships (77, 408, 431)]'}, {'summary': 'AIMVII', 'explanation': 'AIMVIIAIAIMVIIAI[records: Relationships (78, 409, 432)]'}, {'summary': 'AI', 'explanation': 'AIAIAI[records: Relationships (441, 442)]'}, {'summary': '', 'explanation': 'AICSIGMVII[records: Entities (53, 54, 408, 409, 431, 432)]'}, {'summary': 'AI', 'explanation': 'AICSIGMVIIAI[records: Relationships (408, 409, 431, 432)]'}]}
14:40:53,707 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 103.29293325310573. input_tokens=3095, output_tokens=1253
14:42:07,729 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
14:42:07,730 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': '', 'rating': 8.0, 'rating_explanation': '', 'findings': [{'summary': '', 'explanation': 'ARAI[records: Entities (102, 365, 600, 585, 587), Relationships (125, 365, 600, 585, 587)]'}, {'summary': '', 'explanation': 'AR[records: Entities (457, 883, 1034), Relationships (577, 1034)]'}, {'summary': 'AI', 'explanation': 'AIAIAIAIAI[records: Entities (102, 365, 600), Relationships (125, 365, 600)]'}, {'summary': '', 'explanation': '[records: Entities (102, 582, 583, 584, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597), Relationships (582, 583, 584, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597)]'}, {'summary': 'AR', 'explanation': 'ARAR[records: Entities (457, 522), Relationships (577, 522)]'}]}
14:42:07,730 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 129.8252683565952. input_tokens=4059, output_tokens=1534
14:42:47,468 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
14:42:47,468 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'AR/VRAI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'AI', 'explanation': 'AIAR/VRAIAIAR[records: Relationships (714, 262, 886)]'}, {'summary': 'AI', 'explanation': 'AIAIAIAR/VRAR/VR[records: Relationships (645, 629, 894)]'}, {'summary': 'AI', 'explanation': 'AIVRVRVR[records: Relationships (600, 629, 891, 887, 888, 889, 890, 967, 972, 976, 979, 981)]'}, {'summary': 'AI', 'explanation': 'AIAR/VRAR/VRAI[records: Relationships (645, 629, 894, 885)]'}, {'summary': 'AI', 'explanation': 'AIAR/VRAIAIAR[records: Relationships (714, 262, 886)]'}]}
14:42:47,469 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 113.7456673081033. input_tokens=4904, output_tokens=1529
14:43:41,141 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
14:43:41,142 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
14:43:41,142 graphrag.llm.openai.utils INFO Error: JSONDecodeError
14:43:41,142 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
14:43:41,142 graphrag.index.graph.extractors.community_reports.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/index/graph/extractors/community_reports/community_reports_extractor.py", line 58, in __call__
    await self._llm(
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/base_llm.py", line 48, in __call__
    return await self._invoke_json(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_chat_llm.py", line 90, in _invoke_json
    raise RuntimeError(error_msg)
RuntimeError: Failed to generate valid JSON output - Faulty JSON: {}
14:43:41,142 graphrag.index.reporting.file_workflow_callbacks INFO Community Report Extraction Error details=None
14:43:41,142 graphrag.index.verbs.graph.report.strategies.graph_intelligence.run_graph_intelligence WARNING No report found for community: 84
14:43:50,682 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
14:43:50,682 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIVRARAIGCAIAI', 'rating': 8.0, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AIVRARAI[records: Entities (296, 318), Relationships (145, 330, 248, 586, 684, 618, 633, 705, 249, 672, 243, 917, 918, 919, 920, 921, 696, 587, 916, 685, 927, 905, 619, 634, 706, 956, 957, 958, 959, 960, 697, 928, 923, 925, 922, 924, 926, 961)]'}, {'summary': '', 'explanation': 'AIVRARAIAI[records: Relationships (249, 587, 916, 685, 928, 956, 957, 958, 959, 960, 697, 928)]'}, {'summary': 'AI', 'explanation': 'AIAIAI[records: Relationships (248)]'}, {'summary': '', 'explanation': 'AI[records: Relationships (586, 587)]'}, {'summary': 'VR', 'explanation': 'VRAIARVR[records: Relationships (672, 685)]'}]}
14:43:50,683 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 102.93690518382937. input_tokens=4149, output_tokens=1403
14:44:38,886 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
14:44:38,887 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AI', 'rating': 8.0, 'rating_explanation': 'AIAI', 'findings': [{'summary': '', 'explanation': 'AIAI[records: Entities (236), Relationships (184)]'}, {'summary': '', 'explanation': '[records: Entities (234), Relationships (847)]'}, {'summary': '', 'explanation': '[records: Entities (233), Relationships (845)]'}, {'summary': '', 'explanation': 'AI[records: Entities (236, 234, 233), Relationships (184, 847, 845)]'}, {'summary': '', 'explanation': '[records: Entities (234), Relationships (847)]'}]}
14:44:38,887 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 57.72571943514049. input_tokens=3219, output_tokens=1320
14:44:44,886 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
14:44:44,887 graphrag.llm.openai.utils INFO success load json in step 1{'title': ' - ', 'summary': '', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': '[records: Relationships (843, 841)]'}, {'summary': '', 'explanation': '[records: Relationships (839)]'}, {'summary': '', 'explanation': '[records: Relationships (837)]'}, {'summary': '', 'explanation': '[records: Relationships (842)]'}, {'summary': '', 'explanation': '[records: Relationships (843)]'}]}
14:44:44,887 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 54.189160849899054. input_tokens=2460, output_tokens=1198
14:45:52,240 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
14:45:52,241 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIAIAIAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AIAIAIAI[records: Relationships (173, 136, 40, 141, 427, 3, 854, 39, 32, 35, 38, 41, 904, 901, 902, 903, 900)]'}, {'summary': '', 'explanation': 'AI60AIAI[records: Relationships (173, 40, 141, 427, 3, 854, 39, 32, 35, 38, 41, 904, 901, 902, 903, 900)]'}, {'summary': '', 'explanation': 'AIAIAI[records: Relationships (173, 136, 40, 141, 427, 3, 854, 39, 32, 35, 38, 41, 904, 901, 902, 903, 900)]'}, {'summary': '', 'explanation': 'AIAIAI[records: Relationships (173, 136, 40, 141, 427, 3, 854, 39, 32, 35, 38, 41, 904, 901, 902, 903, 900)]'}, {'summary': '', 'explanation': 'AI852345AI[records: Relationships (173, 136, 40, 141, 427, 3, 854, 39, 32, 35, 38, 41, 904, 901, 902, 903, 900)]'}]}
14:45:52,241 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 67.33806468406692. input_tokens=4218, output_tokens=1409
14:47:52,827 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
14:47:52,827 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
14:47:52,827 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title" 	: 	"AIVR" 	,      	"summary" 	: 	"AIVRVRAIAI" 	,      	"rating" 	: 	8.5 	,      	"rating_explanation" 	: 	"AIVRAI" 	,      	"findings" 	: 	[          	{              	"summary" 	: 	"AI" 	,              	"explanation" 	: 	"AIAIAIAI[records: Entities (17), Relationships (58, 262, 267, 260, 247, 249, 261, 221, 258, 255, 256, 257, 259, 191, 263, 264, 265, 270, 246, 268, 690, 687, 686, 688, 689, 585, 626, 623, 622, 624, 625, 640, 711, 637, 708, 636, 707, 638, 709, 639, 710, 683, 269, 617, 266, 268, 632, 704, 965, 970, 974, 977, 968, 969, 962, 963, 964, 973, 702, 699, 698, 263, 264, 265, 269, 617, 266, 268, 632, 704, 965, 970, 974, 977, 968, 969, 962, 963, 964, 973, 702, 699, 698, 933, 960, 930, 957, 929, 956, 931, 958, 932, 959, 695, 693, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 9770, 	   ] ]    	]                	]" 	   , 	 	   "]" 	 	 	    	 	       	 	    	    	 	    	 	          	                                	 	    	 	 	               	 	 	 	 	 	 	 	 	       	                                                                                                          	 	                                                                                                                                                                                                                                                                                                                                                                                                                                                                        	                                                                                                                                                                             	 	 	                     	                                                                                                                 	                                                                                                                                                                             	 	 	                                                       	                                             	 	                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     	          	                                                        	                                        	                     	                                                                                                                                                                        	 	    	                                         	                                            	                      	    	                                	          	                                             	 	    	                     	 	 	 	 	 	 	 	 	    	          	 	 	 	 	          	 	             	               	 	 	 	 	 	 	 	 	 	 	 	    	 	                                                                                                        	                                                 	 	    	 	 	 	 	 		          	 	 	 	       	 	                             	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	                      	 	       	 		 	                                              	             	 	 	 	 	 	                                              	 	 	 	 	    	 	                                          	                                                                                                  	    	                                               	               	                          	                                                 	 	                 	                       	                                                                                                              	                       	              		                            				              	      	   					    				 	                 	 	              	                                  			 	              	    	              	    	                                         	                                                                           	:"]]"                    }]         	   	                 }
14:47:52,829 graphrag.llm.openai.utils INFO success load json in step 3{'title': 'AIVR', 'summary': 'AIVRVRAIAI', 'rating': 8.5, 'rating_explanation': 'AIVRAI', 'findings': [{'summary': 'AI', 'explanation': 'AIAIAIAI[records: Entities (17), Relationships (58, 262, 267, 260, 247, 249, 261, 221, 258, 255, 256, 257, 259, 191, 263, 264, 265, 270, 246, 268, 690, 687, 686, 688, 689, 585, 626, 623, 622, 624, 625, 640, 711, 637, 708, 636, 707, 638, 709, 639, 710, 683, 269, 617, 266, 268, 632, 704, 965, 970, 974, 977, 968, 969, 962, 963, 964, 973, 702, 699, 698, 263, 264, 265, 269, 617, 266, 268, 632, 704, 965, 970, 974, 977, 968, 969, 962, 963, 964, 973, 702, 699, 698, 933, 960, 930, 957, 929, 956, 931, 958, 932, 959, 695, 693, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 9770, \t   ] ]    \t]                \t]', ']': ']]'}]}
14:47:52,830 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 305.34427565615624. input_tokens=8441, output_tokens=3083
14:51:37,998 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
14:51:37,998 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
14:51:37,998 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title" 	: 	" - " 	,      	"summary" 	: 	"" 	,      	"rating" 	: 	8.5 	,      	"rating_explanation" 	: 	"" 	,      	"findings" 	: 	[              	{                      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (835)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (833)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (831)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (837)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (835, 833, 831, 837)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (835, 833, 831, 837)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (835, 833, 831, 837)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (835, 833, 831, 837)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (835, 833, 831, 837)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (835, 833, 831, 837)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (835, 833, 831, 837)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (835, 833, 831, 837)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (835, 833, 831, 837)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (835, 833, 831, 837)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (835, 833, 831, 837)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (835, 833, 831, 837)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (835, 833, 831, 837)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (835, 833, 831, 837)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (835, 833, 831, 837)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (835, 833, 831, 837)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (835, 833, 831, 837)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (835, 833, 831, 837)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (835, 833, 831, 837)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (835, 833, 831, 837)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (835, 833, 831, 837)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (835, 833, 831, 837)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (835, 833, 831, 837)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (835, 833, 831, 837)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (835, 833, 831, 837)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (835, 833, 831, 837)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (835, 833, 831, 837)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (835, 833, 831, 837)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (835, 833, 831, 837)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (835, 833, 831, 837)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (835, 833, 831, 837)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	:
14:51:38,0 graphrag.llm.openai.utils INFO success load json in step 3{'title': ' - ', 'summary': '', 'rating': 8.5, 'rating_explanation': '', 'findings': [{'summary': '', 'explanation': ''}]}
14:51:38,1 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 419.0984702538699. input_tokens=2641, output_tokens=1014
14:52:45,25 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
14:52:45,26 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
14:52:45,26 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title"   	: 	"" 	,      	"summary" 	: 	"AIVRAIAI" 	,      	"rating" 	: 	8.5 	,      	"rating_explanation" 	: 	"AIAI" 	,      	"findings" 	: 	[              	{                      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AIVR[records: Entities (18, 274, 177, 294, 184, 179, 297, 181, 37), Relationships (64, 278, 143, 135, 134, 142, 89, 83, 84, 85, 132, 87, 88, 146, 86, 72, 326, 267, 17, 353, 365, 330, 314, 311, 325, 282, 312, 287, 290, 288, 313, 291, 230, 363, 327, 329, 216, 354, 355, 271, 366, 285, 346, 351, 359, 277, 344, 345, 347, 348, 356, 29, 342, 306, 336, 360, 204, 207, 210, 213, 227, 289, 292, 305, 307, 335, 357, 358, 321, 319, 296, 272, 273, 274, 275, 294, 182, 183, 161, 180, 179, 177, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 17 records... records] ]  ] 	]" 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	    	    	 	 	    	 	 	 	 	    	 	       	, 	 	"] 	]" 	                   	 	 	 	       	 	 	 	 	 	          	 	 	 	 	 	 	 	 	                             	 	 	 	 	                   	 	 	 	                    	 	 			 	 	 	                              	 	    	 	 	 	 	 	 	 	 	 	 	    	 	                           	 	 	 	 	 	 	 	                        	 	                               	 	 	 	   	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	             	 	 	 	 	 	 	 	 	 	             	    	 	 	 	 	                	 	 	 	 	 	    	 	 	 	 	 	 	 	     	 	 	 	 	 	 	 	 	               	 	     	 	 	 	 	     	 	 	 	 	 	 	 	     	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	      	      	 	 	 	 	   	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 	                      	 	    	                         	 	    	                                                                   	 	    	                   	   	 	 	                   	                  	 	 	                                         	 	 	 	   		 	 	 	 	 	 	 	 	 	   		 	 	    	 	 	    	   	                                             	                            	    	                     	    		 	 	    	          	 	 	 	                             	 	 	 	    	 	 	 	 	 	 	    	 	 	 	    	 	 	 	 	 	 	 	 	 	 	 	   	 	 	    	 	    			    	                                     	 	 	 	 	 	 	 	 	    	 	 	       	 	 	 	 	 	 	 	 	 	                  	 	 	 	 	 	 	 	    	 	 	 	 	 	 	 	 	                	 			          	 	                 		    	 	 	 	    	 	               	 	 	 	 	 		                                  	 	 	 	 	 	 	 	 	 	 	 		 	 	 	               				 		      	 	 	 	 	 	 	                             			                 	 	 	 	              				                   		             	 	 	 	 	 	 	               	 	 			 		               	 	 	 				 	                                           	 	 	 	   		 			 	 	 	 	:"]..."                                     	 	 	} 	] 	 	 , 	 	"]    	] 	               	...]<tool_call> , 	..."
14:52:45,27 graphrag.llm.openai.utils INFO success load json in step 3{'title': '', 'summary': 'AIVRAIAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AIVR[records: Entities (18, 274, 177, 294, 184, 179, 297, 181, 37), Relationships (64, 278, 143, 135, 134, 142, 89, 83, 84, 85, 132, 87, 88, 146, 86, 72, 326, 267, 17, 353, 365, 330, 314, 311, 325, 282, 312, 287, 290, 288, 313, 291, 230, 363, 327, 329, 216, 354, 355, 271, 366, 285, 346, 351, 359, 277, 344, 345, 347, 348, 356, 29, 342, 306, 336, 360, 204, 207, 210, 213, 227, 289, 292, 305, 307, 335, 357, 358, 321, 319, 296, 272, 273, 274, 275, 294, 182, 183, 161, 180, 179, 177, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 17 records... records] ]  ] \t]', '] \t]': ']...'}]}
14:52:45,28 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 412.76975164888427. input_tokens=9855, output_tokens=2257
14:53:50,575 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
14:53:50,576 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIARVRAIARVR', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'AI', 'explanation': 'AIARVR[records: Entities (84, 93, 98, 91, 94, 522, 523, 520, 521, 524), Relationships (123, 277, 522, 523, 520, 521, 524)]'}, {'summary': 'ARVR', 'explanation': 'ARVRARVR[records: Relationships (522, 523)]'}, {'summary': '', 'explanation': '[records: Relationships (520)]'}, {'summary': '', 'explanation': '[records: Relationships (521)]'}, {'summary': '', 'explanation': '[records: Relationships (524)]'}]}
14:53:50,577 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 65.49556603701785. input_tokens=2601, output_tokens=1271
15:00:55,545 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
15:00:55,545 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
15:00:55,546 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
15:00:55,546 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title" 	: 	"AI" 	,      	"summary" 	: 	"AIAI" 	,      	"rating" 	: 	8.5 	,      	"rating_explanation" 	: 	"AI" 	,      	"findings" 	: 	[              	{                      	"summary" 	: 	"AIAI" 	,                      	"explanation" 	: 	"AIAIAI[records: Entities (194, 197, 196, 195, 193), Relationships (97, 100, 99, 98, 96)]" 	,                  	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AI[records: Relationships (792)]" 	,                  	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AI[records: Relationships (794)]" 	,                  	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AI[records: Relationships (793)]" 	,                  	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AI[records: Relationships (791)]" 	,              	"summary" 	: 	"AIAI" 	,                      	"explanation" 	: 	"AIAIAIAIAI[records: Entities (194, 197, 196, 195, 193), Relationships (97, 100, 99, 98, 96)]" 	,          	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AIAIAIAIAIAI[records: Entities (194, 197, 196, 195, 193), Relationships (97, 100, 99, 98, 96)]" 	,          	"summary" 	: 	"AIAI" 	,                      	"explanation" 	: 	"AIAIAIAIAIAI[records: Entities (194, 197, 196, 195, 193), Relationships (97, 100, 99, 98, 96)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AIAIAIAIAIAI[records: Entities (194, 197, 196, 195, 193), Relationships (97, 100, 99, 98, 96)]" 	,      	"summary" 	: 	"AIAI" 	,                      	"explanation" 	: 	"AIAIAIAIAIAIAI[records: Entities (194, 197, 196, 195, 193), Relationships (97, 100, 99, 98, 96)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AIAIAIAIAIAI[records: Entities (194, 197, 196, 195, 193), Relationships (97, 100, 99, 98, 96)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AIAIAIAIAI[records: Entities (194, 197, 196, 195, 193), Relationships (97, 100, 99, 98, 96)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AIAIAIAIAIAI[records: Entities (194, 197, 196, 195, 193), Relationships (97, 100, 99, 98, 96)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AIAIAIAIAIAI[records: Entities (194, 197, 196, 195, 193), Relationships (97, 100, 99, 98, 96)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AIAIAIAIAI[records: Entities (194, 197, 196, 195, 193), Relationships (97, 100, 99, 98, 96)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AIAIAIAIAIAI[records: Entities (194, 197, 196, 195, 193), Relationships (97, 100, 99, 98, 96)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AIAIAIAIAIAI[records: Entities (194, 197, 196, 195, 193), Relationships (97, 100, 99, 98, 96)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AIAIAIAIAI[records: Entities (194, 197, 196, 195, 193), Relationships (97, 100, 99, 98, 96)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AIAIAIAIAIAI[records: Entities (194, 197, 196, 195, 193), Relationships (97, 100, 99, 98, 96)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AIAIAIAIAIAI[records: Entities (194, 197, 196, 195, 193), Relationships (97, 100, 99, 98, 96)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AIAIAIAIAI[records: Entities (194, 197, 196, 195, 193), Relationships (97, 100, 99, 98, 96)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AIAIAIAIAIAI[records: Entities (194, 197, 196, 195, 193), Relationships (97, 100, 99, 98, 96)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AIAIAIAIAIAI[records: Entities (194, 197, 196, 195, 193), Relationships (97, 100, 99, 98, 96)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AIAIAIAIAI[records: Entities (194, 197, 196, 195, 193), Relationships (97, 100, 99, 98, 96)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AIAIAIAIAIAI[records: Entities (194, 197, 196, 195, 193), Relationships (97, 100, 99, 98, 96)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AIAIAIAIAIAI[records: Entities (194, 197, 196, 195, 193), Relationships (97, 100, 99, 98, 96)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AIAIAIAIAI[records: Entities (194, 197, 196, 195, 193), Relationships (97, 100, 99, 98, 96)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AIAIAIAIAIAI[records: Entities (194, 197, 196, 195, 193), Relationships (97, 100, 99, 98, 96)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AIAIAIAIAIAI[records: Entities (194, 197, 196, 195, 193), Relationships (97, 100, 99, 98, 96)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AIAIAIAIAI[records: Entities (194, 197, 196, 195, 193), Relationships (97, 100, 99, 98, 96)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AIAIAIAIAIAI[records: Entities (194, 197, 196, 195, 193), Relationships (97, 100, 99, 98, 96)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AIAIAIAIAIAI[records: Entities (194, 197, 196, 195
15:00:55,549 graphrag.llm.openai.utils INFO success load json in step 3{'title': 'AI', 'summary': 'AIAI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'AI', 'explanation': 'AIAIAIAIAIAI[records: Entities (194, 197, 196, 195'}]}
15:00:55,549 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 490.4629398761317. input_tokens=3009, output_tokens=1096
15:00:55,550 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
15:00:55,550 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title" 	: 	"AI" 	,      	"summary" 	: 	"AI&AI + TransformerAI" 	,      	"rating" 	: 	8.5 	,      	"rating_explanation" 	: 	"AI" 	,      	"findings" 	: 	[              	{                  	"summary" 	: 	"AI&" 	,                  	"explanation" 	: 	"AI&AIAIAI[records: Entities (536, 335), Relationships (160, 1097)]" 	,              	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AI&[records: Entities (613, 536), Relationships (163, 1097)]" 	,              	"summary" 	: 	"AI + AI" 	,                  	"explanation" 	: 	"AIAI + AIAIAI[records: Entities (266, 536), Relationships (161, 860)]" 	,              	"summary" 	: 	"Transformer&" 	,                  	"explanation" 	: 	"Transformer&AIAIAI[records: Entities (537), Relationships (1096)]" 	,              	"summary" 	: 	"AIAI + " 	,                  	"explanation" 	: 	"AIAI + AI[records: Entities (613, 266), Relationships (860)]" 	,          	"summary" 	: 	"AI&" 	,                  	"explanation" 	: 	"AI&AI[records: Entities (613, 536), Relationships (160, 1097)]" 	,      	"summary" 	: 	"AIAI + " 	,                  	"explanation" 	: 	"AIAI + AI[records: Entities (613, 266), Relationships (860)]" 	,      	"summary" 	: 	"&Transformer" 	,                  	"explanation" 	: 	"&TransformerAIAIAI[records: Entities (536, 537), Relationships (1096)]" 	,      	"summary" 	: 	"AI&" 	,                  	"explanation" 	: 	"AI&AI[records: Entities (613, 536), Relationships (160, 1097)]" 	,      	"summary" 	: 	"AIAI + " 	,                  	"explanation" 	: 	"AIAI + AI[records: Entities (613, 266), Relationships (860)]" 	,      	"summary" 	: 	"AI&" 	,                  	"explanation" 	: 	"AI&AI[records: Entities (613, 536), Relationships (160, 1097)]" 	,      	"summary" 	: 	"AIAI + " 	,                  	"explanation" 	: 	"AIAI + AI[records: Entities (613, 266), Relationships (860)]" 	,      	"summary" 	: 	"AI&" 	,                  	"explanation" 	: 	"AI&AI[records: Entities (613, 536), Relationships (160, 1097)]" 	,      	"summary" 	: 	"AIAI + " 	,                  	"explanation" 	: 	"AIAI + AI[records: Entities (613, 266), Relationships (860)]" 	,      	"summary" 	: 	"AI&" 	,                  	"explanation" 	: 	"AI&AI[records: Entities (613, 536), Relationships (160, 1097)]" 	,      	"summary" 	: 	"AIAI + " 	,                  	"explanation" 	: 	"AIAI + AI[records: Entities (613, 266), Relationships (860)]" 	,      	"summary" 	: 	"AI&" 	,                  	"explanation" 	: 	"AI&AI[records: Entities (613, 536), Relationships (160, 1097)]" 	,      	"summary" 	: 	"AIAI + " 	,                  	"explanation" 	: 	"AIAI + AI[records: Entities (613, 266), Relationships (860)]" 	,      	"summary" 	: 	"AI&" 	,                  	"explanation" 	: 	"AI&AI[records: Entities (613, 536), Relationships (160, 1097)]" 	,      	"summary" 	: 	"AIAI + " 	,                  	"explanation" 	: 	"AIAI + AI[records: Entities (613, 266), Relationships (860)]" 	,      	"summary" 	: 	"AI&" 	,                  	"explanation" 	: 	"AI&AI[records: Entities (613, 536), Relationships (160, 1097)]" 	,      	"summary" 	: 	"AIAI + " 	,                  	"explanation" 	: 	"AIAI + AI[records: Entities (613, 266), Relationships (860)]" 	,      	"summary" 	: 	"AI&" 	,                  	"explanation" 	: 	"AI&AI[records: Entities (613, 536), Relationships (160, 1097)]" 	,      	"summary" 	: 	"AIAI + " 	,                  	"explanation" 	: 	"AIAI + AI[records: Entities (613, 266), Relationships (860)]" 	,      	"summary" 	: 	"AI&" 	,                  	"explanation" 	: 	"AI&AI[records: Entities (613, 536), Relationships (160, 1097)]" 	,      	"summary" 	: 	"AIAI + " 	,                  	"explanation" 	: 	"AIAI + AI[records: Entities (613, 266), Relationships (860)]" 	,      	"summary" 	: 	"AI&" 	,                  	"explanation" 	: 	"AI&AI[records: Entities (613, 536), Relationships (160, 1097)]" 	,      	"summary" 	: 	"AIAI + " 	,                  	"explanation" 	: 	"AIAI + AI[records: Entities (613, 266), Relationships (860)]" 	,      	"summary" 	: 	"AI&" 	,                  	"explanation" 	: 	"AI&AI[records: Entities (613, 536), Relationships (160, 1097)]" 	,      	"summary" 	: 	"AIAI + " 	,                  	"explanation" 	: 	"AIAI + AI[records: Entities (613, 266), Relationships (860)]" 	,      	"summary" 	: 	"AI&" 	,                  	"explanation" 	: 	"AI&AI[records: Entities (613, 536), Relationships (160, 1097)]" 	,      	"summary" 	: 	"AIAI + " 	,                  	"explanation" 	: 	"AIAI + AI[records: Entities (613, 266), Relationships (860)]" 	,      	"summary" 	: 	"AI&" 	,                  	"explanation" 	: 	"AI&AI[records: Entities (613, 536), Relationships (160, 1097)]" 	,      	"summary" 	: 	"AIAI + " 	,                  	"explanation" 	: 	"AIAI + AI[records: Entities (613, 266), Relationships (860)]" 	,      	"summary" 	: 	"AI&" 	,                  	"explanation" 	: 	"AI&AI[records: Entities (613, 536), Relationships (160, 1097)]" 	,      	"summary" 	: 	"AIAI + " 	,                  	"explanation" 	: 	"AIAI + AI[records: Entities (613, 266), Relationships (860)]" 	,      	"summary" 	: 	"AI&" 	,                  	"explanation" 	: 	"AI&AI[records: Entities (613, 536), Relationships (160, 1097)]" 	,      	"summary" 	: 	"AIAI + " 	,                  	"explanation" 	: 	"AIAI + AI[records: Entities (613, 266), Relationships (860)]" 	,      	"summary" 	: 	"AI&" 	,                  	"explanation" 	: 	"AI&AI[records: Entities (613, 536), Relationships (160, 1097)]" 	,      	"summary" 	: 	"AIAI + " 	,                  	"explanation" 	: 	"AIAI + AI[records: Entities (613, 266), Relationships (860)]" 	,      	"summary" 	: 	"AI&" 	,                  	"explanation" 	: 	"AI&AI[records: Entities (613, 536), Relationships (160, 1097)]" 	,      	"summary" 	: 	"AIAI + " 	,                  	"explanation" 	: 	"AIAI + AI[records: Entities (613, 266), Relationships (860)]" 	,      	"summary" 	: 	"AI&" 	,                  	"explanation" 	: 	"AI&
15:00:55,553 graphrag.llm.openai.utils INFO success load json in step 3{'title': 'AI', 'summary': 'AI&AI + TransformerAI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'AI&', 'explanation': 'AI&'}]}
15:00:55,554 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 490.4700608160347. input_tokens=2652, output_tokens=942
15:02:14,503 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
15:02:14,504 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI - ', 'summary': 'AIIPAIIP', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AIAI[records: Entities (67), Relationships (119)]'}, {'summary': 'AI', 'explanation': 'AIAI[records: Entities (64), Relationships (116)]'}, {'summary': 'AIIP', 'explanation': 'AIIPAIIPIP[records: Entities (65), Relationships (117)]'}, {'summary': '', 'explanation': '[records: Entities (67), Relationships (455)]'}, {'summary': 'IP', 'explanation': 'IP[records: Entities (64), Relationships (453)]'}]}
15:02:14,505 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 78.93318751314655. input_tokens=3043, output_tokens=1178
15:02:20,323 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
15:02:20,323 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
15:02:20,323 graphrag.llm.openai.utils INFO Error: JSONDecodeError
15:02:20,323 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
15:02:41,317 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
15:02:41,317 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'VR/AR/MRAIAIGCAIAI', 'rating': 8.5, 'rating_explanation': '', 'findings': [{'summary': '', 'explanation': 'VR/AR/MRAIAIGCAIAIAI[records: Entities (10, 11, 12, 9, 267, 269, 270, 268, 525), Relationships (4, 51, 52, 53, 50, 17, 207, 210, 213, 204, 315, 317, 318, 316, 16, 5, 22, 24, 25, 15, 20, 12, 21, 26, 0, 2, 3, 18, 6, 11, 208, 211, 214, 205, 861, 209, 206, 212, 215, 862, 866, 864, 865, 863)]'}, {'summary': '', 'explanation': 'AI[records: Entities (267), Relationships (315)]'}, {'summary': '', 'explanation': 'AIAI[records: Entities (11), Relationships (52)]'}, {'summary': '', 'explanation': 'AIAIAI[records: Entities (12), Relationships (53)]'}, {'summary': '', 'explanation': 'AIAIAI[records: Entities (9), Relationships (50)]'}]}
15:02:41,318 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 105.74275360722095. input_tokens=5658, output_tokens=1395
15:03:41,256 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
15:03:41,257 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIAIAI', 'rating': 8.5, 'rating_explanation': 'AIAIAI', 'findings': [{'summary': '', 'explanation': '60AI[records: Relationships (114, 327, 30, 854, 34, 37, 39, 855, 856, 858, 857)]'}, {'summary': 'AI', 'explanation': 'AIAIAIAI[records: Relationships (858)]'}, {'summary': '', 'explanation': 'AI[records: Relationships (859)]'}, {'summary': '', 'explanation': '[records: Relationships (786)]'}, {'summary': '', 'explanation': 'AIAI[records: Relationships (857)]'}]}
15:03:41,258 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 86.73746046004817. input_tokens=2983, output_tokens=1267
15:04:27,421 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
15:04:27,421 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'AI', 'rating': 8.5, 'rating_explanation': '', 'findings': [{'summary': '', 'explanation': 'AI[records: Entities (1, 5), Relationships (28, 29, 30, 31, 32, 789, 790, 787, 788, 27)]'}, {'summary': '', 'explanation': 'AI[records: Relationships (93)]'}, {'summary': '', 'explanation': 'AI[records: Relationships (94)]'}, {'summary': '', 'explanation': 'AI[records: Relationships (91)]'}, {'summary': '', 'explanation': 'AI[records: Relationships (92)]'}]}
15:04:27,422 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 106.08595226379111. input_tokens=3802, output_tokens=1397
15:13:38,264 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
15:13:38,264 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
15:13:38,264 graphrag.llm.openai.utils INFO Error: JSONDecodeError
15:13:38,264 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
15:15:33,494 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
15:15:33,495 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
15:15:33,495 graphrag.llm.openai.utils INFO Error: JSONDecodeError
15:15:33,495 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
15:16:36,668 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
15:16:36,669 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
15:16:36,669 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title" 	: 	"" 	,      	"summary" 	: 	"AIVRAI-SEEDAIAIAIAI" 	,      	"rating" 	: 	8.5 	,      	"rating_explanation" 	: 	"" 	,      	"findings" 	: 	[              	{                      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AIVRAI-SEEDAIAIAIAI[records: Entities (456), Relationships (739, 770, 756, 1033, 220, 1032, 1029, 1031, 1030)]" 	,              	"summary" 	: 	"AI-SEED" 	,                      	"explanation" 	: 	"AI-SEEDAI-SEED[records: Relationships (1033)]" 	,              	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AIAI[records: Relationships (1031)]" 	,              	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AIAIAI[records: Entities (456), Relationships (1030)]" 	,              	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AIAI[records: Relationships (1032)]" 	,              	"summary" 	: 	"VR" 	,                      	"explanation" 	: 	"VRVR[records: Relationships (770)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (739)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (756)]" 	,              	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AIAI[records: Relationships (1029)]" 	,              	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AIVRAI-SEEDAIAIAIAIAI[records: Entities (456), Relationships (739, 770, 756, 1033, 220, 1032, 1029, 1031, 1030)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AIAIAI[records: Entities (456), Relationships (1031, 1030)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AIVRAI-SEEDAIAIAIAIAI[records: Entities (456), Relationships (739, 770, 756, 1033, 220, 1032, 1029, 1031, 1030)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AIVRAI-SEEDAIAIAIAIAI[records: Entities (456), Relationships (739, 770, 756, 1033, 220, 1032, 1029, 1031, 1030)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AIVRAI-SEEDAIAIAIAIAI[records: Entities (456), Relationships (739, 770, 756, 1033, 220, 1032, 1029, 1031, 1030)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AIVRAI-SEEDAIAIAIAIAI[records: Entities (456), Relationships (739, 770, 756, 1033, 220, 1032, 1029, 1031, 1030)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AIVRAI-SEEDAIAIAIAIAI[records: Entities (456), Relationships (739, 770, 756, 1033, 220, 1032, 1029, 1031, 1030)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AIVRAI-SEEDAIAIAIAIAI[records: Entities (456), Relationships (739, 770, 756, 1033, 220, 1032, 1029, 1031, 1030)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AIVRAI-SEEDAIAIAIAIAI[records: Entities (456), Relationships (739, 770, 756, 1033, 220, 1032, 1029, 1031, 1030)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AIVRAI-SEEDAIAIAIAIAI[records: Entities (456), Relationships (739, 770, 756, 1033, 220, 1032, 1029, 1031, 1030)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AIVRAI-SEEDAIAIAIAIAI[records: Entities (456), Relationships (739, 770, 756, 1033, 220, 1032, 1029, 1031, 1030)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AIVRAI-SEEDAIAIAIAIAI[records: Entities (456), Relationships (739, 770, 756, 1033, 220, 1032, 1029, 1031, 1030)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AIVRAI-SEEDAIAIAIAIAI[records: Entities (456), Relationships (739, 770, 756, 1033, 220, 1032, 1029, 1031, 1030)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AIVRAI-SEEDAIAIAIAIAI[records: Entities (456), Relationships (739, 770, 756, 1033, 220, 1032, 1029, 1031, 1030)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AIVRAI-SEEDAIAIAIAIAI[records: Entities (456), Relationships (739, 770, 756, 1033, 220, 1032, 1029, 1031, 1030)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AIVRAI-SEEDAIAIAIAIAI[records: Entities (456), Relationships (739, 770, 756, 1033, 220, 1032, 1029, 1031, 1030)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AIVRAI-SEEDAIAIAIAIAI[records: Entities (456), Relationships (739, 770, 756, 1033, 220, 1032, 1029, 1031, 1030)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AIVRAI-SEEDAIAIAIAIAI[records: Entities (456), Relationships (739, 770, 756, 1033, 220, 1032, 1029, 1031, 1030)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AIVRAI-SEEDAIAIAIAIAI[records: Entities (456), Relationships (739, 770, 756, 1033, 220, 1032, 1029, 1031, 1030)]" 	,      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AIVRAI-SEEDAIAIAIAI
15:16:36,671 graphrag.llm.openai.utils INFO success load json in step 3{'title': '', 'summary': 'AIVRAI-SEEDAIAIAIAI', 'rating': 8.5, 'rating_explanation': '', 'findings': [{'summary': '', 'explanation': 'AIVRAI-SEEDAIAIAIAI'}]}
15:16:36,671 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 729.2341719870456. input_tokens=2543, output_tokens=1192
18:12:27,411 graphrag.index.cli INFO Logging enabled at output/reports/indexing-engine.log
18:12:27,412 graphrag.index.cli INFO Starting pipeline run for: 20241125-181227, dryrun=False
18:12:27,413 graphrag.index.cli INFO Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "openai_chat",
        "model": "Qwen2.5-7B-Instruct",
        "max_tokens": 5000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 3000.0,
        "api_base": "http://192.168.0.244:8016/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 2.0,
        "num_threads": 50
    },
    "async_mode": "asyncio",
    "root_dir": ".",
    "reporting": {
        "type": "file",
        "base_dir": "output/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "model": "m3e-large",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://192.168.0.244:8016/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 2.0,
            "num_threads": 50
        },
        "async_mode": "asyncio",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 500,
        "overlap": 200,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "Qwen2.5-7B-Instruct",
            "max_tokens": 5000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 3000.0,
            "api_base": "http://192.168.0.244:8016/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 2.0,
            "num_threads": 50
        },
        "async_mode": "asyncio",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "\u653f\u7b56\u6cd5\u89c4",
            "\u5206\u7c7b\u65b9\u6cd5",
            "\u5904\u7406\u6280\u672f",
            "\u56de\u6536\u6750\u6599",
            "\u8bbe\u65bd\u8bbe\u5907",
            "\u5206\u7c7b\u6807\u51c6",
            "\u7ba1\u7406\u7ec4\u7ec7",
            "\u7ecf\u6d4e\u6a21\u5f0f",
            "\u6559\u80b2\u57f9\u8bad",
            "\u8ba4\u8bc1\u4f53\u7cfb",
            "\u751f\u6d3b\u65b9\u5f0f",
            "\u80fd\u6e90\u7c7b\u578b",
            "\u73af\u5883\u56e0\u7d20",
            "\u8d44\u6e90\u7ba1\u7406",
            "\u73af\u4fdd\u4ea7\u54c1",
            "\u4f01\u4e1a\u673a\u6784",
            "\u91d1\u878d\u6a21\u5f0f",
            "\u79d1\u5b66\u7814\u7a76",
            "\u6d3b\u52a8\u5021\u5bfc",
            "\u610f\u8bc6\u63d0\u5347",
            "\u73af\u5883\u5f71\u54cd",
            "\u6c61\u67d3\u6cbb\u7406",
            "\u8bc4\u4f30\u4f53\u7cfb",
            "\u5faa\u73af\u5229\u7528",
            "\u8d44\u6e90\u5316\u6280\u672f",
            "\u53ef\u6301\u7eed\u53d1\u5c55",
            "\u751f\u6001\u4fdd\u62a4",
            "\u78b3\u7ba1\u7406",
            "\u6c14\u5019\u884c\u52a8",
            "\u521b\u65b0\u5e94\u7528",
            "\u884c\u4e1a\u5b9e\u8df5",
            "\u57ce\u5e02\u89c4\u5212",
            "\u4ea4\u901a\u6a21\u5f0f",
            "\u6d88\u8d39\u6a21\u5f0f",
            "\u73af\u5883\u76d1\u6d4b",
            "\u5e9f\u5f03\u7269\u5904\u7406",
            "\u6c61\u67d3\u6e90\u63a7\u5236",
            "\u751f\u6001\u4fee\u590d",
            "\u7eff\u8272\u5efa\u7b51",
            "\u73af\u4fdd\u6280\u672f",
            "\u751f\u7269\u964d\u89e3",
            "\u80fd\u6e90\u5229\u7528"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "Qwen2.5-7B-Instruct",
            "max_tokens": 5000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 3000.0,
            "api_base": "http://192.168.0.244:8016/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 2.0,
            "num_threads": 50
        },
        "async_mode": "asyncio",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "Qwen2.5-7B-Instruct",
            "max_tokens": 5000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 3000.0,
            "api_base": "http://192.168.0.244:8016/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 3.0,
            "num_threads": 3
        },
        "async_mode": "asyncio",
        "prompt": "prompts/community_report.txt",
        "max_length": 5000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "Qwen2.5-7B-Instruct",
            "max_tokens": 5000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 3000.0,
            "api_base": "http://192.168.0.244:8016/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 2.0,
            "num_threads": 50
        },
        "async_mode": "asyncio",
        "enabled": true,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
18:12:27,413 graphrag.index.create_pipeline_config INFO skipping workflows 
18:12:27,413 graphrag.index.run INFO Running pipeline
18:12:27,413 graphrag.index.storage.file_pipeline_storage INFO Creating file storage at output/artifacts
18:12:27,413 graphrag.index.input.load_input INFO loading input from root_dir=input
18:12:27,413 graphrag.index.input.load_input INFO using file storage for input
18:12:27,414 graphrag.index.storage.file_pipeline_storage INFO search input for files matching .*\.txt$
18:12:27,414 graphrag.index.input.text INFO found text files from input, found [('Guangzhou Zhongyiyong Intelligent Technology Co., Inc._pdf.txt', {}), ('Guangzhou Zhongyiyong Intelligent Technology Co., Inc.-1.txt', {}), ('Guangzhou Zhongyiyong Intelligent Technology Co., Inc.-2.txt', {}), ('Guangzhou Zhongyiyong Intelligent Technology Co., Inc..txt', {}), ('Guangzhou Zhongyiyong Intelligent Technology Co., Inc.-0904.txt', {})]
18:12:27,416 graphrag.index.input.text INFO Found 5 files, loading 5
18:12:27,416 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_final_covariates', 'create_summarized_entities', 'join_text_units_to_covariate_ids', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents']
18:12:27,417 graphrag.index.run INFO Final # of rows loaded: 5
18:12:27,497 graphrag.index.run INFO Running workflow: create_base_text_units...
18:12:27,498 graphrag.index.run INFO Skipping create_base_text_units because it already exists
18:12:27,574 graphrag.index.run INFO Running workflow: create_base_extracted_entities...
18:12:27,575 graphrag.index.run INFO Skipping create_base_extracted_entities because it already exists
18:12:27,649 graphrag.index.run INFO Running workflow: create_final_covariates...
18:12:27,650 graphrag.index.run INFO Skipping create_final_covariates because it already exists
18:12:27,723 graphrag.index.run INFO Running workflow: create_summarized_entities...
18:12:27,723 graphrag.index.run INFO Skipping create_summarized_entities because it already exists
18:12:27,798 graphrag.index.run INFO Running workflow: join_text_units_to_covariate_ids...
18:12:27,799 graphrag.index.run INFO Skipping join_text_units_to_covariate_ids because it already exists
18:12:27,875 graphrag.index.run INFO Running workflow: create_base_entity_graph...
18:12:27,876 graphrag.index.run INFO Skipping create_base_entity_graph because it already exists
18:12:27,951 graphrag.index.run INFO Running workflow: create_final_entities...
18:12:27,951 graphrag.index.run INFO Skipping create_final_entities because it already exists
18:12:28,24 graphrag.index.run INFO Running workflow: create_final_nodes...
18:12:28,24 graphrag.index.run INFO Skipping create_final_nodes because it already exists
18:12:28,97 graphrag.index.run INFO Running workflow: create_final_communities...
18:12:28,97 graphrag.index.run INFO Skipping create_final_communities because it already exists
18:12:28,178 graphrag.index.run INFO Running workflow: join_text_units_to_entity_ids...
18:12:28,179 graphrag.index.run INFO Skipping join_text_units_to_entity_ids because it already exists
18:12:28,260 graphrag.index.run INFO Running workflow: create_final_relationships...
18:12:28,260 graphrag.index.run INFO Skipping create_final_relationships because it already exists
18:12:28,345 graphrag.index.run INFO Running workflow: join_text_units_to_relationship_ids...
18:12:28,345 graphrag.index.run INFO Skipping join_text_units_to_relationship_ids because it already exists
18:12:28,425 graphrag.index.run INFO Running workflow: create_final_community_reports...
18:12:28,426 graphrag.index.run INFO dependencies for create_final_community_reports: ['create_final_covariates', 'create_final_nodes', 'create_final_relationships']
18:12:28,427 graphrag.index.run INFO read table from storage: create_final_covariates.parquet
18:12:28,431 graphrag.index.run INFO read table from storage: create_final_nodes.parquet
18:12:28,434 graphrag.index.run INFO read table from storage: create_final_relationships.parquet
18:12:28,439 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
18:12:28,453 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
18:12:28,461 datashaper.workflow.workflow INFO executing verb prepare_community_reports_claims
18:12:28,464 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
18:12:28,472 datashaper.workflow.workflow INFO executing verb prepare_community_reports
18:12:28,472 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=3 => 653
18:12:28,584 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=2 => 653
18:12:28,655 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=1 => 653
18:12:28,759 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 653
18:12:28,823 datashaper.workflow.workflow INFO executing verb create_community_reports
18:12:29,25 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=http://192.168.0.244:8016/v1
18:12:29,36 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for Qwen2.5-7B-Instruct: TPM=0, RPM=0
18:12:29,36 graphrag.index.llm.load_llm INFO create concurrency limiter for Qwen2.5-7B-Instruct: 25
18:12:29,38 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI-SEED', 'summary': 'AI-SEEDAIAIAIAI-SEEDAIAI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'AI-SEED', 'explanation': 'AI-SEEDAIAIAIAIAIAIAI[records: Entities (470, 471, 472, 473, 474, 475), Relationships (1050, 1051, 1052, 1053, 1054, 1056, 1057, 1058, 1059, 1060, 1061, 1062)]'}, {'summary': 'AI-SEED', 'explanation': 'AI-SEEDAI-SEED[records: Relationships (363)]'}, {'summary': '', 'explanation': 'AI-SEEDAI[records: Relationships (566, 567, 568, 569, 570, 571)]'}, {'summary': 'AI-SEED', 'explanation': 'AI-SEEDAI-Seed[records: Relationships (1057)]'}, {'summary': 'AI-SEED', 'explanation': 'AI-SEED[records: Relationships (1052, 1053, 1054, 1058, 1059, 1060, 1061, 1062)]'}]}
18:12:29,41 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI-SEED', 'summary': 'AI-SEEDAIAIAIAIGCVRAI-SEEDAI', 'rating': 8.5, 'rating_explanation': 'AI-SEEDAI', 'findings': [{'summary': '', 'explanation': 'AI-SEEDAI-SEEDAIAIGCAI[records: Relationships (23)]'}, {'summary': 'AI-SEED', 'explanation': 'AI-SEEDAIVRAI-SEEDAIAI[records: Relationships (772, 755, 1055, 1084)]'}, {'summary': 'AI-SEED', 'explanation': 'AI-SEEDAIGCAIAI[records: Relationships (193)]'}, {'summary': '', 'explanation': 'AI-SEEDAIAI[records: Relationships (155, 1084)]'}, {'summary': 'AI-SEED', 'explanation': 'AI-SEEDVRAI-SEEDAIAI[records: Relationships (772, 755, 1055)]'}]}
18:12:29,41 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AI585234AI[records: Entities (289, 293), Relationships (136, 141, 427, 901, 902, 903, 900)]'}, {'summary': 'AI5', 'explanation': 'AI5AI[records: Entities (289, 293), Relationships (136, 141, 427, 901, 902, 903, 900)]'}, {'summary': 'AI8', 'explanation': 'AI8AI[records: Entities (289, 293), Relationships (136, 141, 427, 901, 902, 903, 900)]'}, {'summary': 'AI52', 'explanation': 'AI52AI[records: Entities (289, 293), Relationships (136, 141, 427, 901, 902, 903, 900)]'}, {'summary': 'AI34', 'explanation': 'AI34AI[records: Entities (289, 293), Relationships (136, 141, 427, 901, 902, 903, 900)]'}, {'summary': 'AI11', 'explanation': 'AI11AI[records: Entities (289, 293), Relationships (136, 141, 427, 901, 902, 903, 900)]'}]}
18:12:29,42 graphrag.llm.openai.utils INFO success load json in step 1{'title': ' - ', 'summary': 'AI', 'rating': 8.5, 'rating_explanation': '', 'findings': [{'summary': '', 'explanation': 'AI[records: Relationships (1002, 475, 999, 939)]', 'findings': [{'summary': '', 'explanation': 'AI[records: Relationships (1002, 475, 999, 939)]', 'findings': [{'summary': '', 'explanation': 'AI[records: Relationships (1002, 475, 999, 939)]', 'findings': [{'summary': '', 'explanation': 'AI[records: Relationships (1002, 475, 999, 939)]', 'findings': [{'summary': '', 'explanation': 'AI[records: Relationships (1002, 475, 999, 939)]'}]}]}]}]}]}
18:12:29,42 graphrag.llm.openai.utils INFO success load json in step 1{'title': ' - ', 'summary': 'AI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': 'AI[records: Relationships (989)]'}]}
18:12:29,42 graphrag.llm.openai.utils INFO success load json in step 1{'title': ' - ', 'summary': 'IP', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': 'AI[records: Entities (463), Relationships (1040, 1041, 1042, 1039)]'}, {'summary': 'IP', 'explanation': 'IP[records: Entities (337), Relationships (1008)]'}, {'summary': '', 'explanation': '[records: Entities (340), Relationships (1014)]'}, {'summary': '', 'explanation': '[records: Entities (556), Relationships (1038)]'}, {'summary': '', 'explanation': '[records: Entities (578), Relationships (1039)]'}]}
18:12:29,43 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI - ', 'summary': 'AIAIAIAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AIAI[records: Relationships (118, 455)]', 'data_records': [{'source': '', 'ids': [456, 465, 461, 463, 464], 'reference': ''}]}]}
18:12:29,43 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': '60', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'AI', 'explanation': '60[records: Entities (245, 4), Relationships (173, 40, 3, 854, 39, 32, 35, 38, 41)]'}, {'summary': 'AI', 'explanation': 'AI5AI[records: Relationships (40, 3, 39, 41)]'}, {'summary': 'AI', 'explanation': 'AIAI[records: Relationships (32)]'}, {'summary': 'AI', 'explanation': 'AIAI[records: Relationships (35)]'}, {'summary': 'AI', 'explanation': 'AIAI[records: Relationships (38)]'}]}
18:12:29,44 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'AI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': 'AI[records: Entities (82, 449, 445, 580), Relationships (356, 355, 517, 460, 467, 462, 492, 483, 458, 516, 493, 494, 497, 498, 499, 490, 485, 495, 496, 1023, 1021, 518)]'}]}
18:12:29,44 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIAIAIAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AIAIAIAI[records: Relationships (64, 109, 114, 115, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 3, 31, 37 30, 3, 3, 3399, 37, 33701, 370,  ] ... ...  ]]', ']...]summary] ]]': ']]'}], ']]': ']...)...]...]]'}
18:12:29,269 graphrag.llm.openai.utils INFO success load json in step 1{'title': ' - ', 'summary': 'AIAIAI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': 'AI[records: Relationships (12, 216)]'}]}
18:12:29,271 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'AI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'AI', 'explanation': 'AIAI[records: Entities (19), Relationships (57, 367, 369, 370, 371, 372, 373, 374, 368, 270)]'}, {'summary': 'AI', 'explanation': 'AIAR[records: Entities (27), Relationships (61, 222, 223, 388, 390, 387, 389, 396, 394)]'}, {'summary': 'AI', 'explanation': 'AIAIAI[records: Entities (28), Relationships (62, 391, 393, 381, 383, 384, 386, 396, 394)]'}, {'summary': 'AI', 'explanation': 'AI[records: Entities (25), Relationships (59, 222, 223, 382, 383, 384, 386, 396, 394)]'}, {'summary': 'AI', 'explanation': 'AI[records: Entities (26), Relationships (60, 222, 223, 385, 386, 384, 386, 396, 394)]'}]}
18:12:29,272 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': '985985', 'rating': 8.5, 'rating_explanation': '', 'findings': [{'summary': '985', 'explanation': '985[records: Entities (55, 79), Relationships (79, 272)]'}, {'summary': '', 'explanation': '985[records: Relationships (443)]'}, {'summary': '985', 'explanation': '985[records: Relationships (79, 272, 443)]'}, {'summary': '', 'explanation': '985[records: Entities (55, 79), Relationships (79, 272)]'}, {'summary': '', 'explanation': '[records: Relationships (443)]'}]}
18:12:29,278 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'AIAIGCAIAI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': 'AIAI[records: Entities (9, 267, 268, 269, 270), Relationships (50, 204, 205, 206, 209, 212, 215, 861, 862, 863, 864, 865, 866)]'}, {'summary': '', 'explanation': 'AIAIAI[records: Entities (267), Relationships (315, 316, 317, 318)]'}, {'summary': 'AI', 'explanation': 'AIAIAIAIAIAI[records: Entities (269), Relationships (317)]'}, {'summary': 'AIGC', 'explanation': 'AIGCAIAIGCAIGCAI[records: Entities (270), Relationships (318)]'}, {'summary': 'AI', 'explanation': 'AIAIAIAIAI[records: Entities (268), Relationships (316)]'}]}
18:12:29,278 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'CGAI', 'rating': 8.5, 'rating_explanation': '', 'findings': [{'summary': 'CGAI', 'explanation': 'CGCGAI[records: Entities (56), Relationships (80)]', 'records: Entities (56), Relationships (80)': ['56,CG,CG,3', '80,AI,CG,AICG,152']}]}
18:12:29,279 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIAIAIAIGCAIAIAIAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AIAIAIAIGCAIAIAIAIAI[records: Entities (173, 488, 508, 641, 581, 642, 643, 644), Relationships (773, 291, 777, 774, 778, 779, 780, 781, 782)]'}, {'summary': 'AI', 'explanation': 'AIAIAIAIAI[records: Entities (488, 508), Relationships (776, 774, 778, 779, 780, 781, 782)]'}, {'summary': 'AI', 'explanation': 'AIAIGCAIAIAI[records: Entities (641), Relationships (777)]'}, {'summary': 'AI', 'explanation': 'AIAI[records: Entities (643), Relationships (781)]'}, {'summary': 'AI', 'explanation': 'AIAIAI[records: Entities (644), Relationships (782)]'}]}
18:12:29,280 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AIGC', 'summary': 'AIGCAIGCAIAI', 'rating': 7.5, 'rating_explanation': '', 'findings': [{'summary': 'AIGC', 'explanation': 'AIGCAIAI[records: Entities (63), Relationships (292)]'}, {'summary': '', 'explanation': 'AIGC[records: Entities (62, 60), Relationships (448, 447, 449)]'}, {'summary': 'AIGCAI', 'explanation': 'AIAIGCAI[records: Relationships (451)]'}, {'summary': '', 'explanation': '985CG[records: Entities (60)]'}, {'summary': '', 'explanation': '[records: Relationships (448)]'}]}
18:12:29,284 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI-SEED', 'summary': 'AI-SEEDAI-SEEDAIAIAIGCAI-SEEDAI-SEEDAIAI', 'rating': 8.5, 'rating_explanation': 'AI-SEEDAI', 'findings': [{'summary': 'AI-SEED', 'explanation': 'AI-SEEDAIAIAIAIGCAI[records: Entities (500), Relationships (155, 20, 1058, 1059, 1060, 1056, 1057, 1050, 1051, 1052, 1053, 1054, 1058, 1059, 1060, 1056, 1057, 1050, 1051, 1052, 1053, 1054)]'}, {'summary': 'AI-SEED', 'explanation': 'AI-SEEDAIAIAIAI-SEEDAI[records: Entities (470), Relationships (363, 190, 1047, 1048, 1049, 1052, 1053, 1054, 1058, 1059, 1060, 1056, 1057, 1050, 1051, 1052, 1053, 1054)]'}, {'summary': '', 'explanation': 'AI-Seed[records: Entities (473, 474, 475), Relationships (1052, 1053, 1054, 1058, 1059, 1060, 1056, 1057, 1050, 1051, 1052, 1053, 1054)]'}, {'summary': 'AI', 'explanation': 'AI-SeedAIAIAI-SeedAIAIAI[records: Entities (471, 472), Relationships (1050, 1051, 1052, 1053, 1054, 1056, 1057, 1058, 1059, 1060, 1056, 1057, 1050, 1051, 1052, 1053, 1054)]'}, {'summary': 'AI-SEED', 'explanation': 'AI-SEEDAI-SeedAI-Seed[records: Entities (513, 649), Relationships (1057, 1056, 1058, 1059, 1060, 1056, 1057, 1050, 1051, 1052, 1053, 1054)]'}]}
18:12:29,284 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIAIAIAIAIAI-SeedAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AIAIAIAIAIAIAIAI[records: Entities (511, 584, 507)]'}, {'summary': '', 'explanation': 'AIAIAIAI[records: Relationships (1032, 1087)]'}, {'summary': 'AI-Seed', 'explanation': 'AIAI-SeedAIAI-SeedAIAIAIAI[records: Relationships (1048)]'}, {'summary': '', 'explanation': 'AIAIAIAI[records: Relationships (1086)]'}, {'summary': '', 'explanation': 'AIAIAIAIAI[records: Entities (511, 507)]'}]}
18:12:29,285 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI-Seed', 'summary': 'AI-SeedAIAIAI', 'rating': 8.5, 'rating_explanation': 'AI-SeedAI', 'findings': [{'summary': 'AI-Seed', 'explanation': 'AI-SeedAIAIAIAIAIAIAIAIAI[records: Entities (482, 502, 483, 484, 485)]'}, {'summary': 'AI-Seed', 'explanation': 'AI-SeedAI-SeedAI[records: Relationships (261, 1061, 1062, 1063, 1064, 1065, 1058, 1069, 1083, 1070, 1071, 1072)]'}, {'summary': 'AI', 'explanation': 'AIAI-SeedAIAIAI[records: Entities (502)]'}, {'summary': 'AI', 'explanation': 'AIGCAIAI-SeedAIAI[records: Entities (485)]'}, {'summary': 'AIGCAI-Seed', 'explanation': 'AIGCAI-SeedAI[records: Relationships (187, 1070, 1071, 1072)]'}]}
18:12:29,285 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AIGC', 'summary': 'AIGCAIGCAIGCAI', 'rating': 8.5, 'rating_explanation': 'AIGCAI', 'findings': [{'summary': '', 'explanation': '[records: Entities (85, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, \t]', ']   ]': ']... \t]', '] records<tool_call> ]   ...... records<tool_call><tool_call> ,<tool_call> , \t],': '] NONE ......   ...    NONE NONE \t]'}]}
18:12:29,286 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'VR', 'rating': 8.0, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': '[records: Entities (454), Relationships (555, 761, 1028)]'}, {'summary': '', 'explanation': '[records: Relationships (555)]'}, {'summary': 'VR', 'explanation': 'VRVR[records: Relationships (761)]'}, {'summary': '', 'explanation': '[records: Relationships (882, 1028)]'}, {'summary': '', 'explanation': '[records: Relationships (555)]'}]}
18:12:29,286 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': '', 'rating': 8.0, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': '[records: Entities (118, 462, 119, 97, 1035, 649, 648, 650, 578), Relationships (342, 537, 538, 542, 532, 582, 583, 1035, 649, 648, 650, 578)]'}, {'summary': '', 'explanation': '[records: Relationships (537, 538, 542, 532, 582, 583)]'}, {'summary': '', 'explanation': '[records: Relationships (542, 583)]'}, {'summary': '', 'explanation': '[records: Relationships (532, 578)]'}, {'summary': '', 'explanation': '[records: Relationships (1035, 649, 648, 650, 578)]'}]}
18:12:29,287 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'VR', 'summary': 'VRVRAI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'VR', 'explanation': 'VRVRVRAIVRAIGCAI[records: Entities (170, 627, 587, 628, 762, 763, 764, 765, 766, 767, 768, 770, 771, 772, 760, 761, 769, 757, 758, 759, 769)]'}, {'summary': '', 'explanation': 'VRVRVR[records: Entities (169, 25, 757, 758, 759)]'}, {'summary': '', 'explanation': 'VR[records: Entities (594, 628, 769, 758, 759)]'}, {'summary': 'VRAIGC', 'explanation': 'VRAIGCAIGCVRVRAIGC[records: Entities (763, 764)]'}, {'summary': 'VR', 'explanation': 'VRVR[records: Entities (594, 762)]'}]}
18:27:46,482 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
18:27:46,484 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
18:27:46,484 graphrag.llm.openai.utils INFO Error: JSONDecodeError
18:27:46,484 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
18:27:54,616 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
18:27:54,617 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
18:27:54,617 graphrag.llm.openai.utils INFO Error: JSONDecodeError
18:27:54,617 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
18:28:04,147 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
18:28:04,148 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
18:28:04,148 graphrag.llm.openai.utils INFO Error: JSONDecodeError
18:28:04,148 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
18:42:58,203 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
18:42:58,204 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
18:42:58,205 graphrag.llm.openai.utils INFO Error: JSONDecodeError
18:42:58,205 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
18:43:24,846 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
18:43:24,847 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
18:43:24,847 graphrag.llm.openai.utils INFO Error: JSONDecodeError
18:43:24,847 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
18:43:26,232 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
18:43:26,233 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
18:43:26,233 graphrag.llm.openai.utils INFO Error: JSONDecodeError
18:43:26,233 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
18:58:10,57 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
18:58:10,57 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
18:58:10,58 graphrag.llm.openai.utils INFO Error: JSONDecodeError
18:58:10,58 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
18:58:52,390 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
18:58:52,390 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
18:58:52,391 graphrag.llm.openai.utils INFO Error: JSONDecodeError
18:58:52,391 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
18:58:53,481 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
18:58:53,482 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
18:58:53,482 graphrag.llm.openai.utils INFO Error: JSONDecodeError
18:58:53,482 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
19:13:23,838 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
19:13:23,839 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
19:13:23,839 graphrag.llm.openai.utils INFO Error: JSONDecodeError
19:13:23,839 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
19:13:23,839 graphrag.index.graph.extractors.community_reports.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/index/graph/extractors/community_reports/community_reports_extractor.py", line 58, in __call__
    await self._llm(
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/base_llm.py", line 48, in __call__
    return await self._invoke_json(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_chat_llm.py", line 90, in _invoke_json
    raise RuntimeError(error_msg)
RuntimeError: Failed to generate valid JSON output - Faulty JSON: {}
19:13:23,840 graphrag.index.reporting.file_workflow_callbacks INFO Community Report Extraction Error details=None
19:13:23,840 graphrag.index.verbs.graph.report.strategies.graph_intelligence.run_graph_intelligence WARNING No report found for community: 76
19:14:17,579 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
19:14:17,580 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
19:14:17,580 graphrag.llm.openai.utils INFO Error: JSONDecodeError
19:14:17,580 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
19:14:17,580 graphrag.index.graph.extractors.community_reports.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/index/graph/extractors/community_reports/community_reports_extractor.py", line 58, in __call__
    await self._llm(
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/base_llm.py", line 48, in __call__
    return await self._invoke_json(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_chat_llm.py", line 90, in _invoke_json
    raise RuntimeError(error_msg)
RuntimeError: Failed to generate valid JSON output - Faulty JSON: {}
19:14:17,580 graphrag.index.reporting.file_workflow_callbacks INFO Community Report Extraction Error details=None
19:14:17,580 graphrag.index.verbs.graph.report.strategies.graph_intelligence.run_graph_intelligence WARNING No report found for community: 72
19:14:17,584 graphrag.llm.openai.utils INFO success load json in step 1{'title': ' - ', 'summary': 'IP', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': 'AIAI[records: Entities (463, 342, 335, 337, 340, 556, 578, 577, 329, 341, 538, 569, 571, 622, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573, 571, 573,  records records records records records records    records records    records],    records records records records records records], NONE records records records, NONE records records records records, NONE records records records    NONE records records records records records records       NONE records records records records] \t]'}]}
19:14:17,584 graphrag.llm.openai.utils INFO success load json in step 1{'title': ' - ', 'summary': '', 'rating': 8.5, 'rating_explanation': '', 'findings': [{'summary': '', 'explanation': ''}]}
19:14:17,585 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'AI', 'rating': 8.5, 'rating_explanation': '', 'findings': [{'summary': '', 'explanation': '[records: Entities (338), Relationships (1011, 478, 872, 880, 232, 876, 1009, 899, 994, 996, 995, 997, 993, 998, 946, 999, 1010)]'}]}
19:14:17,585 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI - ', 'summary': 'AIAI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'AI', 'explanation': 'AIAIAI[records: Entities (70, 69), Relationships (122, 121, 355, 354, 356)]'}, {'summary': 'AI', 'explanation': 'AIAI[records: Entities (66), Relationships (118)]'}, {'summary': 'AI', 'explanation': 'AIAI[records: Entities (82), Relationships (356, 458, 457)]'}, {'summary': 'AI', 'explanation': 'AIAI[records: Entities (445, 446, 447, 448, 449, 444, 443), Relationships (460, 465, 467, 462, 461, 463, 464, 461, 463, 464)]'}, {'summary': 'AIAI', 'explanation': 'AIAIAI[records: Entities (66, 82), Relationships (118, 356, 458, 457)]'}]}
19:14:17,586 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': '', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': '[records: Entities (68, 332, 333, 331, 330, 339, 328, 552), Relationships (120, 353, 468, 481, 474, 460, 475, 476, 478, 477, 480, 456, 466, 461, 462, 465, 467, 473, 463, 464, 482, 472, 471, 479, 469, 470, 990, 991, 989, 988, 1012, 986, 489, 498, 992)]'}, {'summary': '', 'explanation': 'AI: 466: 473[records: Relationships (466, 473)]'}, {'summary': '', 'explanation': ': 472: 477[records: Relationships (472, 477)]'}, {'summary': '', 'explanation': 'AI: 469: 470[records: Relationships (469, 470)]'}, {'summary': '', 'explanation': ': 482[records: Relationships (482)]'}]}
19:14:17,586 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': '', 'explanation': 'AI[records: Entities (45), Relationships (421, 422, 423)]'}, {'summary': '', 'explanation': 'NYITMITAIAI[records: Entities (528, 529, 530), Relationships (421, 422, 423)]'}, {'summary': '', 'explanation': 'CSIGMVII  [records: Entities (533, 534, 535, 536, 537, 538, 539, 540), Relationships (430, 431, 432, 433, 434, 435, 436, 437, 438)]'}, {'summary': 'AI', 'explanation': 'AIAIAIAI[records: Entities (533), Relationships (439)]'}, {'summary': '', 'explanation': 'AI[records: Entities (531, 532), Relationships (437, 438)]'}]}
19:14:17,587 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AICSIGMVIIAIAIAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AICSIG', 'explanation': 'AICSIGAIAICSIGAI[records: Relationships (77, 408, 431)]'}, {'summary': 'AIMVII', 'explanation': 'AIMVIIAIAIMVIIAI[records: Relationships (78, 409, 432)]'}, {'summary': 'AI', 'explanation': 'AIAIAI[records: Relationships (441, 442)]'}, {'summary': '', 'explanation': 'AICSIGMVII[records: Entities (53, 54, 408, 409, 431, 432)]'}, {'summary': 'AI', 'explanation': 'AICSIGMVIIAI[records: Relationships (408, 409, 431, 432)]'}]}
19:14:17,587 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': '', 'rating': 8.0, 'rating_explanation': '', 'findings': [{'summary': '', 'explanation': 'ARAI[records: Entities (102, 365, 600, 585, 587), Relationships (125, 365, 600, 585, 587)]'}, {'summary': '', 'explanation': 'AR[records: Entities (457, 883, 1034), Relationships (577, 1034)]'}, {'summary': 'AI', 'explanation': 'AIAIAIAIAI[records: Entities (102, 365, 600), Relationships (125, 365, 600)]'}, {'summary': '', 'explanation': '[records: Entities (102, 582, 583, 584, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597), Relationships (582, 583, 584, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597)]'}, {'summary': 'AR', 'explanation': 'ARAR[records: Entities (457, 522), Relationships (577, 522)]'}]}
19:14:17,588 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'AR/VRAI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'AI', 'explanation': 'AIAR/VRAIAIAR[records: Relationships (714, 262, 886)]'}, {'summary': 'AI', 'explanation': 'AIAIAIAR/VRAR/VR[records: Relationships (645, 629, 894)]'}, {'summary': 'AI', 'explanation': 'AIVRVRVR[records: Relationships (600, 629, 891, 887, 888, 889, 890, 967, 972, 976, 979, 981)]'}, {'summary': 'AI', 'explanation': 'AIAR/VRAR/VRAI[records: Relationships (645, 629, 894, 885)]'}, {'summary': 'AI', 'explanation': 'AIAR/VRAIAIAR[records: Relationships (714, 262, 886)]'}]}
19:14:17,588 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIVRARAIGCAIAI', 'rating': 8.0, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AIVRARAI[records: Entities (296, 318), Relationships (145, 330, 248, 586, 684, 618, 633, 705, 249, 672, 243, 917, 918, 919, 920, 921, 696, 587, 916, 685, 927, 905, 619, 634, 706, 956, 957, 958, 959, 960, 697, 928, 923, 925, 922, 924, 926, 961)]'}, {'summary': '', 'explanation': 'AIVRARAIAI[records: Relationships (249, 587, 916, 685, 928, 956, 957, 958, 959, 960, 697, 928)]'}, {'summary': 'AI', 'explanation': 'AIAIAI[records: Relationships (248)]'}, {'summary': '', 'explanation': 'AI[records: Relationships (586, 587)]'}, {'summary': 'VR', 'explanation': 'VRAIARVR[records: Relationships (672, 685)]'}]}
19:14:17,589 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AIVR', 'summary': 'AIVRVRAIAI', 'rating': 8.5, 'rating_explanation': 'AIVRAI', 'findings': [{'summary': 'AI', 'explanation': 'AIAIAIAI[records: Entities (17), Relationships (58, 262, 267, 260, 247, 249, 261, 221, 258, 255, 256, 257, 259, 191, 263, 264, 265, 270, 246, 268, 690, 687, 686, 688, 689, 585, 626, 623, 622, 624, 625, 640, 711, 637, 708, 636, 707, 638, 709, 639, 710, 683, 269, 617, 266, 268, 632, 704, 965, 970, 974, 977, 968, 969, 962, 963, 964, 973, 702, 699, 698, 263, 264, 265, 269, 617, 266, 268, 632, 704, 965, 970, 974, 977, 968, 969, 962, 963, 964, 973, 702, 699, 698, 933, 960, 930, 957, 929, 956, 931, 958, 932, 959, 695, 693, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 9770, \t   ] ]    \t]                \t]', ']': ']]'}]}
19:14:17,589 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AI', 'rating': 8.0, 'rating_explanation': 'AIAI', 'findings': [{'summary': '', 'explanation': 'AIAI[records: Entities (236), Relationships (184)]'}, {'summary': '', 'explanation': '[records: Entities (234), Relationships (847)]'}, {'summary': '', 'explanation': '[records: Entities (233), Relationships (845)]'}, {'summary': '', 'explanation': 'AI[records: Entities (236, 234, 233), Relationships (184, 847, 845)]'}, {'summary': '', 'explanation': '[records: Entities (234), Relationships (847)]'}]}
19:14:17,590 graphrag.llm.openai.utils INFO success load json in step 1{'title': ' - ', 'summary': '', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': '[records: Relationships (843, 841)]'}, {'summary': '', 'explanation': '[records: Relationships (839)]'}, {'summary': '', 'explanation': '[records: Relationships (837)]'}, {'summary': '', 'explanation': '[records: Relationships (842)]'}, {'summary': '', 'explanation': '[records: Relationships (843)]'}]}
19:14:17,590 graphrag.llm.openai.utils INFO success load json in step 1{'title': ' - ', 'summary': '', 'rating': 8.5, 'rating_explanation': '', 'findings': [{'summary': '', 'explanation': ''}]}
19:14:17,591 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIAIAIAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AIAIAIAI[records: Relationships (173, 136, 40, 141, 427, 3, 854, 39, 32, 35, 38, 41, 904, 901, 902, 903, 900)]'}, {'summary': '', 'explanation': 'AI60AIAI[records: Relationships (173, 40, 141, 427, 3, 854, 39, 32, 35, 38, 41, 904, 901, 902, 903, 900)]'}, {'summary': '', 'explanation': 'AIAIAI[records: Relationships (173, 136, 40, 141, 427, 3, 854, 39, 32, 35, 38, 41, 904, 901, 902, 903, 900)]'}, {'summary': '', 'explanation': 'AIAIAI[records: Relationships (173, 136, 40, 141, 427, 3, 854, 39, 32, 35, 38, 41, 904, 901, 902, 903, 900)]'}, {'summary': '', 'explanation': 'AI852345AI[records: Relationships (173, 136, 40, 141, 427, 3, 854, 39, 32, 35, 38, 41, 904, 901, 902, 903, 900)]'}]}
19:14:17,591 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'AIVRAIAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AIVR[records: Entities (18, 274, 177, 294, 184, 179, 297, 181, 37), Relationships (64, 278, 143, 135, 134, 142, 89, 83, 84, 85, 132, 87, 88, 146, 86, 72, 326, 267, 17, 353, 365, 330, 314, 311, 325, 282, 312, 287, 290, 288, 313, 291, 230, 363, 327, 329, 216, 354, 355, 271, 366, 285, 346, 351, 359, 277, 344, 345, 347, 348, 356, 29, 342, 306, 336, 360, 204, 207, 210, 213, 227, 289, 292, 305, 307, 335, 357, 358, 321, 319, 296, 272, 273, 274, 275, 294, 182, 183, 161, 180, 179, 177, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 179, 184, 181, 182, 183, 161, 180, 17 records... records] ]  ] \t]', '] \t]': ']...'}]}
19:14:22,382 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
19:14:22,382 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
19:14:22,383 graphrag.llm.openai.utils INFO Error: JSONDecodeError
19:14:22,383 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
19:14:22,383 graphrag.index.graph.extractors.community_reports.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/index/graph/extractors/community_reports/community_reports_extractor.py", line 58, in __call__
    await self._llm(
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/base_llm.py", line 48, in __call__
    return await self._invoke_json(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_chat_llm.py", line 90, in _invoke_json
    raise RuntimeError(error_msg)
RuntimeError: Failed to generate valid JSON output - Faulty JSON: {}
19:14:22,383 graphrag.index.reporting.file_workflow_callbacks INFO Community Report Extraction Error details=None
19:14:22,383 graphrag.index.verbs.graph.report.strategies.graph_intelligence.run_graph_intelligence WARNING No report found for community: 83
19:28:41,278 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
19:28:41,279 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
19:28:41,279 graphrag.llm.openai.utils INFO Error: JSONDecodeError
19:28:41,279 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
19:43:57,392 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
19:43:57,393 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
19:43:57,393 graphrag.llm.openai.utils INFO Error: JSONDecodeError
19:43:57,393 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
19:59:16,972 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
19:59:16,973 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
19:59:16,973 graphrag.llm.openai.utils INFO Error: JSONDecodeError
19:59:16,973 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
20:14:33,465 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
20:14:33,466 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
20:14:33,466 graphrag.llm.openai.utils INFO Error: JSONDecodeError
20:14:33,466 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
20:14:33,466 graphrag.index.graph.extractors.community_reports.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/index/graph/extractors/community_reports/community_reports_extractor.py", line 58, in __call__
    await self._llm(
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/base_llm.py", line 48, in __call__
    return await self._invoke_json(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_chat_llm.py", line 90, in _invoke_json
    raise RuntimeError(error_msg)
RuntimeError: Failed to generate valid JSON output - Faulty JSON: {}
20:14:33,467 graphrag.index.reporting.file_workflow_callbacks INFO Community Report Extraction Error details=None
20:14:33,467 graphrag.index.verbs.graph.report.strategies.graph_intelligence.run_graph_intelligence WARNING No report found for community: 84
20:14:33,509 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AI&AI + TransformerAI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'AI&', 'explanation': 'AI&'}]}
20:14:33,509 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIARVRAIARVR', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'AI', 'explanation': 'AIARVR[records: Entities (84, 93, 98, 91, 94, 522, 523, 520, 521, 524), Relationships (123, 277, 522, 523, 520, 521, 524)]'}, {'summary': 'ARVR', 'explanation': 'ARVRARVR[records: Relationships (522, 523)]'}, {'summary': '', 'explanation': '[records: Relationships (520)]'}, {'summary': '', 'explanation': '[records: Relationships (521)]'}, {'summary': '', 'explanation': '[records: Relationships (524)]'}]}
20:14:33,509 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIAI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'AI', 'explanation': 'AIAIAIAIAIAI[records: Entities (194, 197, 196, 195'}]}
20:14:33,513 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI - ', 'summary': 'AIIPAIIP', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AIAI[records: Entities (67), Relationships (119)]'}, {'summary': 'AI', 'explanation': 'AIAI[records: Entities (64), Relationships (116)]'}, {'summary': 'AIIP', 'explanation': 'AIIPAIIPIP[records: Entities (65), Relationships (117)]'}, {'summary': '', 'explanation': '[records: Entities (67), Relationships (455)]'}, {'summary': 'IP', 'explanation': 'IP[records: Entities (64), Relationships (453)]'}]}
20:14:33,513 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'VR/AR/MRAIAIGCAIAI', 'rating': 8.5, 'rating_explanation': '', 'findings': [{'summary': '', 'explanation': 'VR/AR/MRAIAIGCAIAIAI[records: Entities (10, 11, 12, 9, 267, 269, 270, 268, 525), Relationships (4, 51, 52, 53, 50, 17, 207, 210, 213, 204, 315, 317, 318, 316, 16, 5, 22, 24, 25, 15, 20, 12, 21, 26, 0, 2, 3, 18, 6, 11, 208, 211, 214, 205, 861, 209, 206, 212, 215, 862, 866, 864, 865, 863)]'}, {'summary': '', 'explanation': 'AI[records: Entities (267), Relationships (315)]'}, {'summary': '', 'explanation': 'AIAI[records: Entities (11), Relationships (52)]'}, {'summary': '', 'explanation': 'AIAIAI[records: Entities (12), Relationships (53)]'}, {'summary': '', 'explanation': 'AIAIAI[records: Entities (9), Relationships (50)]'}]}
20:14:33,514 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIAIAI', 'rating': 8.5, 'rating_explanation': 'AIAIAI', 'findings': [{'summary': '', 'explanation': '60AI[records: Relationships (114, 327, 30, 854, 34, 37, 39, 855, 856, 858, 857)]'}, {'summary': 'AI', 'explanation': 'AIAIAIAI[records: Relationships (858)]'}, {'summary': '', 'explanation': 'AI[records: Relationships (859)]'}, {'summary': '', 'explanation': '[records: Relationships (786)]'}, {'summary': '', 'explanation': 'AIAI[records: Relationships (857)]'}]}
20:14:33,514 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'AI', 'rating': 8.5, 'rating_explanation': '', 'findings': [{'summary': '', 'explanation': 'AI[records: Entities (1, 5), Relationships (28, 29, 30, 31, 32, 789, 790, 787, 788, 27)]'}, {'summary': '', 'explanation': 'AI[records: Relationships (93)]'}, {'summary': '', 'explanation': 'AI[records: Relationships (94)]'}, {'summary': '', 'explanation': 'AI[records: Relationships (91)]'}, {'summary': '', 'explanation': 'AI[records: Relationships (92)]'}]}
20:14:33,518 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'AIVRAI-SEEDAIAIAIAI', 'rating': 8.5, 'rating_explanation': '', 'findings': [{'summary': '', 'explanation': 'AIVRAI-SEEDAIAIAIAI'}]}
20:15:34,984 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
20:15:34,984 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIAIAIAIAIAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AIAIAIAI[records: Entities (487, 495, 501, 504), Relationships (1073, 1074, 1075, 1081, 1082)]'}, {'summary': 'AIAI-Seed', 'explanation': 'AIAI-SeedAIAIAI[records: Entities (501), Relationships (1081)]'}, {'summary': 'AIAI', 'explanation': 'AIAIAIAIAIAI[records: Entities (487), Relationships (1074)]'}, {'summary': 'AIAI', 'explanation': 'AIAIAIAIAIAI[records: Entities (504), Relationships (1082)]'}, {'summary': 'AI', 'explanation': 'AIAIAIAIAIAIAI[records: Entities (487, 495, 501, 504), Relationships (1073, 1074, 1075, 1081, 1082)]'}]}
20:15:34,985 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 61.46556298574433. input_tokens=2498, output_tokens=1052
20:16:37,894 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
20:16:37,895 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIAIAIAIGCAIAIAIAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AIAIAIAIAIAIAI[records: Entities (173, 291, 292, 777, 774, 775, 776, 778, 779, 780, 781, 782), Relationships (158, 291, 292, 192, 777, 774, 775, 776, 778, 779, 780, 781, 782)]'}, {'summary': 'AIGC', 'explanation': 'AIGCAIAI[records: Entities (63, 292, 192), Relationships (451, 192)]'}, {'summary': '', 'explanation': 'AI[records: Entities (219, 777), Relationships (219, 777)]'}, {'summary': 'AI', 'explanation': 'AIAIAIAI[records: Entities (488, 776), Relationships (776, 488)]'}, {'summary': 'AI', 'explanation': 'AIAIAI[records: Entities (508, 774), Relationships (774, 508)]'}]}
20:16:37,895 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 62.905835586134344. input_tokens=4006, output_tokens=1154
20:17:38,402 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
20:17:38,403 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AIGC', 'summary': 'AIGCAIGCAIGCAIGC', 'rating': 8.0, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': 'AIGCAIGCAIGCAIGC[records: Entities (78), Relationships (450, 514, 515)]'}, {'summary': 'AIGC', 'explanation': 'AIGCAIGCAIGCAIGC[records: Relationships (514)]'}, {'summary': '', 'explanation': 'AIGC[records: Relationships (515)]'}, {'summary': 'AIGC', 'explanation': 'AIGCAIGCAIGCAIGC[records: Relationships (450)]'}, {'summary': 'AIGC', 'explanation': 'AIGCAIGCAIGCAIGC[records: Relationships (514, 515)]'}]}
20:17:38,403 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 60.50394763518125. input_tokens=2210, output_tokens=1371
20:20:21,285 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
20:20:21,286 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
20:20:21,286 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title" 	: 	"AIAIGC" 	,      	"summary" 	: 	"AIAIGCAIAI" 	,      	"rating" 	: 	8.5 	,      	"rating_explanation" 	: 	"AIAIGC" 	,      	"findings" 	: 	[              	{                      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AIAI[records: Entities (489, 490), Relationships (778, 780, 1077)]" 	,              	" 	} 	,              	{                      	" 	: 	"AIGCAI" 	,                      	"explanation" 	: 	"AIGCAIAIAI[records: Entities (491), Relationships (780, 1078)]" 	,              	" 	} 	,              	{                      	" 	: 	"" 	,                      	"explanation" 	: 	"[records: Entities (492), Relationships (1079)]" 	,              	" 	} 	,              	{                      	" 	: 	"" 	,                      	"explanation" 	: 	"[records: Entities (493), Relationships (1080)]" 	,              	" 	} 	,              	{                      	" 	: 	"AI" 	,                      	"explanation" 	: 	"AIAIGCAIAI[records: Entities (489, 491), Relationships (778, 780, 1078, 1079, 1080)]" 	,              	" 	} 	]   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,   } 	,
20:20:21,287 graphrag.llm.openai.utils INFO success load json in step 3{'title': 'AIAIGC', 'summary': 'AIAIGCAIAI', 'rating': 8.5, 'rating_explanation': 'AIAIGC', 'findings': [{'summary': 'AI', 'explanation': 'AIAI[records: Entities (489, 490), Relationships (778, 780, 1077)]" \t,'}, {' \t:': 'IGCAI', 'explanation': 'AIGCAIAIAI[records: Entities (491), Relationships (780, 1078)]" \t,'}, {' \t:': '', 'explanation': '[records: Entities (492), Relationships (1079)]" \t,'}, {' \t:': '', 'explanation': '[records: Entities (493), Relationships (1080)]" \t,'}, {' \t:': 'AI', 'explanation': 'AIAIGCAIAI[records: Entities (489, 491), Relationships (778, 780, 1078, 1079, 1080)]" \t,'}]}
20:20:21,288 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 162.88045964203775. input_tokens=2806, output_tokens=2472
20:22:49,923 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
20:22:49,924 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
20:22:49,924 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title" 	: 	"AIGC - " 	,      	"summary" 	: 	"AIGCAIGCAI-SeedAI-SeedAIAI" 	,      	"rating" 	: 	8.5 	,      	"rating_explanation" 	: 	"AI" 	,      	"findings" 	: 	[          	{              	"summary" 	: 	"AIAIGC" 	,              	"explanation" 	: 	"AIAIGCAIAIAIAIAIGCAIAIGC[records: Entities (7, 500, 470, 482, 502, 483, 484, 485, 505, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 13
20:22:49,925 graphrag.llm.openai.utils INFO success load json in step 3{'title': 'AIGC - ', 'summary': 'AIGCAIGCAI-SeedAI-SeedAIAI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'AIAIGC', 'explanation': 'AIAIGCAIAIAIAIAIGCAIAIGC[records: Entities (7, 500, 470, 482, 502, 483, 484, 485, 505, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 13'}]}
20:22:49,926 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 148.6320306318812. input_tokens=6673, output_tokens=4093
20:25:28,264 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
20:25:28,264 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
20:25:28,265 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title" 	: 	"" 	,      	"summary" 	: 	"VRAIGCAI" 	,      	"rating" 	: 	8.5 	,      	"rating_explanation" 	: 	"" 	,      	"findings" 	: 	[          	{              	"summary" 	: 	"AI" 	,              	"explanation" 	: 	"AIAIAI[records: Entities (479), Relationships (156, 157, 152, 166)]" 	,          	" 	,          	{              	" 	: 	"VR" 	,              	"explanation" 	: 	"VRVR[records: Relationships (290, 288, 289, 24, 25, 749, 730)]" 	,          	" 	,          	{              	" 	: 	"AIGC" 	,              	"explanation" 	: 	"AIGCAI[records: Entities (317), Relationships (950, 762, 745, 188, 763, 767, 766, 765, 769, 771, 772, 770, 768, 764, 761, 753, 757, 756, 755, 754, 752, 751, 750, 748, 747, 746, 744, 743, 742, 741, 740, 739, 738, 737, 736, 735, 734, 733, 732, 731, 730, 729, 728, 727, 726, 725, 724, 723, 722, 721, 720, 719, 718, 717, 716, 715, 714, 713, 712, 711, 710, 709, 708, 707, 706, 705, 704, 703, 702, 701, 700, 699, 698, 697, 696, 695, 694, 693, 692, 691, 690, 689, 688, 687, 686, 685, 684, 683, 682, 681, 680, 679, 678, 677, 676, 675, 674, 673, 672, 671, 670, 669, 668, 667, 666, 665, 664, 663, 662, 661, 660, 659, 658, 657, 656, 655, 654, 653, 652, 651, 650, 649, 648, 647, 646, 645, 644, 643, 642, 641, 640, 639, 638, 637, 636, 635, 634, 633, 632, 631, 630, 629, 628, 627, 626, 625, 624, 623, 622, 621, 620, 619, 618, 617, 616, 615, 614, 613, 612, 611, 610, 609, 608, 607, 606, 605, 604, 603, 602, 601, 600, 599, 598, 597, 596, 595, 594, 593, 592, 591, 590, 589, 588, 587, 586, 585, 584, 583, 582, 581, 580, 579, 578, 577, 576, 575, 574, 573, 572, 571, 570, 569, 568, 567, 566, 565, 564, 563, 562, 561, 560, 559, 558, 557, 556, 555, 554, 553, 552, 551, 550, 549, 548, 547, 546, 545, 544, 543, 542, 541, 540, 539, 538, 537, 536, 535, 534, 533, 532, 531, 530, 529, 528, 527, 526, 525, 524, 523, 522, 521, 520, 519, 518, 517, 516, 515, 514, 513, 512, 511, 510, 509, 508, 507, 506, 505, 504, 503, 502, 501, 500, 499, 498, 497, 496, 495, 494, 493, 492, 491, 490, 489, 488, 487, 486, 485, 484, 483, 482, 481, 480, 479, 478, 477, 476, 475, 474, 473, 472, 471, 470, 469, 468, 467, 466, 465, 464, 463, 462, 461, 460, 459, 458, 457, 456, 455, 454, 453, 452, 451, 450, 449, 448, 447, 446, 445, 444, 443, 442, 441, 440, 439, 438, 437, 436, 435, 434, 433, 432, 431, 430, 429, 428, 427, 426, 425, 424, 423, 422, 421, 420, 419, 418, 417, 416, 415, 414, 413, 412, 411, 410, 409, 408, 407, 406, 405, 404, 403, 402, 401, 400, 399, 398, 397, 396, 395, 394, 393, 392, 391, 390, 389, 388, 387, 386, 385, 384, 383, 382, 381, 380, 379, 378, 377, 376, 375, 374, 373, 372, 371, 370, 369, 368, 367, 366, 365, 364, 363, 362, 361, 360, 359, 358, 357, 356, 355, 354, 353, 352, 351, 350, 349, 348, 347, 346, 345, 344, 343, 342, 341, 340, 339, 338, 337, 336, 335, 334, 333, 332, 331, 330, 329, 328, 327, 326, 325, 324, 323, 322, 321, 320, 319, 318, 317, 316, 315, 314, 313, 312, 311, 310, 309, 308, 307, 306, 305, 304, 303, 302, 301, 300, 299, 298, 297, 296, 295, 294, 293, 292, 291, 290, 289, 288, 287, 286, 285, 284, 283, 282, 281, 280, 279, 278, 277, 276, 275, 274, 273, 272, 271, 270, 269, 268, 267, 266, 265, 264, 263, 262, 261, 260, 259, 258, 257, 256, 255, 254, 253, 252, 251, 250, 249, 248, 247, 246, 245, 244, 243, 242, 241, 240, 239, 238, 237, 236, 235, 234, 233, 232, 231, 230, 229, 228, 227, 226, 225, 224, 223, 222, 221, 220, 219, 218, 217, 216, 215, 214, 213, 212, 211, 210, 209, 208, 207, 206, 205, 204, 203, 202, 201, 200, 199, 198, 197, 196, 195, 194, 193, 192, 191, 190, 189, 188, 187, 186, 185, 184, 183, 182, 181, 180, 179, 178, 177, 176, 175, 174, 173, 172, 171, 170, 169, 168, 167, 166, 165, 164, 163, 162, 161, 160, 159, 158, 157, 156, 155, 154, 153, 152, 151, 150, 149, 148, 147, 146, 145, 144, 143, 142, 141, 140, 139, 138, 137, 136, 135, 134, 133, 132, 131, 130, 129, 128, 127, 126, 125, 124, 123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 95, 94, 93, 92, 91, 90, 89, 88, 87, 86, 85, 84, 83, 82, 81, 80, 79, 78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68, 67, 66, 65, 64, 63, 62, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45, 44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1] 	,          	} 	,          	{              	" 	,              	"explanation" 	: 	"AIGC[records: Entities (317), Relationships (950, 762, 745, 188, 763, 767, 766, 765, 769, 771, 772, 770, 768, 764, 761, 753, 757, 756, 755, 754, 752, 751, 750, 748, 747, 746, 744, 743, 742, 741, 740, 739, 738, 737, 736, 735, 734, 733, 732, 731, 730, 729, 728, 727, 726, 725, 724, 723, 722, 721, 720, 719, 718, 717, 716, 715, 714, 713, 712, 711, 710, 709, 708, 707, 706, 705, 704, 703, 702, 701, 700, 699, 698, 697, 696, 695, 694, 693, 692, 691, 690, 689, 688, 687, 686, 685, 684, 683, 682, 681, 680, 679, 678, 677, 676, 675, 674, 673, 672, 671, 670, 669, 668, 667, 666, 665, 664, 663, 662, 661,
20:25:28,266 graphrag.llm.openai.utils INFO success load json in step 3{'title': '', 'summary': 'VRAIGCAI', 'rating': 8.5, 'rating_explanation': '', 'findings': [{'summary': 'AI', 'explanation': 'AIGC[records: Entities (317), Relationships (950, 762, 745, 188, 763, 767, 766, 765, 769, 771, 772, 770, 768, 764, 761, 753, 757, 756, 755, 754, 752, 751, 750, 748, 747, 746, 744, 743, 742, 741, 740, 739, 738, 737, 736, 735, 734, 733, 732, 731, 730, 729, 728, 727, 726, 725, 724, 723, 722, 721, 720, 719, 718, 717, 716, 715, 714, 713, 712, 711, 710, 709, 708, 707, 706, 705, 704, 703, 702, 701, 700, 699, 698, 697, 696, 695, 694, 693, 692, 691, 690, 689, 688, 687, 686, 685, 684, 683, 682, 681, 680, 679, 678, 677, 676, 675, 674, 673, 672, 671, 670, 669, 668, 667, 666, 665, 664, 663, 662, 661,', ' \t,          \t{': 'AIGC'}]}
20:25:28,266 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 158.33504740800709. input_tokens=7137, output_tokens=1604
20:26:32,121 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
20:26:32,122 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': '', 'rating': 7.5, 'rating_explanation': '', 'findings': [{'summary': '', 'explanation': '[records: Entities (595, 104, 105, 103, 106), Relationships (560, 551, 552, 550, 553)]'}, {'summary': '', 'explanation': '[records: Relationships (551, 552, 550, 553)]'}, {'summary': '', 'explanation': '[records: Entities (104, 105, 103, 106)]'}, {'summary': '', 'explanation': '[records: Relationships (895)]'}, {'summary': '', 'explanation': '[records: Relationships (1035)]'}]}
20:26:32,123 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 63.85206018295139. input_tokens=3225, output_tokens=1396
20:28:13,861 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
20:28:13,861 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI - ', 'summary': 'AIAIAIGC', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': '', 'explanation': 'AIAIGC[records: Entities (463, 342, 335, 336, 338, 337, 340, 556, 334, 578, 577, 451, 329, 341, 450, 538, 569, 570, 572, 573, 622), Relationships (1017, 1002, 1005, 1011, 510, 1008, 1014, 512, 519, 1025, 1027, 872, 1040, 1041, 1042, 1038, 1039, 877, 878, 880, 879, 232, 896, 876, 999, 1003, 1009, 1006, 1007, 667, 990, 899, 986, 988, 989, 1012, 987, 1016, 994, 996, 995, 998, 941, 946, 997, 993, 939, 1000, 1001, 1004, 1010, 1007, 1015, 1100)]'}, {'summary': '', 'explanation': 'AIIP[records: Entities (342, 336, 338, 337, 340, 556, 334, 578, 577, 451, 329, 341, 450, 538, 569, 570, 572, 573, 622), Relationships (468, 475, 476, 478, 503, 506, 477, 480, 1038, 519, 1025, 1027, 872, 1040, 1041, 1042, 1038, 1039, 877, 878, 880, 879, 232, 896, 876, 999, 1003, 1009, 1006, 1007, 667, 990, 899, 986, 988, 989, 1012, 987, 1016, 994, 996, 995, 998, 941, 946, 997, 993, 939, 1000, 1001, 1004, 1010, 1007, 1015, 1100)]'}, {'summary': '', 'explanation': 'IP[records: Entities (335, 336, 338, 337, 340, 556, 334, 578, 577, 451, 329, 341, 450, 538, 569, 570, 572, 573, 622), Relationships (1002, 1005, 1011, 510, 1008, 1014, 512, 877, 878, 880, 879, 232, 896, 876, 999, 1003, 1009, 1006, 1007, 667, 990, 899, 986, 988, 989, 1012, 987, 1016, 994, 996, 995, 998, 941, 946, 997, 993, 939, 1000, 1001, 1004, 1010, 1007, 1015, 1100)]'}, {'summary': '', 'explanation': '[records: Entities (336, 337, 340, 556, 334, 578, 577, 451, 329, 341, 450, 538, 569, 570, 572, 573, 622), Relationships (1005, 1011, 510, 1008, 1014, 512, 994, 996, 995, 998, 941, 946, 997, 993, 939, 1000, 1001, 1004, 1010, 1007, 1015, 1100)]'}, {'summary': '', 'explanation': '[records: Entities (338, 337, 340, 556, 334, 578, 577, 451, 329, 341, 450, 538, 569, 570, 572, 573, 622), Relationships (1011, 510, 1008, 1014, 512, 996, 995, 998, 941, 946, 997, 993, 939, 1000, 1001, 1004, 1010, 1007, 1015, 1100)]'}]}
20:28:13,862 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 101.73387205181643. input_tokens=7599, output_tokens=2412
20:43:42,991 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
20:43:42,992 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
20:43:42,992 graphrag.llm.openai.utils INFO Error: JSONDecodeError
20:43:42,992 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
20:44:42,586 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
20:44:42,586 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
20:44:42,587 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
20:44:42,587 graphrag.llm.openai.utils INFO Error: JSONDecodeError
20:44:42,587 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
20:44:42,591 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
20:44:42,591 graphrag.llm.openai.utils INFO Error: JSONDecodeError
20:44:42,591 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
20:59:18,143 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
20:59:18,144 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
20:59:18,144 graphrag.llm.openai.utils INFO Error: JSONDecodeError
20:59:18,144 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
21:14:40,534 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
21:14:40,534 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
21:14:40,534 graphrag.llm.openai.utils INFO Error: JSONDecodeError
21:14:40,535 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
21:15:00,139 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
21:15:00,140 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
21:15:00,140 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
21:15:00,140 graphrag.llm.openai.utils INFO Error: JSONDecodeError
21:15:00,140 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
21:15:00,143 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
21:15:00,143 graphrag.llm.openai.utils INFO Error: JSONDecodeError
21:15:00,143 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
21:30:08,466 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
21:30:08,466 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
21:30:08,466 graphrag.llm.openai.utils INFO Error: JSONDecodeError
21:30:08,466 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
21:30:08,467 graphrag.index.graph.extractors.community_reports.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/index/graph/extractors/community_reports/community_reports_extractor.py", line 58, in __call__
    await self._llm(
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/base_llm.py", line 48, in __call__
    return await self._invoke_json(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_chat_llm.py", line 90, in _invoke_json
    raise RuntimeError(error_msg)
RuntimeError: Failed to generate valid JSON output - Faulty JSON: {}
21:30:08,467 graphrag.index.reporting.file_workflow_callbacks INFO Community Report Extraction Error details=None
21:30:08,467 graphrag.index.verbs.graph.report.strategies.graph_intelligence.run_graph_intelligence WARNING No report found for community: 35
21:31:30,662 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
21:31:30,662 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'IPAI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': 'IPAI[records: Entities (73, 280, 625), Relationships (359, 360, 358, 357, 361, 510, 474, 512, 506, 503, 501, 508, 507, 504, 502, 509, 516, 519, 869, 896, 897, 899, 898, 511, 505, 504, 501, 508, 459, 453)]'}, {'summary': 'IP', 'explanation': 'IPIPIPIPIP[records: Entities (74, 73, 280, 625), Relationships (359, 360, 358, 357, 361, 510, 474, 512, 506, 503, 501, 508, 507, 504, 502, 509, 516, 519, 869, 896, 897, 899, 898, 511, 505, 504, 501, 508, 459, 453)]'}, {'summary': '', 'explanation': 'AIIP[records: Entities (72, 73, 280, 625), Relationships (359, 360, 358, 357, 361, 510, 474, 512, 506, 503, 501, 508, 507, 504, 502, 509, 516, 519, 869, 896, 897, 899, 898, 511, 505, 504, 501, 508, 459, 453)]'}, {'summary': '', 'explanation': 'IP[records: Entities (73, 74, 280, 625), Relationships (359, 360, 358, 357, 361, 510, 474, 512, 506, 503, 501, 508, 507, 504, 502, 509, 516, 519, 869, 896, 897, 899, 898, 511, 505, 504, 501, 508, 459, 453)]'}, {'summary': 'AI', 'explanation': 'AIAIAIAIIP[records: Entities (73, 74, 280, 625), Relationships (359, 360, 358, 357, 361, 510, 474, 512, 506, 503, 501, 508, 507, 504, 502, 509, 516, 519, 869, 896, 897, 899, 898, 511, 505, 504, 501, 508, 459, 453)]'}]}
21:31:30,663 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 82.19170172978193. input_tokens=4620, output_tokens=1815
21:32:41,126 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
21:32:41,127 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI - ', 'summary': 'AIAIAIAI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': 'AI[records: Entities (68), Relationships (468, 481, 474, 460, 475, 476, 478, 456, 477, 480, 465, 467, 466, 462, 461, 463, 464, 469, 470, 472, 471, 479, 468, 482)]'}, {'summary': '', 'explanation': 'AIAI[records: Entities (68, 70, 69), Relationships (356, 492, 483, 990, 458, 457, 989, 988, 1012, 986, 518)]'}, {'summary': '', 'explanation': '[records: Relationships (456, 475, 476, 478, 469, 470, 472, 471, 479, 468, 482)]'}, {'summary': '', 'explanation': 'AI[records: Entities (70), Relationships (355, 500, 492, 1023)]'}, {'summary': '', 'explanation': 'AI[records: Entities (69), Relationships (354, 498, 499, 516, 488, 489, 490)]'}]}
21:32:41,128 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 70.45942329103127. input_tokens=7054, output_tokens=1545
21:45:12,684 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
21:45:12,684 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
21:45:12,685 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
21:45:12,685 graphrag.llm.openai.utils INFO Error: JSONDecodeError
21:45:12,686 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
21:45:12,689 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
21:45:12,690 graphrag.llm.openai.utils INFO Error: JSONDecodeError
21:45:12,690 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
21:48:05,328 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
21:48:05,329 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
21:48:05,329 graphrag.llm.openai.utils INFO Error: JSONDecodeError
21:48:05,329 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
22:03:29,958 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
22:03:29,959 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
22:03:29,959 graphrag.llm.openai.utils INFO Error: JSONDecodeError
22:03:29,959 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
22:15:23,503 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
22:15:23,503 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
22:15:23,504 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
22:15:23,504 graphrag.llm.openai.utils INFO Error: JSONDecodeError
22:15:23,504 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
22:15:23,504 graphrag.index.graph.extractors.community_reports.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/index/graph/extractors/community_reports/community_reports_extractor.py", line 58, in __call__
    await self._llm(
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/base_llm.py", line 48, in __call__
    return await self._invoke_json(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_chat_llm.py", line 90, in _invoke_json
    raise RuntimeError(error_msg)
RuntimeError: Failed to generate valid JSON output - Faulty JSON: {}
22:15:23,504 graphrag.index.reporting.file_workflow_callbacks INFO Community Report Extraction Error details=None
22:15:23,504 graphrag.index.verbs.graph.report.strategies.graph_intelligence.run_graph_intelligence WARNING No report found for community: 24
22:15:23,507 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
22:15:23,508 graphrag.llm.openai.utils INFO Error: JSONDecodeError
22:15:23,508 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
22:15:23,508 graphrag.index.graph.extractors.community_reports.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/index/graph/extractors/community_reports/community_reports_extractor.py", line 58, in __call__
    await self._llm(
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/base_llm.py", line 48, in __call__
    return await self._invoke_json(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_chat_llm.py", line 90, in _invoke_json
    raise RuntimeError(error_msg)
RuntimeError: Failed to generate valid JSON output - Faulty JSON: {}
22:15:23,508 graphrag.index.reporting.file_workflow_callbacks INFO Community Report Extraction Error details=None
22:15:23,508 graphrag.index.verbs.graph.report.strategies.graph_intelligence.run_graph_intelligence WARNING No report found for community: 19
22:17:15,411 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
22:17:15,412 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AITransformerAINeRFAI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'AI', 'explanation': 'AITransformerNeRFAIAI[records: Entities (295, 302, 303, 309, 312, 308), Relationships (144, 329, 906, 910, 911, 912, 913, 907, 908, 909, 914)]'}, {'summary': 'AI', 'explanation': 'AIAIAI[records: Entities (312), Relationships (922, 939)]'}, {'summary': 'NeRF', 'explanation': 'NeRFNeRFNeRFAI[records: Entities (308), Relationships (912)]'}, {'summary': '', 'explanation': 'AINeRFAI[records: Relationships (906, 910, 911, 912, 907, 908, 909, 913)]'}, {'summary': 'AI', 'explanation': 'AIAI[records: Relationships (939)]'}]}
22:17:15,412 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 111.90004257205874. input_tokens=3198, output_tokens=1181
22:18:48,175 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
22:18:48,175 graphrag.llm.openai.utils INFO success load json in step 1{'title': ' - ', 'summary': '', 'rating': 7.5, 'rating_explanation': '', 'findings': [{'summary': 'AI', 'explanation': '[records: Entities (307), Relationships (911)]'}, {'summary': '', 'explanation': 'AI[records: Entities (546), Relationships (936)]'}, {'summary': '', 'explanation': '[records: Entities (307)]'}, {'summary': '', 'explanation': '[records: Entities (546), Relationships (936)]'}, {'summary': '', 'explanation': '[records: Entities (307)]'}]}
22:18:48,176 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 92.759041022975. input_tokens=2115, output_tokens=1160
22:18:56,227 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
22:18:56,227 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
22:18:56,227 graphrag.llm.openai.utils INFO Error: JSONDecodeError
22:18:56,227 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
22:19:40,174 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
22:19:40,174 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'RGB - ', 'summary': 'RGBRGB', 'rating': 8.0, 'rating_explanation': 'RGBAI', 'findings': [{'summary': 'RGB', 'explanation': 'RGBRGB[records: Entities (310), Relationships (914)]'}, {'summary': 'RGB', 'explanation': 'AIRGBRGBRGB[records: Relationships (937)]'}]}
22:19:40,174 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 51.99451629817486. input_tokens=2085, output_tokens=621
22:21:15,532 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
22:21:15,533 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'AI', 'rating': 7.5, 'rating_explanation': '', 'findings': [{'summary': '', 'explanation': 'AI[records: Entities (311), Relationships (915)]'}, {'summary': '', 'explanation': 'AI[records: Relationships (938)]'}, {'summary': '', 'explanation': '[records: Relationships (938)]'}, {'summary': '', 'explanation': '[records: Entities (311)]'}, {'summary': '', 'explanation': '[records: Entities (549)]'}]}
22:21:15,533 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 95.35466813389212. input_tokens=2164, output_tokens=1018
22:22:07,717 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
22:22:07,718 graphrag.llm.openai.utils INFO success load json in step 1{'title': ' - ', 'summary': '', 'rating': 8.0, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': '[records: Entities (306), Relationships (910)]'}, {'summary': '', 'explanation': '[records: Relationships (935)]'}]}
22:22:07,718 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 52.18061051797122. input_tokens=2108, output_tokens=575
22:24:44,321 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
22:24:44,321 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
22:24:44,321 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title" 	: 	"" 	,      	"summary" 	: 	"AIAI" 	,      	"rating" 	: 	8.5 	,      	"rating_explanation" 	: 	"AI" 	,      	"findings" 	: 	[              	{                  	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AIAI[records: Entities (452, 453, 455), Relationships (352, 1024)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Entities (452, 453, 455), Relationships (352, 1024, 1025)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Entities (452, 453, 455), Relationships (1027, 1026, 482)]" 	,              	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAI[records: Entities (452, 453, 455), Relationships (1024, 1025)]" 	,              	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAI[records: Entities (452, 453, 455), Relationships (1026)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Entities (452, 453, 455), Relationships (1025, 1027)]" 	,              	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAIAIAI[records: Entities (452, 453, 455), Relationships (1024, 1026)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AIAI[records: Entities (452, 453, 455), Relationships (352, 1024, 1025, 1026, 1027)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AIAI[records: Entities (452, 453, 455), Relationships (1024, 1025, 1026, 1027)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AIAIAI[records: Entities (452, 453, 455), Relationships (1024, 1025, 1026, 1027)]" 	,          	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AIAI[records: Entities (452, 453, 455), Relationships (1024, 1025, 1026, 1027)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AIAI[records: Entities (452, 453, 455), Relationships (352, 1024, 1025, 1026, 1027)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Entities (452, 453, 455), Relationships (352, 1024, 1025, 1026, 1027)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAIAI[records: Entities (452, 453, 455), Relationships (1024, 1025, 1026, 1027)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AIAI[records: Entities (452, 453, 455), Relationships (1026)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AIAI[records: Entities (452, 453, 455), Relationships (1024, 1025)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Entities (452, 453, 455), Relationships (1025)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AIAI[records: Entities (452, 453, 455), Relationships (1026)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Entities (452, 453, 455), Relationships (482)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Entities (452, 453, 455), Relationships (1027)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAIAI[records: Entities (452, 453, 455), Relationships (1024, 1025)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAI[records: Entities (452, 453, 455), Relationships (1026)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Entities (452, 453, 455), Relationships (1025)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"AI[records: Entities (452, 453, 455), Relationships (1027)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAIAIAI[records: Entities (452, 453, 455), Relationships (1024)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAI[records: Entities (452, 453, 455), Relationships (1026)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAIAIAI[records: Entities (452, 453, 455), Relationships (1024)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAI[records: Entities (452, 453, 455), Relationships (1026)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAI[records: Entities (452, 453, 455), Relationships (1024, 1026)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAI[records: Entities (452, 453, 455), Relationships (1024, 1026)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAI[records: Entities (452, 453, 455), Relationships (1024, 1026)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAI[records: Entities (452, 453, 455), Relationships (1024, 1026)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAI[records: Entities (452, 453, 455), Relationships (1024, 1026)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAI[records: Entities (452, 453, 455), Relationships (1024, 1026)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAI[records: Entities (452, 453, 455), Relationships (1024, 1026)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAI[records: Entities (452, 453, 455), Relationships (1024, 1026)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAI[records: Entities (452, 453, 455), Relationships (1024, 1026)]" 	,      	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAI
22:24:44,323 graphrag.llm.openai.utils INFO success load json in step 3{'title': '', 'summary': 'AIAI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'AI', 'explanation': 'AIAI'}]}
22:24:44,324 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 560.8144032550044. input_tokens=2346, output_tokens=1040
22:26:01,290 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
22:26:01,291 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'AIAIAIAI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': 'AIAI[records: Entities (51, 481), Relationships (147, 406, 410)]'}, {'summary': 'AI', 'explanation': 'AIAIAIAIAI[records: Relationships (147, 430)]'}, {'summary': 'AI', 'explanation': 'AI[records: Relationships (171, 410)]'}, {'summary': '', 'explanation': '[records: Relationships (19, 1068, 1067, 1111, 1112)]'}, {'summary': '', 'explanation': '[records: Relationships (440, 851, 852)]'}]}
22:26:01,291 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 76.96325692534447. input_tokens=3391, output_tokens=1467
22:27:21,203 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
22:27:21,204 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIAIAI', 'rating': 8.0, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AIAICSIGMVII[records: Entities (45, 53, 54), Relationships (401, 408, 409)]'}, {'summary': 'AI', 'explanation': 'AIAICSIGMVIIAI[records: Relationships (77, 78, 408, 409)]'}, {'summary': 'AI', 'explanation': 'AIAI[records: Relationships (288, 433)]'}, {'summary': '', 'explanation': 'AICSIGMVII[records: Relationships (430, 431, 432, 433, 434, 435, 436, 437, 438)]'}, {'summary': 'AIAI', 'explanation': 'AIAIAIMITAIAIAI[records: Relationships (423, 439)]'}]}
22:27:21,204 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 79.90861881198362. input_tokens=4440, output_tokens=1443
22:28:34,599 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
22:28:34,600 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
22:28:34,600 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title" 	: 	"AI" 	,      	"summary" 	: 	"AIAIAIAIAI" 	,      	"rating" 	: 	8.5 	,      	"rating_explanation" 	: 	"AIAI" 	,      	"findings" 	: 	[          	{              	"summary" 	: 	"" 	,              	"explanation" 	: 	"AIAI[records: Entities (39), 411, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295,
22:28:34,601 graphrag.llm.openai.utils INFO success load json in step 3{'title': 'AI', 'summary': 'AIAIAIAIAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': '', 'explanation': 'AIAI[records: Entities (39), 411, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295,'}]}
22:28:34,602 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 386.87845757836476. input_tokens=6970, output_tokens=4031
22:30:57,992 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
22:30:57,993 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIAR/VRAI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'AI', 'explanation': 'AIAIAI[records: Entities (278, 102, 325, 327, 457, 458, 459, 590, 130, 92, 591, 615, 459, 586, 590, 591, 592, 593, 594, 595, 596, 597, 368, 585, 587, 269, 891, 895, 382, 385, 392, 395, 882, 883, 582, 884, 893, 885, 643, 583, 598, 579, 580, 581, 599, 584, 231, 967, 972, 976, 979, 981, 982, 726, 727, 522, 722, 723, 577, 1034), Relationships (159, 125, 326, 365, 557, 262, 600, 250, 629, 645, 714, 586, 590, 591, 592, 593, 594, 595, 596, 597, 368, 585, 587, 269, 891, 895, 382, 385, 392, 395, 882, 883, 582, 884, 893, 885, 643, 583, 598, 579, 580, 581, 599, 584, 231, 967, 972, 976, 979, 981, 982, 726, 727, 522, 722, 723, 577, 1034)]'}, {'summary': '', 'explanation': 'AIAIARAI[records: Entities (102, 590, 591, 592, 593, 594, 595, 596, 597, 586, 587, 583, 580, 581, 579, 599, 584), Relationships (125, 557, 600, 250, 590, 591, 592, 593, 594, 595, 596, 597, 586, 587, 583, 580, 581, 579, 599, 584)]'}, {'summary': '', 'explanation': 'AIVR[records: Entities (325, 327, 457, 458, 615, 459, 591, 269, 891, 895, 382, 385, 392, 395, 882, 883, 582, 884, 893, 885, 643, 583, 598, 579, 580, 581, 599, 584, 231, 967, 972, 976, 979, 981, 982, 726, 727, 522, 722, 723, 577, 1034), Relationships (629, 645, 714, 586, 590, 591, 592, 593, 594, 595, 596, 597, 368, 585, 587, 269, 891, 895, 382, 385, 392, 395, 882, 883, 582, 884, 893, 885, 643, 583, 598, 579, 580, 581, 599, 584, 231, 967, 972, 976, 979, 981, 982, 726, 727, 522, 722, 723, 577, 1034)]'}, {'summary': 'AR/VR', 'explanation': 'AR/VRARVRAR/VRAR/VRAI[records: Entities (327, 458, 615, 459, 591, 596, 726, 727, 982), Relationships (327, 458, 615, 459, 591, 596, 726, 727, 982)]'}, {'summary': '', 'explanation': 'AIAI[records: Entities (262, 278, 325, 327, 457, 458, 459, 591, 596, 597, 586, 587, 583, 580, 581, 579, 599, 584, 231, 967, 972, 976, 979, 981, 982, 726, 727, 522, 722, 723, 577, 1034), Relationships (262, 600, 250, 590, 591, 592, 593, 594, 595, 596, 597, 586, 587, 583, 580, 581, 579, 599, 584, 231, 967, 972, 976, 979, 981, 982, 726, 727, 522, 722, 723, 577, 1034)]'}]}
22:30:57,994 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 143.38654739176854. input_tokens=6946, output_tokens=2400
22:32:07,514 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
22:32:07,514 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIAIAIAI', 'rating': 8.0, 'rating_explanation': 'AI', 'findings': [{'summary': 'AI', 'explanation': 'AIAIAIAI[records: Entities (313, 563), Relationships (923, 941, 942)]'}, {'summary': 'AI', 'explanation': 'AIAIAI[records: Entities (563), Relationships (923, 941, 942)]'}, {'summary': '', 'explanation': 'AI[records: Entities (540), Relationships (940)]'}, {'summary': '', 'explanation': 'AI[records: Relationships (934)]'}, {'summary': 'AI', 'explanation': 'AI[records: Relationships (941)]'}]}
22:32:07,515 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 69.51677659526467. input_tokens=2312, output_tokens=1124
22:33:59,227 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
22:33:59,228 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
22:33:59,228 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title" 	: 	"ARKGE" 	,      	"summary" 	: 	"ARKGEARKGEAR" 	,      	"rating" 	: 	8.5 	,      	"rating_explanation" 	: 	"AI" 	,      	"findings" 	: 	[          	{              	"summary" 	: 	"" 	,              	"explanation" 	: 	"ARAR[records: Relationships (282, 131)]" 	,          	" 	,          	{              	" 	: 	"AR" 	,              	"explanation" 	: 	"AR3DARKGEAR[records: Relationships (714, 691, 627, 641, 696, 670, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697,
22:33:59,229 graphrag.llm.openai.utils INFO success load json in step 3{'title': 'ARKGE', 'summary': 'ARKGEARKGEAR', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': 'AR3DARKGEAR[records: Relationships (714, 691, 627, 641, 696, 670, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697, 698, 699, 700, 701, 702, 695, 697, 712, 713, 715, 694, 697,', ' \t,          \t{': 'AR'}]}
22:33:59,230 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 398.0204634470865. input_tokens=4817, output_tokens=3908
22:34:17,868 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
22:34:17,868 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
22:34:17,868 graphrag.llm.openai.utils INFO Error: JSONDecodeError
22:34:17,868 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
22:34:17,868 graphrag.index.graph.extractors.community_reports.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/index/graph/extractors/community_reports/community_reports_extractor.py", line 58, in __call__
    await self._llm(
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/base_llm.py", line 48, in __call__
    return await self._invoke_json(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_chat_llm.py", line 90, in _invoke_json
    raise RuntimeError(error_msg)
RuntimeError: Failed to generate valid JSON output - Faulty JSON: {}
22:34:17,869 graphrag.index.reporting.file_workflow_callbacks INFO Community Report Extraction Error details=None
22:34:17,869 graphrag.index.verbs.graph.report.strategies.graph_intelligence.run_graph_intelligence WARNING No report found for community: 38
22:35:17,180 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
22:35:17,181 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIAIAIAIAI', 'rating': 7.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'AI', 'explanation': 'AIAIAIAIAIAI[records: Entities (314, 564), Relationships (924, 944)]'}, {'summary': 'AI', 'explanation': 'AIAI[records: Relationships (943)]'}, {'summary': 'AIAI', 'explanation': 'AIAIAI[records: Relationships (944)]'}, {'summary': 'AIAI', 'explanation': 'AIAIAIAI[records: Relationships (924)]'}, {'summary': 'AI', 'explanation': 'AIAI[records: Entities (314, 564), Relationships (924, 944)]'}]}
22:35:17,181 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 59.308897621929646. input_tokens=2161, output_tokens=993
22:37:48,518 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
22:37:48,518 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
22:37:48,518 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title" 	: 	"" 	,      	"summary" 	: 	"" 	,      	"rating" 	: 	8.5 	,      	"rating_explanation" 	: 	"" 	,      	"findings" 	: 	[          	{              	"summary" 	: 	"" 	,              	"explanation" 	: 	"[records: Entities (16), Relationships (230, 234, 236, 237, 238, 239, 240, 241, 242, 243, 245)]"          	} 	,          	{              	"summary" 	: 	"" 	,              	"explanation" 	: 	"[records: Relationships (231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 11
22:37:48,519 graphrag.llm.openai.utils INFO success load json in step 3{'title': '', 'summary': '', 'rating': 8.5, 'rating_explanation': '', 'findings': [{'summary': '', 'explanation': '[records: Entities (16), Relationships (230, 234, 236, 237, 238, 239, 240, 241, 242, 243, 245)]'}, {'summary': '', 'explanation': '[records: Relationships (231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 11'}]}
22:37:48,521 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 151.33388967998326. input_tokens=4291, output_tokens=4602
22:38:48,430 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
22:38:48,431 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'AR/VR', 'rating': 8.5, 'rating_explanation': '', 'findings': [{'summary': '', 'explanation': 'AR/VR[records: Entities (158, 159, 440), Relationships (720, 721, 726, 727, 725, 724)]'}, {'summary': '', 'explanation': '[records: Entities (158), Relationships (726, 724)]'}, {'summary': '', 'explanation': 'AR/VR[records: Entities (159), Relationships (721, 727)]'}, {'summary': '', 'explanation': '[records: Relationships (725)]'}, {'summary': '', 'explanation': '[records: Relationships (724)]'}]}
22:38:48,431 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 59.90655408706516. input_tokens=2450, output_tokens=1111
22:47:13,143 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
22:47:13,144 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
22:47:13,144 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title" 	: 	"AI" 	,      	"summary" 	: 	"AI" 	,      	"rating" 	: 	8.5 	,      	"rating_explanation" 	: 	"AI" 	,      	"findings" 	: 	[              	{                  	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AIAI[records: Entities (222), Relationships (183)]" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities (222), Relationships (183)" 	: 	"NONE" 	,              	"records: Entities
22:47:13,147 graphrag.llm.openai.utils INFO success load json in step 3{'title': 'AI', 'summary': 'AI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'AI', 'explanation': 'AIAI[records: Entities (222), Relationships (183)]', 'records: Entities (222), Relationships (183)': 'NONE'}]}
22:47:13,147 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 504.711542179808. input_tokens=2951, output_tokens=1049
22:48:14,980 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
22:48:14,981 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AI', 'rating': 8.0, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': 'AIAI[records: Entities (236), Relationships (184)]'}, {'summary': '', 'explanation': 'AI[records: Entities (232), Relationships (843)]'}, {'summary': '', 'explanation': 'AI[records: Entities (231), Relationships (841)]'}, {'summary': '', 'explanation': 'AI[records: Entities (234), Relationships (845)]'}, {'summary': '', 'explanation': 'AI[records: Entities (228), Relationships (835)]'}]}
22:48:14,981 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 61.82978372275829. input_tokens=4176, output_tokens=1325
22:49:05,241 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
22:49:05,242 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
22:49:05,242 graphrag.llm.openai.utils INFO Error: JSONDecodeError
22:49:05,242 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
22:50:56,344 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
22:50:56,344 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
22:50:56,344 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title" 	: 	"" 	,      	"summary" 	: 	"" 	,      	"rating" 	: 	8.0 	,      	"rating_explanation" 	: 	"AI" 	,      	"findings" 	: 	[          	{              	"summary" 	: 	"" 	,              	"explanation" 	: 	"[records: Entities (109, 110), Relationships (127, 128, 129, 130, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061,
22:50:56,345 graphrag.llm.openai.utils INFO success load json in step 3{'title': '', 'summary': '', 'rating': 8.0, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': '[records: Entities (109, 110), Relationships (127, 128, 129, 130, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061,'}]}
22:50:56,347 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 1017.1111509497277. input_tokens=5083, output_tokens=4125
22:54:13,681 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
22:54:13,681 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
22:54:13,681 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title" 	: 	"AI" 	,      	"summary" 	: 	"AI" 	,      	"rating" 	: 	8.5 	,      	"rating_explanation" 	: 	"AIAI" 	,      	"findings" 	: 	[              	{                  	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AI[records: Entities (203, 204, 207), Relationships (106, 107, 176, 802, 801)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (805, 806)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (106, 802, 801)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (804)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (808)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (807)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (806)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (106, 802, 801)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (803)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (809)]" 	,      	"findings" 	: 	[              	{                  	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AI[records: Entities (203, 204, 207), Relationships (106, 107, 176, 802, 801)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (805, 806)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (106, 802, 801)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (804)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (808)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (807)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (806)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (106, 802, 801)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (803)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (809)]" 	,      	"findings" 	: 	[              	{                  	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AI[records: Entities (203, 204, 207), Relationships (106, 107, 176, 802, 801)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (805, 806)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (106, 802, 801)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (804)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (808)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (807)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (806)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (106, 802, 801)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (803)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (809)]" 	,      	"findings" 	: 	[              	{                  	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AI[records: Entities (203, 204, 207), Relationships (106, 107, 176, 802, 801)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (805, 806)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (106, 802, 801)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (804)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (808)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (807)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (806)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (106, 802, 801)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (803)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (809)]" 	,      	"findings" 	: 	[              	{                  	"summary" 	: 	"AI" 	,                  	"explanation" 	: 	"AI[records: Entities (203, 204, 207), Relationships (106, 107, 176, 802, 801)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (805, 806)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (106, 802, 801)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (804)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (808)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (807)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[records: Relationships (806)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"
22:54:13,684 graphrag.llm.openai.utils INFO success load json in step 3{'title': 'AI', 'summary': 'AI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': '', 'explanation': '[records: Relationships (809)]', 'findings': [{'summary': '', 'explanation': '[records: Relationships (809)]', 'findings': [{'summary': '', 'explanation': '[records: Relationships (809)]', 'findings': [{'summary': '', 'explanation': '[records: Relationships (809)]', 'findings': [{'summary': '', 'explanation': ''}]}]}]}]}]}
22:54:13,684 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 358.6986357057467. input_tokens=3003, output_tokens=2420
23:08:29,579 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
23:08:29,579 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
23:08:29,580 graphrag.llm.openai.utils INFO Error: JSONDecodeError
23:08:29,580 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
23:09:46,175 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
23:09:46,175 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
23:09:46,175 graphrag.llm.openai.utils INFO Error: JSONDecodeError
23:09:46,175 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
23:10:38,263 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
23:10:38,263 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
23:10:38,263 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title" 	: 	"AI" 	,      	"summary" 	: 	"AI" 	,      	"rating" 	: 	8.5 	,      	"rating_explanation" 	: 	"AI" 	,      	"findings" 	: 	[              	{                      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215)]" 	,                  	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (810, 811)]" 	,                  	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (812, 813)]" 	,                  	"summary" 	: 	"" 	,                      	"explanation" 	: 	"AI[records: Relationships (809)]" 	,                  	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Relationships (811)]" 	,                  	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 813)]" 	,              	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 813)]" 	,              	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 813)]" 	,              	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 813)]" 	,              	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 813)]" 	,          	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 813)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 813)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 813)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 813)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 813)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 813)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 813)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 813)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 813)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 813)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 813)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 813)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 813)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 813)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 813)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 813)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 813)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 813)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 813)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 813)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 813)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 813)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 813)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 813)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 813)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 813)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 813)]" 	,      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 8
23:10:38,265 graphrag.llm.openai.utils INFO success load json in step 3{'title': 'AI', 'summary': 'AI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'AI', 'explanation': 'AI[records: Entities (212, 214, 213, 215), Relationships (810, 809, 812, 811, 8'}]}
23:10:38,268 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 1181.9150756862946. input_tokens=2442, output_tokens=984
23:25:11,886 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
23:25:11,887 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
23:25:11,887 graphrag.llm.openai.utils INFO Error: JSONDecodeError
23:25:11,887 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
23:28:08,903 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
23:28:08,904 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
23:28:08,904 graphrag.llm.openai.utils INFO Error: JSONDecodeError
23:28:08,904 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
23:30:20,139 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
23:30:20,140 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
23:30:20,140 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title" 	: 	"AI" 	,      	"summary" 	: 	"AI" 	,      	"rating" 	: 	7.0 	,      	"rating_explanation" 	: 	"AIAI" 	,      	"findings" 	: 	[              	{                      	"summary" 	: 	"AI" 	,                      	"explanation" 	: 	"AIAI[records: Entities (221), Relationships (182, 822)]" 	,              	"summary" 	: 	"" 	,              	"explanation" 	: 	"AIAI[records: Entities (219), Relationships (818, 820)]" 	,              	"summary" 	: 	"" 	,              	"explanation" 	: 	"AIAI[records: Entities (220), Relationships (820)]" 	,              	"summary" 	: 	"" 	,              	"explanation" 	: 	"AIAI[records: Entities (218, 217), Relationships (816, 815)]" 	,              	"summary" 	: 	"" 	,              	"explanation" 	: 	"AIAI[records: Entities (216, 214), Relationships (814, 813)]" 	,      	"summary" 	: 	"AI" 	,      	"explanation" 	: 	"AIAIAI[records: Relationships (822, 818, 820)]" 	,      	"summary" 	: 	"AI" 	,      	"explanation" 	: 	"AIAI[records: Entities (221, 219, 220, 218, 217), Relationships (182, 822, 818, 820, 816, 815, 814, 813)]" 	,      	"summary" 	: 	"AIAI" 	,      	"explanation" 	: 	"AIAIAIAI[records: Entities (221, 219, 220, 218, 217), Relationships (182, 822, 818, 820, 816, 815, 814, 813)]" 	,      	"summary" 	: 	"AI" 	,      	"explanation" 	: 	"AIAIAI[records: Entities (218, 217), Relationships (816, 815)]" 	,      	"summary" 	: 	"AI" 	,      	"explanation" 	: 	"AIAI[records: Entities (216, 214), Relationships (814, 813)]" 	,      	"summary" 	: 	"AI" 	,      	"explanation" 	: 	"AI[records: Entities (221), Relationships (822)]" 	,      	"summary" 	: 	"AI" 	,      	"explanation" 	: 	"AI[records: Entities (219), Relationships (818, 820)]" 	,      	"summary" 	: 	"AI" 	,      	"explanation" 	: 	"AI[records: Entities (218, 217), Relationships (816, 815)]" 	,      	"summary" 	: 	"AI" 	,      	"explanation" 	: 	"AI[records: Entities (216, 214), Relationships (814, 813)]" 	,      	"summary" 	: 	"AI" 	,      	"explanation" 	: 	"AIAIAI[records: Relationships (822, 818, 820)]" 	,      	"summary" 	: 	"AI" 	,      	"explanation" 	: 	"AIAI[records: Entities (221, 219, 220, 218, 217), Relationships (182, 822, 818, 820, 816, 815, 814, 813)]" 	,      	"summary" 	: 	"AIAI" 	,      	"explanation" 	: 	"AIAIAIAI[records: Entities (221, 219, 220, 218, 217), Relationships (182, 822, 818, 820, 816, 815, 814, 813)]" 	,      	"summary" 	: 	"AI" 	,      	"explanation" 	: 	"AIAIAI[records: Entities (218, 217), Relationships (816, 815)]" 	,      	"summary" 	: 	"AI" 	,      	"explanation" 	: 	"AIAI[records: Entities (216, 214), Relationships (814, 813)]" 	,      	"summary" 	: 	"AI" 	,      	"explanation" 	: 	"AI[records: Entities (221), Relationships (822)]" 	,      	"summary" 	: 	"AI" 	,      	"explanation" 	: 	"AI[records: Entities (219), Relationships (818, 820)]" 	,      	"summary" 	: 	"AI" 	,      	"explanation" 	: 	"AI[records: Entities (218, 217), Relationships (816, 815)]" 	,      	"summary" 	: 	"AI" 	,      	"explanation" 	: 	"AI[records: Entities (216, 214), Relationships (814, 813)]" 	,      	"summary" 	: 	"AI" 	,      	"explanation" 	: 	"AIAIAI[records: Relationships (822, 818, 820)]" 	,      	"summary" 	: 	"AI" 	,      	"explanation" 	: 	"AIAI[records: Entities (221, 219, 220, 218, 217), Relationships (182, 822, 818, 820, 816, 815, 814, 813)]" 	,      	"summary" 	: 	"AIAI" 	,      	"explanation" 	: 	"AIAIAIAI[records: Entities (221, 219, 220, 218, 217), Relationships (182, 822, 818, 820, 816, 815, 814, 813)]" 	,      	"summary" 	: 	"AI" 	,      	"explanation" 	: 	"AIAIAI[records: Entities (218, 217), Relationships (816, 815)]" 	,      	"summary" 	: 	"AI" 	,      	"explanation" 	: 	"AIAI[records: Entities (216, 214), Relationships (814, 813)]" 	,      	"summary" 	: 	"AI" 	,      	"explanation" 	: 	"AI[records: Entities (221), Relationships (822)]" 	,      	"summary" 	: 	"AI" 	,      	"explanation" 	: 	"AI[records: Entities (219), Relationships (818, 820)]" 	,      	"summary" 	: 	"AI" 	,      	"explanation" 	: 	"AI[records: Entities (218, 217), Relationships (816, 815)]" 	,      	"summary" 	: 	"AI" 	,      	"explanation" 	: 	"AI[records: Entities (216, 214), Relationships (814, 813)]" 	,      	"summary" 	: 	"AI" 	,      	"explanation" 	: 	"AIAIAI[records: Relationships (822, 818, 820)]" 	,      	"summary" 	: 	"AI" 	,      	"explanation" 	: 	"AIAI[records: Entities (221, 219, 220, 218, 217), Relationships (182, 822, 818, 820, 816, 815, 814, 813)]" 	,      	"summary" 	: 	"AIAI" 	,      	"explanation" 	: 	"AIAIAIAI[records: Entities (221, 219, 220, 218, 217), Relationships (182, 822, 818, 820, 816, 815, 814, 813)]" 	,      	"summary" 	: 	"AI" 	,      	"explanation" 	: 	"AIAIAI[records: Entities (218, 217), Relationships (816, 815)]" 	,      	"summary" 	: 	"AI" 	,      	"explanation" 	: 	"AIAI[records: Entities (216, 214), Relationships (814, 813)]" 	,      	"summary" 	: 	"AI" 	,      	"explanation" 	: 	"AI[records: Entities (221), Relationships (822)]" 	,      	"summary" 	: 	"AI" 	,      	"explanation" 	: 	"AI[records: Entities (219), Relationships (818, 820)]" 	,      	"summary" 	: 	"AI" 	,      	"explanation" 	: 	"AI[
23:30:20,142 graphrag.llm.openai.utils INFO success load json in step 3{'title': 'AI', 'summary': 'AI', 'rating': 7.0, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AI['}]}
23:30:20,142 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 1181.8696535271592. input_tokens=2971, output_tokens=986
23:34:22,462 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
23:34:22,463 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AR - ', 'summary': 'ARARARARAR', 'rating': 8.5, 'rating_explanation': 'ARAR', 'findings': [{'summary': 'AR', 'explanation': 'ARARARAIAR[records: Entities (136, 138, 139, 142, 146, 542, 566), Relationships (129, 313, 672, 671, 665, 670, 669, 656, 667, 659, 660, 661, 662, 663, 664, 657, 658, 666, 668, 674, 675, 678)]'}, {'summary': 'AR', 'explanation': 'ARARARAR[records: Entities (138), Relationships (660, 674)]'}, {'summary': 'AR', 'explanation': 'ARARARAR[records: Entities (139), Relationships (661, 675)]'}, {'summary': 'AR', 'explanation': 'ARARARAR[records: Entities (142), Relationships (662, 678)]'}, {'summary': 'AR', 'explanation': 'ARARARAR[records: Entities (136, 146), Relationships (677, 659, 667)]'}]}
23:34:22,463 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 242.3168877842836. input_tokens=3730, output_tokens=1415
23:39:15,517 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
23:39:15,518 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AR', 'summary': 'ARARARARAR', 'rating': 7.5, 'rating_explanation': 'AR', 'findings': [{'summary': 'AR', 'explanation': 'ARARARARARARARARAR[records: Entities (141, 140, 137), Relationships (663, 662, 659, 677, 676, 673)]'}, {'summary': '', 'explanation': '[records: Entities (135, 134, 132, 133), Relationships (655, 653, 651, 652, 654)]'}, {'summary': '', 'explanation': 'ARARARAR[records: Relationships (663, 662, 659, 677, 676, 673, 655, 653, 651, 652, 654)]'}, {'summary': '', 'explanation': 'ARARARAR[records: Entities (141, 140, 137, 135, 134, 132, 133), Relationships (663, 662, 659, 677, 676, 673, 655, 653, 651, 652, 654)]'}, {'summary': '', 'explanation': 'ARAR[records: Entities (141, 140, 137, 135, 134, 132, 133), Relationships (663, 662, 659, 677, 676, 673, 655, 653, 651, 652, 654)]'}]}
23:39:15,519 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 293.05047246208414. input_tokens=3215, output_tokens=1794
23:40:41,295 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
23:40:41,296 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
23:40:41,296 graphrag.llm.openai.utils INFO Error: JSONDecodeError
23:40:41,296 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
23:52:26,607 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
23:52:26,608 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
23:52:26,608 graphrag.llm.openai.utils INFO Error: JSONDecodeError
23:52:26,608 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
23:52:26,608 graphrag.index.graph.extractors.community_reports.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/index/graph/extractors/community_reports/community_reports_extractor.py", line 58, in __call__
    await self._llm(
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/base_llm.py", line 48, in __call__
    return await self._invoke_json(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_chat_llm.py", line 90, in _invoke_json
    raise RuntimeError(error_msg)
RuntimeError: Failed to generate valid JSON output - Faulty JSON: {}
23:52:26,608 graphrag.index.reporting.file_workflow_callbacks INFO Community Report Extraction Error details=None
23:52:26,608 graphrag.index.verbs.graph.report.strategies.graph_intelligence.run_graph_intelligence WARNING No report found for community: 51
23:56:04,261 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
23:56:04,262 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
23:56:04,262 graphrag.llm.openai.utils INFO Error: JSONDecodeError
23:56:04,262 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
23:56:04,262 graphrag.index.graph.extractors.community_reports.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/index/graph/extractors/community_reports/community_reports_extractor.py", line 58, in __call__
    await self._llm(
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/base_llm.py", line 48, in __call__
    return await self._invoke_json(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_chat_llm.py", line 90, in _invoke_json
    raise RuntimeError(error_msg)
RuntimeError: Failed to generate valid JSON output - Faulty JSON: {}
23:56:04,262 graphrag.index.reporting.file_workflow_callbacks INFO Community Report Extraction Error details=None
23:56:04,262 graphrag.index.verbs.graph.report.strategies.graph_intelligence.run_graph_intelligence WARNING No report found for community: 61
23:57:09,394 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
23:57:09,395 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AIGC', 'summary': 'AIGCAIGCAIGCAI', 'rating': 8.0, 'rating_explanation': 'AIGCAI', 'findings': [{'summary': '', 'explanation': '[records: Entities (118, 462, 119, 454, 97, 588), Relationships (342, 537, 538, 542, 555, 532, 882, 582, 583, 761, 1035, 649, 648, 650, 647, 578, 1028)]'}, {'summary': '', 'explanation': '[records: Entities (462, 119, 454, 97, 588), Relationships (649, 648, 650, 647, 578)]'}, {'summary': '', 'explanation': '[records: Entities (119, 454, 97, 588), Relationships (542, 583)]'}, {'summary': '', 'explanation': '[records: Entities (454, 97, 588), Relationships (555, 761, 1028)]'}, {'summary': '', 'explanation': '[records: Entities (97, 588), Relationships (532, 578)]'}]}
23:57:09,395 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 65.12866702396423. input_tokens=5515, output_tokens=1437
23:57:48,450 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
23:57:48,450 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'AIVRAIAIAIVR', 'rating': 8.0, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AIVRAIAI[records: Entities (56, 57, 58, 55, 80, 79, 273, 274, 275, 272, 444, 445, 446, 443), Relationships (80, 81, 82, 79, 273, 274, 275, 272, 444, 445, 446, 443)]'}, {'summary': 'AI', 'explanation': 'AIAIAI[records: Entities (56, 57, 58, 55, 80, 79, 273, 274, 275, 272, 444, 445, 446, 443), Relationships (80, 81, 82, 79, 273, 274, 275, 272, 444, 445, 446, 443)]'}, {'summary': 'AI', 'explanation': 'AIVRVRAIAI[records: Entities (56, 57, 58, 55, 80, 79, 273, 274, 275, 272, 444, 445, 446, 443), Relationships (80, 81, 82, 79, 273, 274, 275, 272, 444, 445, 446, 443)]'}, {'summary': 'AI', 'explanation': 'AICG985AIAI[records: Entities (56, 57, 58, 55, 80, 79, 273, 274, 275, 272, 444, 445, 446, 443), Relationships (80, 81, 82, 79, 273, 274, 275, 272, 444, 445, 446, 443)]'}, {'summary': 'AI', 'explanation': 'AIAIAI[records: Entities (56, 57, 58, 55, 80, 79, 273, 274, 275, 272, 444, 445, 446, 443), Relationships (80, 81, 82, 79, 273, 274, 275, 272, 444, 445, 446, 443)]'}]}
23:57:48,451 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 321.83806383563206. input_tokens=4210, output_tokens=1777
23:59:39,311 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
23:59:39,312 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
23:59:39,312 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title" 	: 	"AIVR" 	,      	"summary" 	: 	"AIVRVRAIAI" 	,      	"rating" 	: 	8.0 	,      	"rating_explanation" 	: 	"AIAI" 	,      	"findings" 	: 	[          	{              	"summary" 	: 	"AI" 	,              	"explanation" 	: 	"AIAIAIAI[records: Entities (296, 248), Relationships (248, 586, 684, 618, 633, 705, 249, 672, 243, 917, 918, 919, 920, 921, 696, 587, 916, 685, 927, 905, 619, 634, 706, 956, 957, 958, 959, 960, 961, 697, 928, 923, 925, 922, 924, 926, 961, 693, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934,
23:59:39,313 graphrag.llm.openai.utils INFO success load json in step 3{'title': 'AIVR', 'summary': 'AIVRVRAIAI', 'rating': 8.0, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AIAIAIAI[records: Entities (296, 248), Relationships (248, 586, 684, 618, 633, 705, 249, 672, 243, 917, 918, 919, 920, 921, 696, 587, 916, 685, 927, 905, 619, 634, 706, 956, 957, 958, 959, 960, 961, 697, 928, 923, 925, 922, 924, 926, 961, 693, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934,'}]}
23:59:39,314 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 149.91341951303184. input_tokens=6143, output_tokens=4299
00:02:12,810 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
00:02:12,811 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
00:02:12,811 graphrag.llm.openai.utils INFO Error: JSONDecodeError
00:02:12,811 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
00:17:36,651 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
00:17:36,652 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
00:17:36,652 graphrag.llm.openai.utils INFO Error: JSONDecodeError
00:17:36,652 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
00:33:03,248 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
00:33:03,249 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
00:33:03,249 graphrag.llm.openai.utils INFO Error: JSONDecodeError
00:33:03,249 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
00:48:27,619 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
00:48:27,619 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
00:48:27,619 graphrag.llm.openai.utils INFO Error: JSONDecodeError
00:48:27,619 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
00:48:27,619 graphrag.index.graph.extractors.community_reports.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/index/graph/extractors/community_reports/community_reports_extractor.py", line 58, in __call__
    await self._llm(
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/base_llm.py", line 48, in __call__
    return await self._invoke_json(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_chat_llm.py", line 90, in _invoke_json
    raise RuntimeError(error_msg)
RuntimeError: Failed to generate valid JSON output - Faulty JSON: {}
00:48:27,620 graphrag.index.reporting.file_workflow_callbacks INFO Community Report Extraction Error details=None
00:48:27,620 graphrag.index.verbs.graph.report.strategies.graph_intelligence.run_graph_intelligence WARNING No report found for community: 14
00:49:30,907 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
00:49:30,907 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'AI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': 'AI[records: Entities (108, 124, 120, 125, 121, 122, 123), Relationships (126, 366, 610, 606, 611, 607, 608, 609)]'}, {'summary': '', 'explanation': '[records: Relationships (610, 606, 611, 607, 608, 609)]'}, {'summary': 'AI', 'explanation': 'AIAI[records: Relationships (126, 366)]'}, {'summary': '', 'explanation': '[records: Relationships (610, 611, 606, 607, 608, 609)]'}, {'summary': '', 'explanation': '[records: Relationships (610, 606, 611, 607, 608, 609)]'}]}
00:49:30,908 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 63.17937353393063. input_tokens=2628, output_tokens=1314
00:51:02,152 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
00:51:02,153 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
00:51:02,153 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title" 	: 	"" 	,      	"summary" 	: 	"" 	,      	"rating" 	: 	8.5 	,      	"rating_explanation" 	: 	"AI" 	,      	"findings" 	: 	[          	{              	"summary" 	: 	"" 	,              	"explanation" 	: 	"[records: Entities (16), Relationships (230, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245)]"          	} 	,          	{              	"summary" 	: 	"" 	,              	"explanation" 	: 	"[records: Relationships (231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102
00:51:02,154 graphrag.llm.openai.utils INFO success load json in step 3{'title': '', 'summary': '', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': '[records: Entities (16), Relationships (230, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245)]'}, {'summary': '', 'explanation': '[records: Relationships (231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102'}]}
00:51:02,155 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 154.42831610096619. input_tokens=4760, output_tokens=4728
00:52:00,716 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
00:52:00,717 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
00:52:00,717 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title" 	: 	"AI" 	,      	"summary" 	: 	"AI" 	,      	"rating" 	: 	8.5 	,      	"rating_explanation" 	: 	"AIAI" 	,      	"findings" 	: 	[          	{              	"summary" 	: 	"AI" 	,              	"explanation" 	: 	"AI[records: Entities (198, 201, 203, 212, 214, 221, 222, 224, 227, 228, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 198, 201, 203, 212, 214, 221, 222, 224, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531,
00:52:00,718 graphrag.llm.openai.utils INFO success load json in step 3{'title': 'AI', 'summary': 'AI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AI[records: Entities (198, 201, 203, 212, 214, 221, 222, 224, 227, 228, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 198, 201, 203, 212, 214, 221, 222, 224, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531,'}]}
00:52:00,719 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 149.8046459336765. input_tokens=9108, output_tokens=3911
00:52:10,839 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
00:52:10,840 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AR', 'summary': 'ARARARARARAR', 'rating': 8.0, 'rating_explanation': 'ARAI', 'findings': [{'summary': 'AR', 'explanation': 'ARARARARAR[records: Entities (136, 141, 138, 139, 140, 142, 146, 147), Relationships (665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678)]'}, {'summary': '', 'explanation': 'ARARARARARAR[records: Entities (136, 141, 138, 139, 140, 142, 146, 147), Relationships (663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678)]'}, {'summary': 'ARAI', 'explanation': 'ARAIAIARAIAR[records: Entities (136, 147), Relationships (669, 671)]'}, {'summary': '', 'explanation': 'ARAR[records: Entities (136, 147), Relationships (666)]'}, {'summary': '', 'explanation': 'ARARARAR[records: Entities (136, 141, 138, 139, 140, 142, 146, 147), Relationships (663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678)]'}]}
00:52:10,840 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 68.68038130598143. input_tokens=4779, output_tokens=1379
00:53:07,687 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
00:53:07,688 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIAIAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': '', 'explanation': 'AIAIAI[records: Entities (174, 186), Relationships (293, 783)]'}, {'summary': 'AI', 'explanation': 'AIAI[records: Relationships (783)]'}, {'summary': 'AI', 'explanation': 'AIAIAI[records: Relationships (783)]'}, {'summary': 'AI', 'explanation': 'AIAI[records: Entities (174, 186), Relationships (293, 783)]'}, {'summary': 'AI', 'explanation': 'AIAIAI[records: Entities (174, 186), Relationships (293, 783)]'}]}
00:53:07,688 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 56.84396398393437. input_tokens=2043, output_tokens=955
00:54:06,364 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
00:54:06,364 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIAIGCAIAIGCAIAI', 'rating': 8.0, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': 'AIGCAIAI[records: Entities (175, 176), Relationships (294, 295)]'}, {'summary': 'AIGCAI', 'explanation': 'AIAIGCAI[records: Relationships (785)]'}, {'summary': 'AIGCAI', 'explanation': 'AIGCAIAIGCAI[records: Relationships (784)]'}, {'summary': 'AI', 'explanation': 'AIAIGCAI[records: Relationships (785)]'}, {'summary': '', 'explanation': 'AIGCAIAIAI[records: Relationships (784)]'}]}
00:54:06,365 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 58.67236388614401. input_tokens=2197, output_tokens=1027
00:54:30,548 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
00:54:30,548 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
00:54:30,548 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title"   	: 	"AI" 	,      	"summary" 	: 	"AIAIGCAI" 	,      	"rating" 	: 	8.5 	,      	"rating_explanation" 	: 	"AIAI" 	,      	"findings" 	: 	[          	{              	"summary" 	: 	"AI" 	,              	"explanation" 	: 	"AIAIAIGCAIAIGCAI[records: Entities (163, 173, 495, 521, 63, 456, 515, 641, 508, 488, 504, 487, 501, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642,
00:54:30,549 graphrag.llm.openai.utils INFO success load json in step 3{'title': 'AI', 'summary': 'AIAIGCAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AIAIAIGCAIAIGCAI[records: Entities (163, 173, 495, 521, 63, 456, 515, 641, 508, 488, 504, 487, 501, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642, 509, 78, 62, 497, 490, 492, 493, 497, 491, 642,'}]}
00:54:30,550 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 149.8255289341323. input_tokens=8569, output_tokens=3987
00:55:31,188 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
00:55:31,189 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'AIRGBNERFTransformerAI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'AI', 'explanation': 'AITransformerRGBNERFAI[records: Entities (295, 302, 303, 306, 307, 308, 309, 310, 311, 312, 313), Relationships (144, 329, 905, 906, 911, 915, 914, 910, 912, 907, 908, 909, 913)]'}, {'summary': 'AIAI', 'explanation': 'AIAIAIAI[records: Entities (312), Relationships (906, 939)]'}, {'summary': '', 'explanation': 'AI[records: Entities (307), Relationships (906, 936)]'}, {'summary': '', 'explanation': 'AI[records: Entities (311), Relationships (906, 938)]'}, {'summary': 'RGB', 'explanation': 'RGBAI[records: Entities (310), Relationships (906, 937)]'}, {'summary': '', 'explanation': 'AI[records: Entities (306), Relationships (906, 935)]'}, {'summary': 'NERF', 'explanation': 'NERFAI[records: Entities (312), Relationships (906, 912)]'}, {'summary': '', 'explanation': '[records: Entities (545, 546, 548, 549), Relationships (906, 937, 938, 939)]'}]}
00:55:31,189 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 84.82045912509784. input_tokens=3954, output_tokens=1719
00:55:45,67 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
00:55:45,67 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'AIAIVRAIAIAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AIVRAIAI[records: Entities (56, 57, 58, 55, 80, 79, 273, 274, 275, 272, 444, 445, 446, 443), Relationships (80, 81, 82, 79, 273, 274, 275, 272, 444, 445, 446, 443)]'}, {'summary': 'AI', 'explanation': 'AIAIAI[records: Entities (56, 57, 58, 55, 80, 79, 273, 274, 275, 272, 444, 445, 446, 443), Relationships (80, 81, 82, 79, 273, 274, 275, 272, 444, 445, 446, 443)]'}, {'summary': 'AI', 'explanation': 'AIVRVRAIAI[records: Entities (56, 57, 58, 55, 80, 79, 273, 274, 275, 272, 444, 445, 446, 443), Relationships (80, 81, 82, 79, 273, 274, 275, 272, 444, 445, 446, 443)]'}, {'summary': 'AI', 'explanation': 'AICG985AIAI[records: Entities (56, 57, 58, 55, 80, 79, 273, 274, 275, 272, 444, 445, 446, 443), Relationships (80, 81, 82, 79, 273, 274, 275, 272, 444, 445, 446, 443)]'}, {'summary': 'AI', 'explanation': 'AIAIAI[records: Entities (56, 57, 58, 55, 80, 79, 273, 274, 275, 272, 444, 445, 446, 443), Relationships (80, 81, 82, 79, 273, 274, 275, 272, 444, 445, 446, 443)]'}]}
00:55:45,68 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 74.51225135102868. input_tokens=8196, output_tokens=1742
00:58:03,829 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
00:58:03,830 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
00:58:03,830 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title"   	: 	" - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI - 
00:58:03,831 graphrag.llm.openai.utils INFO success load json in step 3{'title': ' - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI - '}
00:58:58,842 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
00:58:58,842 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
00:58:58,842 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title"   	: 	"AIGC" 	,      	"summary" 	: 	"AIGCAIGCAIGCAI" 	,      	"rating" 	: 	8.5 	,      	"rating_explanation" 	: 	"AIGCAI" 	,      	"findings" 	: 	[              	{                      	"summary" 	: 	"" 	,                      	"explanation" 	: 	"[records: Entities (118, 462, 119, 454, 97, 588), Relationships (342, 537, 538, 542, 555, 532, 882, 582, 583, 761, 1035, 649, 648, 650, 647, 578, 1028)]" 	,              		"explanation" 	: 	"[records: Entities (118, 462, 119, 454, 97, 588), Relationships (342, 537, 538, 542, 555, 532, 882, 582, 583, 761, 1035, 649, 648, 650, 647, 578, 1028)]" 	,              		"explanation" 	: 	"[records: Entities (118, 462, 119, 454, 97, 588), Relationships (342, 537, 538, 542, 555, 532, 882, 582, 583, 761, 1035, 649, 648, 650, 647, 578, 1028)]" 	,              		"explanation" 	: 	"[records: Entities (118, 462, 119, 454, 97, 588), Relationships (342, 537, 538, 542, 555, 532, 882, 582, 583, 761, 1035, 649, 648, 650, 647, 578, 1028)]" 	,              		"explanation" 	: 	"[records: Entities (118, 462, 119, 454, 97, 588), Relationships (342, 537, 538, 542, 555, 532, 882, 582, 583, 761, 1035, 649, 648, 650, 647, 578, 1028)]" 	,              		"explanation" 	: 	"[records: Entities (118, 462, 119, 454, 97, 588), Relationships (342, 537, 538, 542, 555, 532, 882, 582, 583, 761, 1035, 649, 648, 650, 647, 578, 1028)]" 	,              		"explanation" 	: 	"[records: Entities (118, 462, 119, 454, 97, 588), Relationships (342, 537, 538, 542, 555, 532, 882, 582, 583, 761, 1035, 649, 648, 650, 647, 578, 1028)]" 	,              		"explanation" 	: 	"[records: Entities (118, 462, 119, 454, 97, 588), Relationships (342, 537, 538, 542, 555, 532, 882, 582, 583, 761, 1035, 649, 648, 650, 647, 578, 1028)]" 	,              		"explanation" 	: 	"[records: Entities (118, 462, 119, 454, 97, 588), Relationships (342, 537, 538, 542, 555, 532, 882, 582, 583, 761, 1035, 649, 648, 650, 647, 578, 1028)]" 	,              		"explanation" 	: 	"[records: Entities (118, 462, 119, 454, 97, 588), Relationships (342, 537, 538, 542, 555, 532, 882, 582, 583, 761, 1035, 649, 648, 650, 647, 578, 1028)]" 	,              		"explanation" 	: 	"[records: Entities (118, 462, 119, 454, 97, 588), Relationships (342, 537, 538, 542, 555, 532, 882, 582, 583, 761, 1035, 649, 648, 650, 647, 578, 1028)]" 	,              		"explanation" 	: 	"[records: Entities (118, 462, 119, 454, 97, 588), Relationships (342, 537, 538, 542, 555, 532, 882, 582, 583, 761, 1035, 649, 648, 650, 647, 578, 1028)]" 	,              		"explanation" 	: 	"[records: Entities (118, 462, 119, 454, 97, 588), Relationships (342, 537, 538, 542, 555, 532, 882, 582, 583, 761, 1035, 649, 648, 650, 647, 578, 1028)]" 	,              		"explanation" 	: 	"[records: Entities (118, 462, 119, 454, 97, 588), Relationships (342, 537, 538, 542, 555, 532, 882, 582, 583, 761, 1035, 649, 648, 650, 647, 578, 1028)]" 	,              		"explanation" 	: 	"[records: Entities (118, 462, 119, 454, 97, 588), Relationships (342, 537, 538, 542, 555, 532, 882, 582, 583, 761, 1035, 649, 648, 650, 647, 578, 1028)]" 	,              		"explanation" 	: 	"[records: Entities (118, 462, 119, 454, 97, 588), Relationships (342, 537, 538, 542, 555, 532, 882, 582, 583, 761, 1035, 649, 648, 650, 647, 578, 1028)]" 	,              		"explanation" 	: 	"[records: Entities (118, 462, 119, 454, 97, 588), Relationships (342, 537, 538, 542, 555, 532, 882, 582, 583, 761, 1035, 649, 648, 650, 647, 578, 1028)]" 	,              		"explanation" 	: 	"[records: Entities (118, 462, 119, 454, 97, 588), Relationships (342, 537, 538, 542, 555, 532, 882, 582, 583, 761, 1035, 649, 648, 650, 647, 578, 1028)]" 	,              		"explanation" 	: 	"[records: Entities (118, 462, 119, 454, 97, 588), Relationships (342, 537, 538, 542, 555, 532, 882, 582, 583, 761, 1035, 649, 648, 650, 647, 578, 1028)]" 	,              		"explanation" 	: 	"[records: Entities (118, 462, 119, 454, 97, 588), Relationships (342, 537, 538, 542, 555, 532, 882, 582, 583, 761, 1035, 649, 648, 650, 647, 578, 1028)]" 	,              		"explanation" 	: 	"[records: Entities (118, 462, 119, 454, 97, 588), Relationships (342, 537, 538, 542, 555, 532, 882, 582, 583, 761, 1035, 649, 648, 650, 647, 578, 1028)]" 	,              		"explanation" 	: 	"[records: Entities (118, 462, 119, 454, 97, 588), Relationships (342, 537, 538, 542, 555, 532, 882, 582, 583, 761, 1035, 649, 648, 650, 647, 578, 1028)]" 	,              		"explanation" 	: 	"[records: Entities (118, 462, 119, 454, 97, 588), Relationships (342, 537, 538, 542, 555, 532, 882, 582, 583, 761, 1035, 649, 648, 650, 647, 578, 1028)]" 	,              		"explanation" 	: 	"[records: Entities (118, 462, 119, 454, 97, 588), Relationships (342, 537, 538, 542, 555, 532, 882, 582, 583, 761, 1035, 649, 648, 650, 647, 578, 1028)]" 	,              		"explanation" 	: 	"[records: Entities (118, 462, 119, 454, 97, 588), Relationships (342, 537, 538, 542, 555, 532, 882, 582, 583, 761, 1035, 649, 648,
00:58:58,844 graphrag.llm.openai.utils INFO success load json in step 3{'title': 'AIGC', 'summary': 'AIGCAIGCAIGCAI', 'rating': 8.5, 'rating_explanation': 'AIGCAI', 'findings': [{'summary': '', 'explanation': '[records: Entities (118, 462, 119, 454, 97, 588), Relationships (342, 537, 538, 542, 555, 532, 882, 582, 583, 761, 1035, 649, 648,'}]}
00:58:58,844 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 207.64911023015156. input_tokens=9761, output_tokens=1275
01:00:21,79 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
01:00:21,80 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
01:00:21,80 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title"   	: 	" - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI - 
01:00:21,81 graphrag.llm.openai.utils INFO success load json in step 3{'title': ' - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI - '}
01:01:31,357 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
01:01:31,357 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
01:01:31,357 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title" 	: 	"AI" 	,      	"summary" 	: 	"AIAIAIAIAI" 	,      	"rating" 	: 	8.5 	,      	"rating_explanation" 	: 	"AI" 	,      	"findings" 	: 	[          	{              	"summary" 	: 	"AI" 	,              	"explanation" 	: 	"AIAI[records: Entities (45), 51, 528, 533, 531, 532, 529, 530, 531, 532, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 53
01:01:31,358 graphrag.llm.openai.utils INFO success load json in step 3{'title': 'AI', 'summary': 'AIAIAIAIAI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'AI', 'explanation': 'AIAI[records: Entities (45), 51, 528, 533, 531, 532, 529, 530, 531, 532, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 530, 528, 533, 529, 53'}]}
01:01:31,359 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 152.50878442684188. input_tokens=9169, output_tokens=3961
01:02:40,268 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
01:02:40,269 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
01:02:40,269 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title"   	: 	" - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI - 
01:02:40,270 graphrag.llm.openai.utils INFO success load json in step 3{'title': ' - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI - '}
01:04:01,582 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
01:04:01,582 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
01:04:01,582 graphrag.llm.openai.utils INFO Error: JSONDecodeError
01:04:01,582 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
01:04:03,94 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
01:04:03,95 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
01:04:03,95 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title" 	: 	"AIVR" 	,      	"summary" 	: 	"AIVRVRAIAI" 	,      	"rating" 	: 	7.5 	,      	"rating_explanation" 	: 	"AI" 	,      	"findings" 	: 	[          	{              	"summary" 	: 	"AI" 	,              	"explanation" 	: 	"AIAIAIAI[records: Entities (296, 248), Relationships (248, 586, 684, 618, 633, 705, 249, 672, 243, 917, 918, 919, 920, 921, 696, 587, 916, 685, 927, 905, 619, 634, 706, 956, 957, 958, 959, 960, 961, 697, 928, 923, 925, 922, 924, 926, 961, 693, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976,
01:04:03,96 graphrag.llm.openai.utils INFO success load json in step 3{'title': 'AIVR', 'summary': 'AIVRVRAIAI', 'rating': 7.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'AI', 'explanation': 'AIAIAIAI[records: Entities (296, 248), Relationships (248, 586, 684, 618, 633, 705, 249, 672, 243, 917, 918, 919, 920, 921, 696, 587, 916, 685, 927, 905, 619, 634, 706, 956, 957, 958, 959, 960, 961, 697, 928, 923, 925, 922, 924, 926, 961, 693, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976, 979, 966, 971, 975, 978, 980, 934, 928, 981, 972, 967, 976,'}]}
01:04:03,97 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 151.73190650716424. input_tokens=7205, output_tokens=4158
01:04:58,380 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
01:04:58,380 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
01:04:58,380 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title"   	: 	" - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI - 
01:04:58,382 graphrag.llm.openai.utils INFO success load json in step 3{'title': ' - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI - '}
01:04:58,382 graphrag.index.graph.extractors.community_reports.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/index/graph/extractors/community_reports/community_reports_extractor.py", line 58, in __call__
    await self._llm(
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/base_llm.py", line 48, in __call__
    return await self._invoke_json(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_chat_llm.py", line 90, in _invoke_json
    raise RuntimeError(error_msg)
RuntimeError: Failed to generate valid JSON output - Faulty JSON: {'title': ' - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI -  - AI - '}
01:04:58,382 graphrag.index.reporting.file_workflow_callbacks INFO Community Report Extraction Error details=None
01:04:58,382 graphrag.index.verbs.graph.report.strategies.graph_intelligence.run_graph_intelligence WARNING No report found for community: 6
01:19:27,355 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
01:19:27,356 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
01:19:27,356 graphrag.llm.openai.utils INFO Error: JSONDecodeError
01:19:27,356 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
01:34:51,390 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
01:34:51,391 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
01:34:51,391 graphrag.llm.openai.utils INFO Error: JSONDecodeError
01:34:51,391 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
01:50:15,405 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
01:50:15,406 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
01:50:15,406 graphrag.llm.openai.utils INFO Error: JSONDecodeError
01:50:15,406 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
01:50:15,406 graphrag.index.graph.extractors.community_reports.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/index/graph/extractors/community_reports/community_reports_extractor.py", line 58, in __call__
    await self._llm(
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/caching_llm.py", line 96, in __call__
    result = await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/home/zxd/.conda/envs/grag/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/home/zxd/.conda/envs/grag/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/base/base_llm.py", line 48, in __call__
    return await self._invoke_json(input, **kwargs)
  File "/home/zxd/code/Chat/knowledge_graphrag/graphrag/graphrag/llm/openai/openai_chat_llm.py", line 90, in _invoke_json
    raise RuntimeError(error_msg)
RuntimeError: Failed to generate valid JSON output - Faulty JSON: {}
01:50:15,406 graphrag.index.reporting.file_workflow_callbacks INFO Community Report Extraction Error details=None
01:50:15,406 graphrag.index.verbs.graph.report.strategies.graph_intelligence.run_graph_intelligence WARNING No report found for community: 1
01:50:15,411 datashaper.workflow.workflow INFO executing verb window
01:50:15,412 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_community_reports.parquet
01:50:15,499 graphrag.index.run INFO Running workflow: create_final_text_units...
01:50:15,499 graphrag.index.run INFO dependencies for create_final_text_units: ['join_text_units_to_entity_ids', 'create_base_text_units', 'join_text_units_to_covariate_ids', 'join_text_units_to_relationship_ids']
01:50:15,499 graphrag.index.run INFO read table from storage: join_text_units_to_entity_ids.parquet
01:50:15,501 graphrag.index.run INFO read table from storage: create_base_text_units.parquet
01:50:15,503 graphrag.index.run INFO read table from storage: join_text_units_to_covariate_ids.parquet
01:50:15,504 graphrag.index.run INFO read table from storage: join_text_units_to_relationship_ids.parquet
01:50:15,509 datashaper.workflow.workflow INFO executing verb select
01:50:15,511 datashaper.workflow.workflow INFO executing verb rename
01:50:15,514 datashaper.workflow.workflow INFO executing verb join
01:50:15,519 datashaper.workflow.workflow INFO executing verb join
01:50:15,524 datashaper.workflow.workflow INFO executing verb join
01:50:15,529 datashaper.workflow.workflow INFO executing verb aggregate_override
01:50:15,533 datashaper.workflow.workflow INFO executing verb select
01:50:15,533 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_text_units.parquet
01:50:15,633 graphrag.index.run INFO Running workflow: create_base_documents...
01:50:15,633 graphrag.index.run INFO dependencies for create_base_documents: ['create_final_text_units']
01:50:15,633 graphrag.index.run INFO read table from storage: create_final_text_units.parquet
01:50:15,642 datashaper.workflow.workflow INFO executing verb unroll
01:50:15,646 datashaper.workflow.workflow INFO executing verb select
01:50:15,649 datashaper.workflow.workflow INFO executing verb rename
01:50:15,653 datashaper.workflow.workflow INFO executing verb join
01:50:15,658 datashaper.workflow.workflow INFO executing verb aggregate_override
01:50:15,663 datashaper.workflow.workflow INFO executing verb join
01:50:15,669 datashaper.workflow.workflow INFO executing verb rename
01:50:15,673 datashaper.workflow.workflow INFO executing verb convert
01:50:15,674 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_documents.parquet
01:50:15,756 graphrag.index.run INFO Running workflow: create_final_documents...
01:50:15,756 graphrag.index.run INFO dependencies for create_final_documents: ['create_base_documents']
01:50:15,757 graphrag.index.run INFO read table from storage: create_base_documents.parquet
01:50:15,767 datashaper.workflow.workflow INFO executing verb rename
01:50:15,767 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_documents.parquet
01:50:15,784 graphrag.index.cli INFO All workflows completed successfully.
10:21:09,886 graphrag.index.cli INFO Logging enabled at output/reports/indexing-engine.log
10:21:09,887 graphrag.index.cli INFO Starting pipeline run for: 20241126-102109, dryrun=False
10:21:09,887 graphrag.index.cli INFO Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "openai_chat",
        "model": "Qwen2.5-7B-Instruct",
        "max_tokens": 5000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 3000.0,
        "api_base": "http://192.168.0.244:8016/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 2.0,
        "num_threads": 50
    },
    "async_mode": "asyncio",
    "root_dir": ".",
    "reporting": {
        "type": "file",
        "base_dir": "output/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "model": "m3e-large",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://192.168.0.244:8016/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 2.0,
            "num_threads": 50
        },
        "async_mode": "asyncio",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 500,
        "overlap": 200,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "Qwen2.5-7B-Instruct",
            "max_tokens": 5000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 3000.0,
            "api_base": "http://192.168.0.244:8016/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 2.0,
            "num_threads": 50
        },
        "async_mode": "asyncio",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "\u653f\u7b56\u6cd5\u89c4",
            "\u5206\u7c7b\u65b9\u6cd5",
            "\u5904\u7406\u6280\u672f",
            "\u56de\u6536\u6750\u6599",
            "\u8bbe\u65bd\u8bbe\u5907",
            "\u5206\u7c7b\u6807\u51c6",
            "\u7ba1\u7406\u7ec4\u7ec7",
            "\u7ecf\u6d4e\u6a21\u5f0f",
            "\u6559\u80b2\u57f9\u8bad",
            "\u8ba4\u8bc1\u4f53\u7cfb",
            "\u751f\u6d3b\u65b9\u5f0f",
            "\u80fd\u6e90\u7c7b\u578b",
            "\u73af\u5883\u56e0\u7d20",
            "\u8d44\u6e90\u7ba1\u7406",
            "\u73af\u4fdd\u4ea7\u54c1",
            "\u4f01\u4e1a\u673a\u6784",
            "\u91d1\u878d\u6a21\u5f0f",
            "\u79d1\u5b66\u7814\u7a76",
            "\u6d3b\u52a8\u5021\u5bfc",
            "\u610f\u8bc6\u63d0\u5347",
            "\u73af\u5883\u5f71\u54cd",
            "\u6c61\u67d3\u6cbb\u7406",
            "\u8bc4\u4f30\u4f53\u7cfb",
            "\u5faa\u73af\u5229\u7528",
            "\u8d44\u6e90\u5316\u6280\u672f",
            "\u53ef\u6301\u7eed\u53d1\u5c55",
            "\u751f\u6001\u4fdd\u62a4",
            "\u78b3\u7ba1\u7406",
            "\u6c14\u5019\u884c\u52a8",
            "\u521b\u65b0\u5e94\u7528",
            "\u884c\u4e1a\u5b9e\u8df5",
            "\u57ce\u5e02\u89c4\u5212",
            "\u4ea4\u901a\u6a21\u5f0f",
            "\u6d88\u8d39\u6a21\u5f0f",
            "\u73af\u5883\u76d1\u6d4b",
            "\u5e9f\u5f03\u7269\u5904\u7406",
            "\u6c61\u67d3\u6e90\u63a7\u5236",
            "\u751f\u6001\u4fee\u590d",
            "\u7eff\u8272\u5efa\u7b51",
            "\u73af\u4fdd\u6280\u672f",
            "\u751f\u7269\u964d\u89e3",
            "\u80fd\u6e90\u5229\u7528"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "Qwen2.5-7B-Instruct",
            "max_tokens": 5000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 3000.0,
            "api_base": "http://192.168.0.244:8016/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 2.0,
            "num_threads": 50
        },
        "async_mode": "asyncio",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "Qwen2.5-7B-Instruct",
            "max_tokens": 5000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 3000.0,
            "api_base": "http://192.168.0.244:8016/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 3.0,
            "num_threads": 3
        },
        "async_mode": "asyncio",
        "prompt": "prompts/community_report.txt",
        "max_length": 5000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "Qwen2.5-7B-Instruct",
            "max_tokens": 5000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 3000.0,
            "api_base": "http://192.168.0.244:8016/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 2.0,
            "num_threads": 50
        },
        "async_mode": "asyncio",
        "enabled": true,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
10:21:09,888 graphrag.index.create_pipeline_config INFO skipping workflows 
10:21:09,888 graphrag.index.run INFO Running pipeline
10:21:09,888 graphrag.index.storage.file_pipeline_storage INFO Creating file storage at output/artifacts
10:21:09,888 graphrag.index.input.load_input INFO loading input from root_dir=input
10:21:09,888 graphrag.index.input.load_input INFO using file storage for input
10:21:09,889 graphrag.index.storage.file_pipeline_storage INFO search input for files matching .*\.txt$
10:21:09,889 graphrag.index.input.text INFO found text files from input, found [('Guangzhou Zhongyiyong Intelligent Technology Co., Inc._pdf.txt', {}), ('Guangzhou Zhongyiyong Intelligent Technology Co., Inc.-1.txt', {}), ('Guangzhou Zhongyiyong Intelligent Technology Co., Inc.-2.txt', {}), ('Guangzhou Zhongyiyong Intelligent Technology Co., Inc..txt', {}), ('Guangzhou Zhongyiyong Intelligent Technology Co., Inc.-0904.txt', {})]
10:21:09,890 graphrag.index.input.text INFO Found 5 files, loading 5
10:21:09,891 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_final_covariates', 'create_summarized_entities', 'join_text_units_to_covariate_ids', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents']
10:21:09,891 graphrag.index.run INFO Final # of rows loaded: 5
10:21:09,973 graphrag.index.run INFO Running workflow: create_base_text_units...
10:21:09,973 graphrag.index.run INFO Skipping create_base_text_units because it already exists
10:21:10,48 graphrag.index.run INFO Running workflow: create_base_extracted_entities...
10:21:10,49 graphrag.index.run INFO Skipping create_base_extracted_entities because it already exists
10:21:10,124 graphrag.index.run INFO Running workflow: create_final_covariates...
10:21:10,125 graphrag.index.run INFO Skipping create_final_covariates because it already exists
10:21:10,200 graphrag.index.run INFO Running workflow: create_summarized_entities...
10:21:10,201 graphrag.index.run INFO Skipping create_summarized_entities because it already exists
10:21:10,277 graphrag.index.run INFO Running workflow: join_text_units_to_covariate_ids...
10:21:10,277 graphrag.index.run INFO Skipping join_text_units_to_covariate_ids because it already exists
10:21:10,352 graphrag.index.run INFO Running workflow: create_base_entity_graph...
10:21:10,352 graphrag.index.run INFO Skipping create_base_entity_graph because it already exists
10:21:10,427 graphrag.index.run INFO Running workflow: create_final_entities...
10:21:10,428 graphrag.index.run INFO Skipping create_final_entities because it already exists
10:21:10,502 graphrag.index.run INFO Running workflow: create_final_nodes...
10:21:10,502 graphrag.index.run INFO Skipping create_final_nodes because it already exists
10:21:10,578 graphrag.index.run INFO Running workflow: create_final_communities...
10:21:10,579 graphrag.index.run INFO Skipping create_final_communities because it already exists
10:21:10,656 graphrag.index.run INFO Running workflow: join_text_units_to_entity_ids...
10:21:10,656 graphrag.index.run INFO Skipping join_text_units_to_entity_ids because it already exists
10:21:10,731 graphrag.index.run INFO Running workflow: create_final_relationships...
10:21:10,732 graphrag.index.run INFO Skipping create_final_relationships because it already exists
10:21:10,809 graphrag.index.run INFO Running workflow: join_text_units_to_relationship_ids...
10:21:10,809 graphrag.index.run INFO Skipping join_text_units_to_relationship_ids because it already exists
10:21:10,887 graphrag.index.run INFO Running workflow: create_final_community_reports...
10:21:10,888 graphrag.index.run INFO dependencies for create_final_community_reports: ['create_final_covariates', 'create_final_relationships', 'create_final_nodes']
10:21:10,888 graphrag.index.run INFO read table from storage: create_final_covariates.parquet
10:21:10,893 graphrag.index.run INFO read table from storage: create_final_relationships.parquet
10:21:10,895 graphrag.index.run INFO read table from storage: create_final_nodes.parquet
10:21:10,900 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
10:21:10,915 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
10:21:10,923 datashaper.workflow.workflow INFO executing verb prepare_community_reports_claims
10:21:10,926 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
10:21:10,934 datashaper.workflow.workflow INFO executing verb prepare_community_reports
10:21:10,934 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=3 => 653
10:21:11,46 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=2 => 653
10:21:11,116 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=1 => 653
10:21:11,220 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 653
10:21:11,285 datashaper.workflow.workflow INFO executing verb create_community_reports
10:21:11,486 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=http://192.168.0.244:8016/v1
10:21:11,498 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for Qwen2.5-7B-Instruct: TPM=0, RPM=0
10:21:11,498 graphrag.index.llm.load_llm INFO create concurrency limiter for Qwen2.5-7B-Instruct: 25
10:21:11,499 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AI585234AI[records: Entities (289, 293), Relationships (136, 141, 427, 901, 902, 903, 900)]'}, {'summary': 'AI5', 'explanation': 'AI5AI[records: Entities (289, 293), Relationships (136, 141, 427, 901, 902, 903, 900)]'}, {'summary': 'AI8', 'explanation': 'AI8AI[records: Entities (289, 293), Relationships (136, 141, 427, 901, 902, 903, 900)]'}, {'summary': 'AI52', 'explanation': 'AI52AI[records: Entities (289, 293), Relationships (136, 141, 427, 901, 902, 903, 900)]'}, {'summary': 'AI34', 'explanation': 'AI34AI[records: Entities (289, 293), Relationships (136, 141, 427, 901, 902, 903, 900)]'}, {'summary': 'AI11', 'explanation': 'AI11AI[records: Entities (289, 293), Relationships (136, 141, 427, 901, 902, 903, 900)]'}]}
10:21:11,502 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI-SEED', 'summary': 'AI-SEEDAIAIAIAIGCVRAI-SEEDAI', 'rating': 8.5, 'rating_explanation': 'AI-SEEDAI', 'findings': [{'summary': '', 'explanation': 'AI-SEEDAI-SEEDAIAIGCAI[records: Relationships (23)]'}, {'summary': 'AI-SEED', 'explanation': 'AI-SEEDAIVRAI-SEEDAIAI[records: Relationships (772, 755, 1055, 1084)]'}, {'summary': 'AI-SEED', 'explanation': 'AI-SEEDAIGCAIAI[records: Relationships (193)]'}, {'summary': '', 'explanation': 'AI-SEEDAIAI[records: Relationships (155, 1084)]'}, {'summary': 'AI-SEED', 'explanation': 'AI-SEEDVRAI-SEEDAIAI[records: Relationships (772, 755, 1055)]'}]}
10:21:11,502 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI-SEED', 'summary': 'AI-SEEDAIAIAIAI-SEEDAIAI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'AI-SEED', 'explanation': 'AI-SEEDAIAIAIAIAIAIAI[records: Entities (470, 471, 472, 473, 474, 475), Relationships (1050, 1051, 1052, 1053, 1054, 1056, 1057, 1058, 1059, 1060, 1061, 1062)]'}, {'summary': 'AI-SEED', 'explanation': 'AI-SEEDAI-SEED[records: Relationships (363)]'}, {'summary': '', 'explanation': 'AI-SEEDAI[records: Relationships (566, 567, 568, 569, 570, 571)]'}, {'summary': 'AI-SEED', 'explanation': 'AI-SEEDAI-Seed[records: Relationships (1057)]'}, {'summary': 'AI-SEED', 'explanation': 'AI-SEED[records: Relationships (1052, 1053, 1054, 1058, 1059, 1060, 1061, 1062)]'}]}
10:21:11,503 graphrag.llm.openai.utils INFO success load json in step 1{'title': ' - ', 'summary': 'IP', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': 'AI[records: Entities (463), Relationships (1040, 1041, 1042, 1039)]'}, {'summary': 'IP', 'explanation': 'IP[records: Entities (337), Relationships (1008)]'}, {'summary': '', 'explanation': '[records: Entities (340), Relationships (1014)]'}, {'summary': '', 'explanation': '[records: Entities (556), Relationships (1038)]'}, {'summary': '', 'explanation': '[records: Entities (578), Relationships (1039)]'}]}
10:21:11,504 graphrag.llm.openai.utils INFO success load json in step 1{'title': ' - ', 'summary': 'AI', 'rating': 8.5, 'rating_explanation': '', 'findings': [{'summary': '', 'explanation': 'AI[records: Relationships (1002, 475, 999, 939)]', 'findings': [{'summary': '', 'explanation': 'AI[records: Relationships (1002, 475, 999, 939)]', 'findings': [{'summary': '', 'explanation': 'AI[records: Relationships (1002, 475, 999, 939)]', 'findings': [{'summary': '', 'explanation': 'AI[records: Relationships (1002, 475, 999, 939)]', 'findings': [{'summary': '', 'explanation': 'AI[records: Relationships (1002, 475, 999, 939)]'}]}]}]}]}]}
10:21:11,523 graphrag.llm.openai.utils INFO success load json in step 1{'title': ' - ', 'summary': 'AI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': 'AI[records: Relationships (989)]'}]}
10:21:11,523 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': '60', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'AI', 'explanation': '60[records: Entities (245, 4), Relationships (173, 40, 3, 854, 39, 32, 35, 38, 41)]'}, {'summary': 'AI', 'explanation': 'AI5AI[records: Relationships (40, 3, 39, 41)]'}, {'summary': 'AI', 'explanation': 'AIAI[records: Relationships (32)]'}, {'summary': 'AI', 'explanation': 'AIAI[records: Relationships (35)]'}, {'summary': 'AI', 'explanation': 'AIAI[records: Relationships (38)]'}]}
10:21:11,524 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIAIAIAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AIAIAIAI[records: Relationships (64, 109, 114, 115, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 3, 31, 37 30, 3, 3, 3399, 37, 33701, 370,  ] ... ...  ]]', ']...]summary] ]]': ']]'}], ']]': ']...)...]...]]'}
10:21:11,535 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI - ', 'summary': 'AIAIAIAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AIAI[records: Relationships (118, 455)]', 'data_records': [{'source': '', 'ids': [456, 465, 461, 463, 464], 'reference': ''}]}]}
10:21:11,539 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'AI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': 'AI[records: Entities (82, 449, 445, 580), Relationships (356, 355, 517, 460, 467, 462, 492, 483, 458, 516, 493, 494, 497, 498, 499, 490, 485, 495, 496, 1023, 1021, 518)]'}]}
10:21:11,766 graphrag.llm.openai.utils INFO success load json in step 1{'title': ' - ', 'summary': 'AIAIAI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': 'AI[records: Relationships (12, 216)]'}]}
10:21:11,769 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': '985985', 'rating': 8.5, 'rating_explanation': '', 'findings': [{'summary': '985', 'explanation': '985[records: Entities (55, 79), Relationships (79, 272)]'}, {'summary': '', 'explanation': '985[records: Relationships (443)]'}, {'summary': '985', 'explanation': '985[records: Relationships (79, 272, 443)]'}, {'summary': '', 'explanation': '985[records: Entities (55, 79), Relationships (79, 272)]'}, {'summary': '', 'explanation': '[records: Relationships (443)]'}]}
10:21:11,769 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'AIAIGCAIAI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': 'AIAI[records: Entities (9, 267, 268, 269, 270), Relationships (50, 204, 205, 206, 209, 212, 215, 861, 862, 863, 864, 865, 866)]'}, {'summary': '', 'explanation': 'AIAIAI[records: Entities (267), Relationships (315, 316, 317, 318)]'}, {'summary': 'AI', 'explanation': 'AIAIAIAIAIAI[records: Entities (269), Relationships (317)]'}, {'summary': 'AIGC', 'explanation': 'AIGCAIAIGCAIGCAI[records: Entities (270), Relationships (318)]'}, {'summary': 'AI', 'explanation': 'AIAIAIAIAI[records: Entities (268), Relationships (316)]'}]}
10:21:11,770 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'CGAI', 'rating': 8.5, 'rating_explanation': '', 'findings': [{'summary': 'CGAI', 'explanation': 'CGCGAI[records: Entities (56), Relationships (80)]', 'records: Entities (56), Relationships (80)': ['56,CG,CG,3', '80,AI,CG,AICG,152']}]}
10:21:11,776 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'AI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'AI', 'explanation': 'AIAI[records: Entities (19), Relationships (57, 367, 369, 370, 371, 372, 373, 374, 368, 270)]'}, {'summary': 'AI', 'explanation': 'AIAR[records: Entities (27), Relationships (61, 222, 223, 388, 390, 387, 389, 396, 394)]'}, {'summary': 'AI', 'explanation': 'AIAIAI[records: Entities (28), Relationships (62, 391, 393, 381, 383, 384, 386, 396, 394)]'}, {'summary': 'AI', 'explanation': 'AI[records: Entities (25), Relationships (59, 222, 223, 382, 383, 384, 386, 396, 394)]'}, {'summary': 'AI', 'explanation': 'AI[records: Entities (26), Relationships (60, 222, 223, 385, 386, 384, 386, 396, 394)]'}]}
10:21:11,777 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIAIAIAIGCAIAIAIAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AIAIAIAIGCAIAIAIAIAI[records: Entities (173, 488, 508, 641, 581, 642, 643, 644), Relationships (773, 291, 777, 774, 778, 779, 780, 781, 782)]'}, {'summary': 'AI', 'explanation': 'AIAIAIAIAI[records: Entities (488, 508), Relationships (776, 774, 778, 779, 780, 781, 782)]'}, {'summary': 'AI', 'explanation': 'AIAIGCAIAIAI[records: Entities (641), Relationships (777)]'}, {'summary': 'AI', 'explanation': 'AIAI[records: Entities (643), Relationships (781)]'}, {'summary': 'AI', 'explanation': 'AIAIAI[records: Entities (644), Relationships (782)]'}]}
10:21:11,777 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AIGC', 'summary': 'AIGCAIGCAIAI', 'rating': 7.5, 'rating_explanation': '', 'findings': [{'summary': 'AIGC', 'explanation': 'AIGCAIAI[records: Entities (63), Relationships (292)]'}, {'summary': '', 'explanation': 'AIGC[records: Entities (62, 60), Relationships (448, 447, 449)]'}, {'summary': 'AIGCAI', 'explanation': 'AIAIGCAI[records: Relationships (451)]'}, {'summary': '', 'explanation': '985CG[records: Entities (60)]'}, {'summary': '', 'explanation': '[records: Relationships (448)]'}]}
10:21:11,782 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI-SEED', 'summary': 'AI-SEEDAI-SEEDAIAIAIGCAI-SEEDAI-SEEDAIAI', 'rating': 8.5, 'rating_explanation': 'AI-SEEDAI', 'findings': [{'summary': 'AI-SEED', 'explanation': 'AI-SEEDAIAIAIAIGCAI[records: Entities (500), Relationships (155, 20, 1058, 1059, 1060, 1056, 1057, 1050, 1051, 1052, 1053, 1054, 1058, 1059, 1060, 1056, 1057, 1050, 1051, 1052, 1053, 1054)]'}, {'summary': 'AI-SEED', 'explanation': 'AI-SEEDAIAIAIAI-SEEDAI[records: Entities (470), Relationships (363, 190, 1047, 1048, 1049, 1052, 1053, 1054, 1058, 1059, 1060, 1056, 1057, 1050, 1051, 1052, 1053, 1054)]'}, {'summary': '', 'explanation': 'AI-Seed[records: Entities (473, 474, 475), Relationships (1052, 1053, 1054, 1058, 1059, 1060, 1056, 1057, 1050, 1051, 1052, 1053, 1054)]'}, {'summary': 'AI', 'explanation': 'AI-SeedAIAIAI-SeedAIAIAI[records: Entities (471, 472), Relationships (1050, 1051, 1052, 1053, 1054, 1056, 1057, 1058, 1059, 1060, 1056, 1057, 1050, 1051, 1052, 1053, 1054)]'}, {'summary': 'AI-SEED', 'explanation': 'AI-SEEDAI-SeedAI-Seed[records: Entities (513, 649), Relationships (1057, 1056, 1058, 1059, 1060, 1056, 1057, 1050, 1051, 1052, 1053, 1054)]'}]}
10:21:11,783 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIAIAIAIAIAI-SeedAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AIAIAIAIAIAIAIAI[records: Entities (511, 584, 507)]'}, {'summary': '', 'explanation': 'AIAIAIAI[records: Relationships (1032, 1087)]'}, {'summary': 'AI-Seed', 'explanation': 'AIAI-SeedAIAI-SeedAIAIAIAI[records: Relationships (1048)]'}, {'summary': '', 'explanation': 'AIAIAIAI[records: Relationships (1086)]'}, {'summary': '', 'explanation': 'AIAIAIAIAI[records: Entities (511, 507)]'}]}
10:21:11,783 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI-Seed', 'summary': 'AI-SeedAIAIAI', 'rating': 8.5, 'rating_explanation': 'AI-SeedAI', 'findings': [{'summary': 'AI-Seed', 'explanation': 'AI-SeedAIAIAIAIAIAIAIAIAI[records: Entities (482, 502, 483, 484, 485)]'}, {'summary': 'AI-Seed', 'explanation': 'AI-SeedAI-SeedAI[records: Relationships (261, 1061, 1062, 1063, 1064, 1065, 1058, 1069, 1083, 1070, 1071, 1072)]'}, {'summary': 'AI', 'explanation': 'AIAI-SeedAIAIAI[records: Entities (502)]'}, {'summary': 'AI', 'explanation': 'AIGCAIAI-SeedAIAI[records: Entities (485)]'}, {'summary': 'AIGCAI-Seed', 'explanation': 'AIGCAI-SeedAI[records: Relationships (187, 1070, 1071, 1072)]'}]}
10:21:11,784 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AIGC', 'summary': 'AIGCAIGCAIGCAI', 'rating': 8.5, 'rating_explanation': 'AIGCAI', 'findings': [{'summary': '', 'explanation': '[records: Entities (85, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, \t]', ']   ]': ']... \t]', '] records<tool_call> ]   ...... records<tool_call><tool_call> ,<tool_call> , \t],': '] NONE ......   ...    NONE NONE \t]'}]}
10:21:11,785 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'VR', 'rating': 8.0, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': '[records: Entities (454), Relationships (555, 761, 1028)]'}, {'summary': '', 'explanation': '[records: Relationships (555)]'}, {'summary': 'VR', 'explanation': 'VRVR[records: Relationships (761)]'}, {'summary': '', 'explanation': '[records: Relationships (882, 1028)]'}, {'summary': '', 'explanation': '[records: Relationships (555)]'}]}
10:21:11,789 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': '', 'rating': 8.0, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': '[records: Entities (118, 462, 119, 97, 1035, 649, 648, 650, 578), Relationships (342, 537, 538, 542, 532, 582, 583, 1035, 649, 648, 650, 578)]'}, {'summary': '', 'explanation': '[records: Relationships (537, 538, 542, 532, 582, 583)]'}, {'summary': '', 'explanation': '[records: Relationships (542, 583)]'}, {'summary': '', 'explanation': '[records: Relationships (532, 578)]'}, {'summary': '', 'explanation': '[records: Relationships (1035, 649, 648, 650, 578)]'}]}
10:21:11,790 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'VR', 'summary': 'VRVRAI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'VR', 'explanation': 'VRVRVRAIVRAIGCAI[records: Entities (170, 627, 587, 628, 762, 763, 764, 765, 766, 767, 768, 770, 771, 772, 760, 761, 769, 757, 758, 759, 769)]'}, {'summary': '', 'explanation': 'VRVRVR[records: Entities (169, 25, 757, 758, 759)]'}, {'summary': '', 'explanation': 'VR[records: Entities (594, 628, 769, 758, 759)]'}, {'summary': 'VRAIGC', 'explanation': 'VRAIGCAIGCVRVRAIGC[records: Entities (763, 764)]'}, {'summary': 'VR', 'explanation': 'VRVR[records: Entities (594, 762)]'}]}
10:27:54,317 graphrag.index.cli INFO Logging enabled at output/reports/indexing-engine.log
10:27:54,319 graphrag.index.cli INFO Starting pipeline run for: 20241126-102754, dryrun=False
10:27:54,319 graphrag.index.cli INFO Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "openai_chat",
        "model": "Qwen2.5-7B-Instruct",
        "max_tokens": 5000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 3000.0,
        "api_base": "http://192.168.0.244:8016/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 2.0,
        "num_threads": 50
    },
    "async_mode": "asyncio",
    "root_dir": ".",
    "reporting": {
        "type": "file",
        "base_dir": "output/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "model": "m3e-large",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://192.168.0.244:8016/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 2.0,
            "num_threads": 50
        },
        "async_mode": "asyncio",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 500,
        "overlap": 200,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "Qwen2.5-7B-Instruct",
            "max_tokens": 5000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 3000.0,
            "api_base": "http://192.168.0.244:8016/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 2.0,
            "num_threads": 50
        },
        "async_mode": "asyncio",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "\u653f\u7b56\u6cd5\u89c4",
            "\u5206\u7c7b\u65b9\u6cd5",
            "\u5904\u7406\u6280\u672f",
            "\u56de\u6536\u6750\u6599",
            "\u8bbe\u65bd\u8bbe\u5907",
            "\u5206\u7c7b\u6807\u51c6",
            "\u7ba1\u7406\u7ec4\u7ec7",
            "\u7ecf\u6d4e\u6a21\u5f0f",
            "\u6559\u80b2\u57f9\u8bad",
            "\u8ba4\u8bc1\u4f53\u7cfb",
            "\u751f\u6d3b\u65b9\u5f0f",
            "\u80fd\u6e90\u7c7b\u578b",
            "\u73af\u5883\u56e0\u7d20",
            "\u8d44\u6e90\u7ba1\u7406",
            "\u73af\u4fdd\u4ea7\u54c1",
            "\u4f01\u4e1a\u673a\u6784",
            "\u91d1\u878d\u6a21\u5f0f",
            "\u79d1\u5b66\u7814\u7a76",
            "\u6d3b\u52a8\u5021\u5bfc",
            "\u610f\u8bc6\u63d0\u5347",
            "\u73af\u5883\u5f71\u54cd",
            "\u6c61\u67d3\u6cbb\u7406",
            "\u8bc4\u4f30\u4f53\u7cfb",
            "\u5faa\u73af\u5229\u7528",
            "\u8d44\u6e90\u5316\u6280\u672f",
            "\u53ef\u6301\u7eed\u53d1\u5c55",
            "\u751f\u6001\u4fdd\u62a4",
            "\u78b3\u7ba1\u7406",
            "\u6c14\u5019\u884c\u52a8",
            "\u521b\u65b0\u5e94\u7528",
            "\u884c\u4e1a\u5b9e\u8df5",
            "\u57ce\u5e02\u89c4\u5212",
            "\u4ea4\u901a\u6a21\u5f0f",
            "\u6d88\u8d39\u6a21\u5f0f",
            "\u73af\u5883\u76d1\u6d4b",
            "\u5e9f\u5f03\u7269\u5904\u7406",
            "\u6c61\u67d3\u6e90\u63a7\u5236",
            "\u751f\u6001\u4fee\u590d",
            "\u7eff\u8272\u5efa\u7b51",
            "\u73af\u4fdd\u6280\u672f",
            "\u751f\u7269\u964d\u89e3",
            "\u80fd\u6e90\u5229\u7528"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "Qwen2.5-7B-Instruct",
            "max_tokens": 5000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 3000.0,
            "api_base": "http://192.168.0.244:8016/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 2.0,
            "num_threads": 50
        },
        "async_mode": "asyncio",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "Qwen2.5-7B-Instruct",
            "max_tokens": 5000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 3000.0,
            "api_base": "http://192.168.0.244:8016/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 3.0,
            "num_threads": 3
        },
        "async_mode": "asyncio",
        "prompt": "prompts/community_report.txt",
        "max_length": 5000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "Qwen2.5-7B-Instruct",
            "max_tokens": 5000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 3000.0,
            "api_base": "http://192.168.0.244:8016/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 2.0,
            "num_threads": 50
        },
        "async_mode": "asyncio",
        "enabled": true,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
10:27:54,320 graphrag.index.create_pipeline_config INFO skipping workflows 
10:27:54,320 graphrag.index.run INFO Running pipeline
10:27:54,320 graphrag.index.storage.file_pipeline_storage INFO Creating file storage at output/artifacts
10:27:54,320 graphrag.index.input.load_input INFO loading input from root_dir=input
10:27:54,320 graphrag.index.input.load_input INFO using file storage for input
10:27:54,321 graphrag.index.storage.file_pipeline_storage INFO search input for files matching .*\.txt$
10:27:54,321 graphrag.index.input.text INFO found text files from input, found [('Guangzhou Zhongyiyong Intelligent Technology Co., Inc._pdf.txt', {}), ('Guangzhou Zhongyiyong Intelligent Technology Co., Inc.-1.txt', {}), ('Guangzhou Zhongyiyong Intelligent Technology Co., Inc.-2.txt', {}), ('Guangzhou Zhongyiyong Intelligent Technology Co., Inc..txt', {}), ('Guangzhou Zhongyiyong Intelligent Technology Co., Inc.-0904.txt', {})]
10:27:54,322 graphrag.index.input.text INFO Found 5 files, loading 5
10:27:54,323 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_final_covariates', 'create_summarized_entities', 'join_text_units_to_covariate_ids', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents']
10:27:54,323 graphrag.index.run INFO Final # of rows loaded: 5
10:27:54,405 graphrag.index.run INFO Running workflow: create_base_text_units...
10:27:54,406 graphrag.index.run INFO Skipping create_base_text_units because it already exists
10:27:54,480 graphrag.index.run INFO Running workflow: create_base_extracted_entities...
10:27:54,481 graphrag.index.run INFO Skipping create_base_extracted_entities because it already exists
10:27:54,563 graphrag.index.run INFO Running workflow: create_final_covariates...
10:27:54,563 graphrag.index.run INFO Skipping create_final_covariates because it already exists
10:27:54,640 graphrag.index.run INFO Running workflow: create_summarized_entities...
10:27:54,640 graphrag.index.run INFO Skipping create_summarized_entities because it already exists
10:27:54,721 graphrag.index.run INFO Running workflow: join_text_units_to_covariate_ids...
10:27:54,721 graphrag.index.run INFO Skipping join_text_units_to_covariate_ids because it already exists
10:27:54,802 graphrag.index.run INFO Running workflow: create_base_entity_graph...
10:27:54,803 graphrag.index.run INFO Skipping create_base_entity_graph because it already exists
10:27:54,879 graphrag.index.run INFO Running workflow: create_final_entities...
10:27:54,879 graphrag.index.run INFO Skipping create_final_entities because it already exists
10:27:54,959 graphrag.index.run INFO Running workflow: create_final_nodes...
10:27:54,960 graphrag.index.run INFO Skipping create_final_nodes because it already exists
10:27:55,37 graphrag.index.run INFO Running workflow: create_final_communities...
10:27:55,37 graphrag.index.run INFO Skipping create_final_communities because it already exists
10:27:55,117 graphrag.index.run INFO Running workflow: join_text_units_to_entity_ids...
10:27:55,117 graphrag.index.run INFO Skipping join_text_units_to_entity_ids because it already exists
10:27:55,192 graphrag.index.run INFO Running workflow: create_final_relationships...
10:27:55,192 graphrag.index.run INFO Skipping create_final_relationships because it already exists
10:27:55,267 graphrag.index.run INFO Running workflow: join_text_units_to_relationship_ids...
10:27:55,268 graphrag.index.run INFO Skipping join_text_units_to_relationship_ids because it already exists
10:27:55,352 graphrag.index.run INFO Running workflow: create_final_community_reports...
10:27:55,352 graphrag.index.run INFO dependencies for create_final_community_reports: ['create_final_nodes', 'create_final_covariates', 'create_final_relationships']
10:27:55,353 graphrag.index.run INFO read table from storage: create_final_nodes.parquet
10:27:55,359 graphrag.index.run INFO read table from storage: create_final_covariates.parquet
10:27:55,361 graphrag.index.run INFO read table from storage: create_final_relationships.parquet
10:27:55,366 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
10:27:55,381 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
10:27:55,389 datashaper.workflow.workflow INFO executing verb prepare_community_reports_claims
10:27:55,393 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
10:27:55,401 datashaper.workflow.workflow INFO executing verb prepare_community_reports
10:27:55,401 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=3 => 653
10:27:55,526 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=2 => 653
10:27:55,603 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=1 => 653
10:27:55,707 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 653
10:27:55,772 datashaper.workflow.workflow INFO executing verb create_community_reports
10:27:55,974 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=http://192.168.0.244:8016/v1
10:27:55,986 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for Qwen2.5-7B-Instruct: TPM=0, RPM=0
10:27:55,986 graphrag.index.llm.load_llm INFO create concurrency limiter for Qwen2.5-7B-Instruct: 25
10:27:55,987 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI-SEED', 'summary': 'AI-SEEDAIAIAIAI-SEEDAIAI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'AI-SEED', 'explanation': 'AI-SEEDAIAIAIAIAIAIAI[records: Entities (470, 471, 472, 473, 474, 475), Relationships (1050, 1051, 1052, 1053, 1054, 1056, 1057, 1058, 1059, 1060, 1061, 1062)]'}, {'summary': 'AI-SEED', 'explanation': 'AI-SEEDAI-SEED[records: Relationships (363)]'}, {'summary': '', 'explanation': 'AI-SEEDAI[records: Relationships (566, 567, 568, 569, 570, 571)]'}, {'summary': 'AI-SEED', 'explanation': 'AI-SEEDAI-Seed[records: Relationships (1057)]'}, {'summary': 'AI-SEED', 'explanation': 'AI-SEED[records: Relationships (1052, 1053, 1054, 1058, 1059, 1060, 1061, 1062)]'}]}
10:27:55,990 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AI585234AI[records: Entities (289, 293), Relationships (136, 141, 427, 901, 902, 903, 900)]'}, {'summary': 'AI5', 'explanation': 'AI5AI[records: Entities (289, 293), Relationships (136, 141, 427, 901, 902, 903, 900)]'}, {'summary': 'AI8', 'explanation': 'AI8AI[records: Entities (289, 293), Relationships (136, 141, 427, 901, 902, 903, 900)]'}, {'summary': 'AI52', 'explanation': 'AI52AI[records: Entities (289, 293), Relationships (136, 141, 427, 901, 902, 903, 900)]'}, {'summary': 'AI34', 'explanation': 'AI34AI[records: Entities (289, 293), Relationships (136, 141, 427, 901, 902, 903, 900)]'}, {'summary': 'AI11', 'explanation': 'AI11AI[records: Entities (289, 293), Relationships (136, 141, 427, 901, 902, 903, 900)]'}]}
10:27:55,990 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI-SEED', 'summary': 'AI-SEEDAIAIAIAIGCVRAI-SEEDAI', 'rating': 8.5, 'rating_explanation': 'AI-SEEDAI', 'findings': [{'summary': '', 'explanation': 'AI-SEEDAI-SEEDAIAIGCAI[records: Relationships (23)]'}, {'summary': 'AI-SEED', 'explanation': 'AI-SEEDAIVRAI-SEEDAIAI[records: Relationships (772, 755, 1055, 1084)]'}, {'summary': 'AI-SEED', 'explanation': 'AI-SEEDAIGCAIAI[records: Relationships (193)]'}, {'summary': '', 'explanation': 'AI-SEEDAIAI[records: Relationships (155, 1084)]'}, {'summary': 'AI-SEED', 'explanation': 'AI-SEEDVRAI-SEEDAIAI[records: Relationships (772, 755, 1055)]'}]}
10:27:55,991 graphrag.llm.openai.utils INFO success load json in step 1{'title': ' - ', 'summary': 'AI', 'rating': 8.5, 'rating_explanation': '', 'findings': [{'summary': '', 'explanation': 'AI[records: Relationships (1002, 475, 999, 939)]', 'findings': [{'summary': '', 'explanation': 'AI[records: Relationships (1002, 475, 999, 939)]', 'findings': [{'summary': '', 'explanation': 'AI[records: Relationships (1002, 475, 999, 939)]', 'findings': [{'summary': '', 'explanation': 'AI[records: Relationships (1002, 475, 999, 939)]', 'findings': [{'summary': '', 'explanation': 'AI[records: Relationships (1002, 475, 999, 939)]'}]}]}]}]}]}
10:27:55,991 graphrag.llm.openai.utils INFO success load json in step 1{'title': ' - ', 'summary': 'AI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': 'AI[records: Relationships (989)]'}]}
10:27:55,991 graphrag.llm.openai.utils INFO success load json in step 1{'title': ' - ', 'summary': 'IP', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': 'AI[records: Entities (463), Relationships (1040, 1041, 1042, 1039)]'}, {'summary': 'IP', 'explanation': 'IP[records: Entities (337), Relationships (1008)]'}, {'summary': '', 'explanation': '[records: Entities (340), Relationships (1014)]'}, {'summary': '', 'explanation': '[records: Entities (556), Relationships (1038)]'}, {'summary': '', 'explanation': '[records: Entities (578), Relationships (1039)]'}]}
10:27:55,992 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI - ', 'summary': 'AIAIAIAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AIAI[records: Relationships (118, 455)]', 'data_records': [{'source': '', 'ids': [456, 465, 461, 463, 464], 'reference': ''}]}]}
10:27:55,992 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'AI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': 'AI[records: Entities (82, 449, 445, 580), Relationships (356, 355, 517, 460, 467, 462, 492, 483, 458, 516, 493, 494, 497, 498, 499, 490, 485, 495, 496, 1023, 1021, 518)]'}]}
10:27:55,993 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': '60', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'AI', 'explanation': '60[records: Entities (245, 4), Relationships (173, 40, 3, 854, 39, 32, 35, 38, 41)]'}, {'summary': 'AI', 'explanation': 'AI5AI[records: Relationships (40, 3, 39, 41)]'}, {'summary': 'AI', 'explanation': 'AIAI[records: Relationships (32)]'}, {'summary': 'AI', 'explanation': 'AIAI[records: Relationships (35)]'}, {'summary': 'AI', 'explanation': 'AIAI[records: Relationships (38)]'}]}
10:27:55,993 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIAIAIAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AIAIAIAI[records: Relationships (64, 109, 114, 115, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 3, 31, 37 30, 3, 3, 3399, 37, 33701, 370,  ] ... ...  ]]', ']...]summary] ]]': ']]'}], ']]': ']...)...]...]]'}
10:27:56,220 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'AI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'AI', 'explanation': 'AIAI[records: Entities (19), Relationships (57, 367, 369, 370, 371, 372, 373, 374, 368, 270)]'}, {'summary': 'AI', 'explanation': 'AIAR[records: Entities (27), Relationships (61, 222, 223, 388, 390, 387, 389, 396, 394)]'}, {'summary': 'AI', 'explanation': 'AIAIAI[records: Entities (28), Relationships (62, 391, 393, 381, 383, 384, 386, 396, 394)]'}, {'summary': 'AI', 'explanation': 'AI[records: Entities (25), Relationships (59, 222, 223, 382, 383, 384, 386, 396, 394)]'}, {'summary': 'AI', 'explanation': 'AI[records: Entities (26), Relationships (60, 222, 223, 385, 386, 384, 386, 396, 394)]'}]}
10:27:56,222 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': '985985', 'rating': 8.5, 'rating_explanation': '', 'findings': [{'summary': '985', 'explanation': '985[records: Entities (55, 79), Relationships (79, 272)]'}, {'summary': '', 'explanation': '985[records: Relationships (443)]'}, {'summary': '985', 'explanation': '985[records: Relationships (79, 272, 443)]'}, {'summary': '', 'explanation': '985[records: Entities (55, 79), Relationships (79, 272)]'}, {'summary': '', 'explanation': '[records: Relationships (443)]'}]}
10:27:56,223 graphrag.llm.openai.utils INFO success load json in step 1{'title': ' - ', 'summary': 'AIAIAI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': 'AI[records: Relationships (12, 216)]'}]}
10:27:56,230 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'CGAI', 'rating': 8.5, 'rating_explanation': '', 'findings': [{'summary': 'CGAI', 'explanation': 'CGCGAI[records: Entities (56), Relationships (80)]', 'records: Entities (56), Relationships (80)': ['56,CG,CG,3', '80,AI,CG,AICG,152']}]}
10:27:56,230 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'AIAIGCAIAI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': 'AIAI[records: Entities (9, 267, 268, 269, 270), Relationships (50, 204, 205, 206, 209, 212, 215, 861, 862, 863, 864, 865, 866)]'}, {'summary': '', 'explanation': 'AIAIAI[records: Entities (267), Relationships (315, 316, 317, 318)]'}, {'summary': 'AI', 'explanation': 'AIAIAIAIAIAI[records: Entities (269), Relationships (317)]'}, {'summary': 'AIGC', 'explanation': 'AIGCAIAIGCAIGCAI[records: Entities (270), Relationships (318)]'}, {'summary': 'AI', 'explanation': 'AIAIAIAIAI[records: Entities (268), Relationships (316)]'}]}
10:27:56,231 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIAIAIAIGCAIAIAIAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AIAIAIAIGCAIAIAIAIAI[records: Entities (173, 488, 508, 641, 581, 642, 643, 644), Relationships (773, 291, 777, 774, 778, 779, 780, 781, 782)]'}, {'summary': 'AI', 'explanation': 'AIAIAIAIAI[records: Entities (488, 508), Relationships (776, 774, 778, 779, 780, 781, 782)]'}, {'summary': 'AI', 'explanation': 'AIAIGCAIAIAI[records: Entities (641), Relationships (777)]'}, {'summary': 'AI', 'explanation': 'AIAI[records: Entities (643), Relationships (781)]'}, {'summary': 'AI', 'explanation': 'AIAIAI[records: Entities (644), Relationships (782)]'}]}
10:27:56,232 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AIGC', 'summary': 'AIGCAIGCAIAI', 'rating': 7.5, 'rating_explanation': '', 'findings': [{'summary': 'AIGC', 'explanation': 'AIGCAIAI[records: Entities (63), Relationships (292)]'}, {'summary': '', 'explanation': 'AIGC[records: Entities (62, 60), Relationships (448, 447, 449)]'}, {'summary': 'AIGCAI', 'explanation': 'AIAIGCAI[records: Relationships (451)]'}, {'summary': '', 'explanation': '985CG[records: Entities (60)]'}, {'summary': '', 'explanation': '[records: Relationships (448)]'}]}
10:27:56,236 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI-SEED', 'summary': 'AI-SEEDAI-SEEDAIAIAIGCAI-SEEDAI-SEEDAIAI', 'rating': 8.5, 'rating_explanation': 'AI-SEEDAI', 'findings': [{'summary': 'AI-SEED', 'explanation': 'AI-SEEDAIAIAIAIGCAI[records: Entities (500), Relationships (155, 20, 1058, 1059, 1060, 1056, 1057, 1050, 1051, 1052, 1053, 1054, 1058, 1059, 1060, 1056, 1057, 1050, 1051, 1052, 1053, 1054)]'}, {'summary': 'AI-SEED', 'explanation': 'AI-SEEDAIAIAIAI-SEEDAI[records: Entities (470), Relationships (363, 190, 1047, 1048, 1049, 1052, 1053, 1054, 1058, 1059, 1060, 1056, 1057, 1050, 1051, 1052, 1053, 1054)]'}, {'summary': '', 'explanation': 'AI-Seed[records: Entities (473, 474, 475), Relationships (1052, 1053, 1054, 1058, 1059, 1060, 1056, 1057, 1050, 1051, 1052, 1053, 1054)]'}, {'summary': 'AI', 'explanation': 'AI-SeedAIAIAI-SeedAIAIAI[records: Entities (471, 472), Relationships (1050, 1051, 1052, 1053, 1054, 1056, 1057, 1058, 1059, 1060, 1056, 1057, 1050, 1051, 1052, 1053, 1054)]'}, {'summary': 'AI-SEED', 'explanation': 'AI-SEEDAI-SeedAI-Seed[records: Entities (513, 649), Relationships (1057, 1056, 1058, 1059, 1060, 1056, 1057, 1050, 1051, 1052, 1053, 1054)]'}]}
10:27:56,236 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI', 'summary': 'AIAIAIAIAIAI-SeedAI', 'rating': 8.5, 'rating_explanation': 'AIAI', 'findings': [{'summary': 'AI', 'explanation': 'AIAIAIAIAIAIAIAI[records: Entities (511, 584, 507)]'}, {'summary': '', 'explanation': 'AIAIAIAI[records: Relationships (1032, 1087)]'}, {'summary': 'AI-Seed', 'explanation': 'AIAI-SeedAIAI-SeedAIAIAIAI[records: Relationships (1048)]'}, {'summary': '', 'explanation': 'AIAIAIAI[records: Relationships (1086)]'}, {'summary': '', 'explanation': 'AIAIAIAIAI[records: Entities (511, 507)]'}]}
10:27:56,237 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AI-Seed', 'summary': 'AI-SeedAIAIAI', 'rating': 8.5, 'rating_explanation': 'AI-SeedAI', 'findings': [{'summary': 'AI-Seed', 'explanation': 'AI-SeedAIAIAIAIAIAIAIAIAI[records: Entities (482, 502, 483, 484, 485)]'}, {'summary': 'AI-Seed', 'explanation': 'AI-SeedAI-SeedAI[records: Relationships (261, 1061, 1062, 1063, 1064, 1065, 1058, 1069, 1083, 1070, 1071, 1072)]'}, {'summary': 'AI', 'explanation': 'AIAI-SeedAIAIAI[records: Entities (502)]'}, {'summary': 'AI', 'explanation': 'AIGCAIAI-SeedAIAI[records: Entities (485)]'}, {'summary': 'AIGCAI-Seed', 'explanation': 'AIGCAI-SeedAI[records: Relationships (187, 1070, 1071, 1072)]'}]}
10:27:56,237 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'AIGC', 'summary': 'AIGCAIGCAIGCAI', 'rating': 8.5, 'rating_explanation': 'AIGCAI', 'findings': [{'summary': '', 'explanation': '[records: Entities (85, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, \t]', ']   ]': ']... \t]', '] records<tool_call> ]   ...... records<tool_call><tool_call> ,<tool_call> , \t],': '] NONE ......   ...    NONE NONE \t]'}]}
10:27:56,238 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': 'VR', 'rating': 8.0, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': '[records: Entities (454), Relationships (555, 761, 1028)]'}, {'summary': '', 'explanation': '[records: Relationships (555)]'}, {'summary': 'VR', 'explanation': 'VRVR[records: Relationships (761)]'}, {'summary': '', 'explanation': '[records: Relationships (882, 1028)]'}, {'summary': '', 'explanation': '[records: Relationships (555)]'}]}
10:27:56,238 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': '', 'rating': 8.0, 'rating_explanation': 'AI', 'findings': [{'summary': '', 'explanation': '[records: Entities (118, 462, 119, 97, 1035, 649, 648, 650, 578), Relationships (342, 537, 538, 542, 532, 582, 583, 1035, 649, 648, 650, 578)]'}, {'summary': '', 'explanation': '[records: Relationships (537, 538, 542, 532, 582, 583)]'}, {'summary': '', 'explanation': '[records: Relationships (542, 583)]'}, {'summary': '', 'explanation': '[records: Relationships (532, 578)]'}, {'summary': '', 'explanation': '[records: Relationships (1035, 649, 648, 650, 578)]'}]}
10:27:56,239 graphrag.llm.openai.utils INFO success load json in step 1{'title': 'VR', 'summary': 'VRVRAI', 'rating': 8.5, 'rating_explanation': 'AI', 'findings': [{'summary': 'VR', 'explanation': 'VRVRVRAIVRAIGCAI[records: Entities (170, 627, 587, 628, 762, 763, 764, 765, 766, 767, 768, 770, 771, 772, 760, 761, 769, 757, 758, 759, 769)]'}, {'summary': '', 'explanation': 'VRVRVR[records: Entities (169, 25, 757, 758, 759)]'}, {'summary': '', 'explanation': 'VR[records: Entities (594, 628, 769, 758, 759)]'}, {'summary': 'VRAIGC', 'explanation': 'VRAIGCAIGCVRVRAIGC[records: Entities (763, 764)]'}, {'summary': 'VR', 'explanation': 'VRVR[records: Entities (594, 762)]'}]}
10:43:08,229 httpx INFO HTTP Request: POST http://192.168.0.244:8016/v1/chat/completions "HTTP/1.1 200 OK"
10:43:08,231 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
10:43:08,231 graphrag.llm.openai.utils INFO Error: JSONDecodeError
10:43:08,231 graphrag.llm.openai.utils INFO Execption: not expected dict type. result: , result will be None, type=<class 'str'>:
