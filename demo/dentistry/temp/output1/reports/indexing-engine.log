00:29:17,295 graphrag.index.cli INFO Logging enabled at output/reports/indexing-engine.log
00:29:17,296 graphrag.index.cli INFO Starting pipeline run for: 20240908-002917, dryrun=False
00:29:17,297 graphrag.index.cli INFO Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "openai_chat",
        "model": "Qwen2-7B-Instruct",
        "max_tokens": 6000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 3000.0,
        "api_base": "http://192.168.0.245:5008/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 2.0,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": ".",
    "reporting": {
        "type": "file",
        "base_dir": "output/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "model": "m3e-large",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://192.168.0.245:6008/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 2.0,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 600,
        "overlap": 150,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "Qwen2-7B-Instruct",
            "max_tokens": 6000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 3000.0,
            "api_base": "http://192.168.0.245:5008/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 2.0,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "\u5e74\u9f84\u7fa4\u4f53",
            "\u6cbb\u7597\u65b9\u6cd5",
            "\u75c7\u72b6",
            "\u65e9\u671f\u75c7\u72b6",
            "\u5e38\u89c1\u75c7\u72b6",
            "\u5065\u5eb7\u72b6\u51b5",
            "\u75be\u75c5\u540d\u79f0",
            "\u68c0\u67e5\u9879\u76ee",
            "\u836f\u7269\u540d\u79f0",
            "\u751f\u6d3b\u65b9\u5f0f",
            "\u98ce\u9669\u56e0\u7d20",
            "\u9884\u9632\u63aa\u65bd",
            "\u533b\u7597\u673a\u6784",
            "\u4e13\u79d1\u9886\u57df",
            "\u75c5\u7406\u7c7b\u578b",
            "\u4e34\u5e8a\u8bd5\u9a8c",
            "\u8425\u517b\u7d20",
            "\u5fc3\u7406\u72b6\u6001",
            "\u5eb7\u590d\u63aa\u65bd",
            "\u6ce8\u610f\u4e8b\u9879",
            "\u6cbb\u7597\u65b9\u6848",
            "\u8eab\u4f53\u5668\u5b98",
            "\u5176\u4ed6"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "Qwen2-7B-Instruct",
            "max_tokens": 6000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 3000.0,
            "api_base": "http://192.168.0.245:5008/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 2.0,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "Qwen2-7B-Instruct",
            "max_tokens": 6000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 3000.0,
            "api_base": "http://192.168.0.245:5008/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 3.0,
            "num_threads": 3
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 5000,
        "max_input_length": 3000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "Qwen2-7B-Instruct",
            "max_tokens": 6000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 3000.0,
            "api_base": "http://192.168.0.245:5008/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 2.0,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": true,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
00:29:17,297 graphrag.index.create_pipeline_config INFO skipping workflows 
00:29:17,297 graphrag.index.run INFO Running pipeline
00:29:17,297 graphrag.index.storage.file_pipeline_storage INFO Creating file storage at output/artifacts
00:29:17,297 graphrag.index.input.load_input INFO loading input from root_dir=input
00:29:17,297 graphrag.index.input.load_input INFO using file storage for input
00:29:17,298 graphrag.index.storage.file_pipeline_storage INFO search input for files matching .*\.txt$
00:29:17,298 graphrag.index.input.text INFO found text files from input, found [('dentistry.txt', {})]
00:29:17,299 graphrag.index.input.text INFO Found 1 files, loading 1
00:29:17,300 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_final_covariates', 'create_summarized_entities', 'join_text_units_to_covariate_ids', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents']
00:29:17,300 graphrag.index.run INFO Final # of rows loaded: 1
00:29:17,376 graphrag.index.run INFO Running workflow: create_base_text_units...
00:29:17,376 graphrag.index.run INFO dependencies for create_base_text_units: []
00:29:17,379 datashaper.workflow.workflow INFO executing verb orderby
00:29:17,380 datashaper.workflow.workflow INFO executing verb zip
00:29:17,382 datashaper.workflow.workflow INFO executing verb aggregate_override
00:29:17,384 datashaper.workflow.workflow INFO executing verb chunk
00:29:17,470 datashaper.workflow.workflow INFO executing verb select
00:29:17,473 datashaper.workflow.workflow INFO executing verb unroll
00:29:17,475 datashaper.workflow.workflow INFO executing verb rename
00:29:17,477 datashaper.workflow.workflow INFO executing verb genid
00:29:17,480 datashaper.workflow.workflow INFO executing verb unzip
00:29:17,483 datashaper.workflow.workflow INFO executing verb copy
00:29:17,485 datashaper.workflow.workflow INFO executing verb filter
00:29:17,488 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_text_units.parquet
00:29:17,576 graphrag.index.run INFO Running workflow: create_base_extracted_entities...
00:29:17,576 graphrag.index.run INFO dependencies for create_base_extracted_entities: ['create_base_text_units']
00:29:17,576 graphrag.index.run INFO read table from storage: create_base_text_units.parquet
00:29:17,584 datashaper.workflow.workflow INFO executing verb entity_extract
00:29:17,585 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=http://192.168.0.245:5008/v1
00:29:17,597 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for Qwen2-7B-Instruct: TPM=0, RPM=0
00:29:17,597 graphrag.index.llm.load_llm INFO create concurrency limiter for Qwen2-7B-Instruct: 25
00:29:38,17 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:29:38,19 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 20.404726300999755. input_tokens=3944, output_tokens=1221
00:29:44,394 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:29:44,395 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 26.77849239000352. input_tokens=3944, output_tokens=1590
00:29:46,681 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:29:46,682 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 29.061898301995825. input_tokens=3772, output_tokens=1632
00:29:48,541 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:29:48,542 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 30.92322593499557. input_tokens=3944, output_tokens=1965
00:30:10,162 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:30:10,163 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 25.76671543798875. input_tokens=55, output_tokens=1585
00:30:12,885 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:30:12,886 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 55.275891436991515. input_tokens=3944, output_tokens=3761
00:30:14,762 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:30:14,762 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 28.07903749200341. input_tokens=55, output_tokens=1608
00:30:16,691 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:30:16,692 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 28.149047254002653. input_tokens=55, output_tokens=1898
00:30:21,319 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:30:21,320 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 63.711653297999874. input_tokens=3944, output_tokens=3713
00:30:26,509 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:30:26,510 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 13.622797160991468. input_tokens=55, output_tokens=735
00:30:27,765 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:30:27,766 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 70.16637733700918. input_tokens=3944, output_tokens=4495
00:30:30,653 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:30:30,654 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 73.04214033699827. input_tokens=3944, output_tokens=4258
00:30:55,258 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:30:55,259 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 27.49204575899057. input_tokens=55, output_tokens=1845
00:31:17,37 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:31:17,38 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 46.38194460100203. input_tokens=55, output_tokens=2985
00:31:18,710 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:31:18,711 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 57.38999869899999. input_tokens=55, output_tokens=3568
00:32:03,575 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:32:03,575 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:32:03,577 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 165.9724521659955. input_tokens=3944, output_tokens=12535
00:32:03,579 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 165.97183730300458. input_tokens=3943, output_tokens=10363
00:32:23,596 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:32:23,598 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 165.5774094179942. input_tokens=55, output_tokens=10266
00:32:31,108 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:32:31,109 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 27.52629650500603. input_tokens=55, output_tokens=1827
00:34:36,777 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:34:36,779 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 153.1985601060005. input_tokens=55, output_tokens=12015
00:34:36,787 datashaper.workflow.workflow INFO executing verb merge_graphs
00:34:36,799 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_extracted_entities.parquet
00:34:36,882 graphrag.index.run INFO Running workflow: create_final_covariates...
00:34:36,883 graphrag.index.run INFO dependencies for create_final_covariates: ['create_base_text_units']
00:34:36,883 graphrag.index.run INFO read table from storage: create_base_text_units.parquet
00:34:36,891 datashaper.workflow.workflow INFO executing verb extract_covariates
00:34:38,932 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:34:38,933 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 2.032921665988397. input_tokens=2106, output_tokens=5
00:34:39,286 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:34:39,286 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 0.35269610899558757. input_tokens=32, output_tokens=5
00:34:40,113 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:34:40,114 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.2158922519884072. input_tokens=2105, output_tokens=45
00:34:40,567 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:34:40,567 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.6738620639953297. input_tokens=2106, output_tokens=52
00:34:42,139 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:34:42,140 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 1.5717637380002998. input_tokens=32, output_tokens=52
00:34:45,883 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:34:45,884 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:34:45,884 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 8.974209419990075. input_tokens=2107, output_tokens=282
00:34:45,885 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 8.982962241003406. input_tokens=2106, output_tokens=282
00:34:45,986 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:34:45,986 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:34:45,987 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 9.08298469800502. input_tokens=2106, output_tokens=283
00:34:45,987 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 9.075274934992194. input_tokens=1935, output_tokens=283
00:35:00,365 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:00,366 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 20.250941674006754. input_tokens=32, output_tokens=858
00:35:02,238 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:02,239 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 25.333066920997226. input_tokens=2108, output_tokens=1426
00:35:02,921 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:02,922 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 26.014012494997587. input_tokens=2106, output_tokens=1060
00:35:06,422 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:06,423 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 29.526926608989015. input_tokens=2106, output_tokens=1370
00:35:11,477 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:11,478 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 25.588738353995723. input_tokens=32, output_tokens=1302
00:35:14,56 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:14,57 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 28.065501799996127. input_tokens=32, output_tokens=1424
00:35:16,210 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:16,211 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 30.222444177998113. input_tokens=32, output_tokens=1400
00:35:24,126 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:24,127 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 38.24133459299628. input_tokens=32, output_tokens=1793
00:35:24,715 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:24,716 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 22.475427709010546. input_tokens=32, output_tokens=1426
00:35:25,388 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:25,389 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 22.46573654099484. input_tokens=32, output_tokens=1060
00:35:31,249 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:31,250 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 24.825723030997324. input_tokens=32, output_tokens=1370
00:35:31,257 datashaper.workflow.workflow INFO executing verb window
00:35:31,261 datashaper.workflow.workflow INFO executing verb genid
00:35:31,264 datashaper.workflow.workflow INFO executing verb convert
00:35:31,267 datashaper.workflow.workflow INFO executing verb rename
00:35:31,271 datashaper.workflow.workflow INFO executing verb select
00:35:31,272 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_covariates.parquet
00:35:31,369 graphrag.index.run INFO Running workflow: create_summarized_entities...
00:35:31,369 graphrag.index.run INFO dependencies for create_summarized_entities: ['create_base_extracted_entities']
00:35:31,370 graphrag.index.run INFO read table from storage: create_base_extracted_entities.parquet
00:35:31,379 datashaper.workflow.workflow INFO executing verb summarize_descriptions
00:35:33,480 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:33,480 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.0738944049953716. input_tokens=404, output_tokens=92
00:35:33,894 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:33,895 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.4813104509958066. input_tokens=436, output_tokens=147
00:35:33,921 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:33,921 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.5099012479913654. input_tokens=398, output_tokens=138
00:35:34,158 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:34,159 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.7574994000024162. input_tokens=487, output_tokens=144
00:35:35,68 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:35,69 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.6273455770133296. input_tokens=460, output_tokens=227
00:35:35,223 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:35,223 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.808391136000864. input_tokens=433, output_tokens=207
00:35:35,351 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:35,352 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.9528111630061176. input_tokens=616, output_tokens=234
00:35:35,377 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:35,377 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.9431761690066196. input_tokens=392, output_tokens=209
00:35:35,565 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:35,566 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.155821489999653. input_tokens=590, output_tokens=257
00:35:35,750 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:35,750 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.345620792999398. input_tokens=612, output_tokens=265
00:35:35,854 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:35,855 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.423966039001243. input_tokens=421, output_tokens=256
00:35:36,737 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:36,738 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 5.312269697009469. input_tokens=430, output_tokens=227
00:35:36,764 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:36,764 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 5.361457460006932. input_tokens=461, output_tokens=319
00:35:36,947 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:36,947 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 5.526767514005769. input_tokens=415, output_tokens=295
00:35:37,193 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:37,194 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.7131079839891754. input_tokens=434, output_tokens=249
00:35:37,611 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:37,612 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 6.203470387990819. input_tokens=599, output_tokens=387
00:35:37,792 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:37,793 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.4407153929932974. input_tokens=637, output_tokens=173
00:35:37,934 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:37,934 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.012646335002501. input_tokens=465, output_tokens=263
00:35:38,141 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:38,142 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.391569024999626. input_tokens=529, output_tokens=163
00:35:38,274 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:38,274 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 6.846971471997676. input_tokens=413, output_tokens=369
00:35:38,376 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:38,376 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 6.93805004900787. input_tokens=411, output_tokens=446
00:35:38,688 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:38,689 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 7.256322225002805. input_tokens=425, output_tokens=480
00:35:38,790 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:38,791 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 7.354512805992272. input_tokens=416, output_tokens=292
00:35:39,154 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:39,155 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.2996020060090814. input_tokens=467, output_tokens=195
00:35:39,310 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:39,310 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 5.151536584991845. input_tokens=429, output_tokens=344
00:35:39,546 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:39,546 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:39,547 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.599317863001488. input_tokens=400, output_tokens=133
00:35:39,547 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 8.12512557899754. input_tokens=421, output_tokens=466
00:35:39,710 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:39,711 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 8.291888483989169. input_tokens=416, output_tokens=457
00:35:39,736 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:39,737 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.0475808769988362. input_tokens=424, output_tokens=69
00:35:39,887 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:39,888 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.0945483520044945. input_tokens=396, output_tokens=111
00:35:39,914 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:39,914 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:39,915 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 8.497702818000107. input_tokens=474, output_tokens=446
00:35:39,915 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.537471949995961. input_tokens=442, output_tokens=255
00:35:40,155 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:40,156 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.961666350995074. input_tokens=436, output_tokens=163
00:35:40,258 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:40,259 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.5203819870075677. input_tokens=423, output_tokens=202
00:35:40,311 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:40,312 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 8.887870528007625. input_tokens=435, output_tokens=391
00:35:40,337 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:40,338 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.771701399004087. input_tokens=557, output_tokens=261
00:35:40,390 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:40,390 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 8.961329112004023. input_tokens=449, output_tokens=526
00:35:40,543 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:40,544 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.4016314210020937. input_tokens=545, output_tokens=137
00:35:40,646 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:40,646 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.7585780120134586. input_tokens=430, output_tokens=50
00:35:40,849 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:40,849 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.932167869003024. input_tokens=425, output_tokens=72
00:35:40,874 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:40,875 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.110391107999021. input_tokens=431, output_tokens=225
00:35:40,925 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:40,926 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.3135916120081674. input_tokens=443, output_tokens=176
00:35:41,54 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:41,55 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.678140682997764. input_tokens=395, output_tokens=159
00:35:41,183 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:41,184 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 9.743743353013997. input_tokens=461, output_tokens=506
00:35:41,361 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:41,362 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.0876425030000973. input_tokens=399, output_tokens=123
00:35:41,489 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:41,490 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.6986888959945645. input_tokens=413, output_tokens=183
00:35:41,717 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:41,718 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 7.822929109999677. input_tokens=462, output_tokens=479
00:35:41,768 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:41,769 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.457965586989303. input_tokens=469, output_tokens=180
00:35:41,769 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:41,769 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.032345546002034. input_tokens=420, output_tokens=160
00:35:41,892 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:41,893 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.1818720100127393. input_tokens=438, output_tokens=181
00:35:41,990 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:41,991 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.056569988009869. input_tokens=429, output_tokens=295
00:35:42,307 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:42,308 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.7587272889941232. input_tokens=465, output_tokens=197
00:35:42,356 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:42,357 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.809414054994704. input_tokens=438, output_tokens=191
00:35:42,816 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:42,817 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.9012733779964037. input_tokens=418, output_tokens=232
00:35:43,177 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:43,178 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.023150167995482. input_tokens=454, output_tokens=291
00:35:43,802 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:43,803 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 8.579127847013297. input_tokens=418, output_tokens=592
00:35:43,874 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:43,875 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 8.805375976997311. input_tokens=411, output_tokens=465
00:35:45,446 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:35:45,447 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 5.291435808001552. input_tokens=446, output_tokens=417
00:35:45,459 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_summarized_entities.parquet
00:35:45,549 graphrag.index.run INFO Running workflow: join_text_units_to_covariate_ids...
00:35:45,549 graphrag.index.run INFO dependencies for join_text_units_to_covariate_ids: ['create_final_covariates']
00:35:45,549 graphrag.index.run INFO read table from storage: create_final_covariates.parquet
00:35:45,560 datashaper.workflow.workflow INFO executing verb select
00:35:45,564 datashaper.workflow.workflow INFO executing verb aggregate_override
00:35:45,566 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_covariate_ids.parquet
00:35:45,651 graphrag.index.run INFO Running workflow: create_base_entity_graph...
00:35:45,652 graphrag.index.run INFO dependencies for create_base_entity_graph: ['create_summarized_entities']
00:35:45,652 graphrag.index.run INFO read table from storage: create_summarized_entities.parquet
00:35:45,662 datashaper.workflow.workflow INFO executing verb cluster_graph
00:35:45,701 datashaper.workflow.workflow INFO executing verb select
00:35:45,702 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_entity_graph.parquet
00:35:45,788 graphrag.index.run INFO Running workflow: create_final_entities...
00:35:45,789 graphrag.index.run INFO dependencies for create_final_entities: ['create_base_entity_graph']
00:35:45,789 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
00:35:45,801 datashaper.workflow.workflow INFO executing verb unpack_graph
00:35:45,817 datashaper.workflow.workflow INFO executing verb rename
00:35:45,823 datashaper.workflow.workflow INFO executing verb select
00:35:45,828 datashaper.workflow.workflow INFO executing verb dedupe
00:35:45,834 datashaper.workflow.workflow INFO executing verb rename
00:35:45,839 datashaper.workflow.workflow INFO executing verb filter
00:35:45,848 datashaper.workflow.workflow INFO executing verb text_split
00:35:45,855 datashaper.workflow.workflow INFO executing verb drop
00:35:45,861 datashaper.workflow.workflow INFO executing verb merge
00:35:45,889 datashaper.workflow.workflow INFO executing verb text_embed
00:35:45,889 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=http://192.168.0.245:6008/v1
00:35:45,901 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for m3e-large: TPM=0, RPM=0
00:35:45,901 graphrag.index.llm.load_llm INFO create concurrency limiter for m3e-large: 25
00:35:45,910 graphrag.index.verbs.text.embed.strategies.openai INFO embedding 290 inputs via 290 snippets using 19 batches. max_batch_size=16, max_tokens=8191
00:35:46,184 httpx INFO HTTP Request: POST http://192.168.0.245:6008/v1/embeddings "HTTP/1.1 200 OK"
00:35:46,359 httpx INFO HTTP Request: POST http://192.168.0.245:6008/v1/embeddings "HTTP/1.1 200 OK"
00:35:46,543 httpx INFO HTTP Request: POST http://192.168.0.245:6008/v1/embeddings "HTTP/1.1 200 OK"
00:35:46,726 httpx INFO HTTP Request: POST http://192.168.0.245:6008/v1/embeddings "HTTP/1.1 200 OK"
00:35:46,894 httpx INFO HTTP Request: POST http://192.168.0.245:6008/v1/embeddings "HTTP/1.1 200 OK"
00:35:47,85 httpx INFO HTTP Request: POST http://192.168.0.245:6008/v1/embeddings "HTTP/1.1 200 OK"
00:35:47,267 httpx INFO HTTP Request: POST http://192.168.0.245:6008/v1/embeddings "HTTP/1.1 200 OK"
00:35:47,659 httpx INFO HTTP Request: POST http://192.168.0.245:6008/v1/embeddings "HTTP/1.1 200 OK"
00:35:47,921 httpx INFO HTTP Request: POST http://192.168.0.245:6008/v1/embeddings "HTTP/1.1 200 OK"
00:35:48,124 httpx INFO HTTP Request: POST http://192.168.0.245:6008/v1/embeddings "HTTP/1.1 200 OK"
00:35:48,328 httpx INFO HTTP Request: POST http://192.168.0.245:6008/v1/embeddings "HTTP/1.1 200 OK"
00:35:48,504 httpx INFO HTTP Request: POST http://192.168.0.245:6008/v1/embeddings "HTTP/1.1 200 OK"
00:35:48,677 httpx INFO HTTP Request: POST http://192.168.0.245:6008/v1/embeddings "HTTP/1.1 200 OK"
00:35:48,857 httpx INFO HTTP Request: POST http://192.168.0.245:6008/v1/embeddings "HTTP/1.1 200 OK"
00:35:49,39 httpx INFO HTTP Request: POST http://192.168.0.245:6008/v1/embeddings "HTTP/1.1 200 OK"
00:35:49,221 httpx INFO HTTP Request: POST http://192.168.0.245:6008/v1/embeddings "HTTP/1.1 200 OK"
00:35:49,389 httpx INFO HTTP Request: POST http://192.168.0.245:6008/v1/embeddings "HTTP/1.1 200 OK"
00:35:49,575 httpx INFO HTTP Request: POST http://192.168.0.245:6008/v1/embeddings "HTTP/1.1 200 OK"
00:35:49,595 httpx INFO HTTP Request: POST http://192.168.0.245:6008/v1/embeddings "HTTP/1.1 200 OK"
00:35:49,607 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 3.68250314501347. input_tokens=32, output_tokens=0
00:35:49,688 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 3.7765672840032494. input_tokens=817, output_tokens=0
00:35:49,755 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 3.8303113720030524. input_tokens=912, output_tokens=0
00:35:49,818 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 3.8986369509948418. input_tokens=533, output_tokens=0
00:35:49,882 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 3.969246930006193. input_tokens=2632, output_tokens=0
00:35:49,945 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 4.022269487002632. input_tokens=735, output_tokens=0
00:35:50,9 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 4.090174755998305. input_tokens=1041, output_tokens=0
00:35:50,72 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 4.15305191600055. input_tokens=843, output_tokens=0
00:35:50,137 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 4.21491767000407. input_tokens=792, output_tokens=0
00:35:50,201 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 4.277415409000241. input_tokens=529, output_tokens=0
00:35:50,264 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 4.3434354519995395. input_tokens=1112, output_tokens=0
00:35:50,327 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 4.406001091003418. input_tokens=806, output_tokens=0
00:35:50,390 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 4.475501438995707. input_tokens=5832, output_tokens=0
00:35:50,453 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 4.53750406501058. input_tokens=2905, output_tokens=0
00:35:50,515 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 4.599349716008874. input_tokens=1636, output_tokens=0
00:35:50,579 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 4.66198904698831. input_tokens=1589, output_tokens=0
00:35:50,648 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 4.730999692998012. input_tokens=854, output_tokens=0
00:35:50,712 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 4.7937439210072625. input_tokens=771, output_tokens=0
00:35:50,785 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 4.8636562780011445. input_tokens=726, output_tokens=0
00:35:50,807 datashaper.workflow.workflow INFO executing verb drop
00:35:50,813 datashaper.workflow.workflow INFO executing verb filter
00:35:50,817 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_entities.parquet
00:35:50,942 graphrag.index.run INFO Running workflow: create_final_nodes...
00:35:50,942 graphrag.index.run INFO dependencies for create_final_nodes: ['create_base_entity_graph']
00:35:50,943 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
00:35:50,958 datashaper.workflow.workflow INFO executing verb layout_graph
00:35:51,6 datashaper.workflow.workflow INFO executing verb unpack_graph
00:35:51,26 datashaper.workflow.workflow INFO executing verb unpack_graph
00:35:51,45 datashaper.workflow.workflow INFO executing verb filter
00:35:51,56 datashaper.workflow.workflow INFO executing verb drop
00:35:51,63 datashaper.workflow.workflow INFO executing verb select
00:35:51,70 datashaper.workflow.workflow INFO executing verb rename
00:35:51,78 datashaper.workflow.workflow INFO executing verb convert
00:35:51,86 datashaper.workflow.workflow INFO executing verb join
00:35:51,96 datashaper.workflow.workflow INFO executing verb rename
00:35:51,98 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_nodes.parquet
00:35:51,196 graphrag.index.run INFO Running workflow: create_final_communities...
00:35:51,197 graphrag.index.run INFO dependencies for create_final_communities: ['create_base_entity_graph']
00:35:51,197 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
00:35:51,214 datashaper.workflow.workflow INFO executing verb unpack_graph
00:35:51,234 datashaper.workflow.workflow INFO executing verb unpack_graph
00:35:51,253 datashaper.workflow.workflow INFO executing verb aggregate_override
00:35:51,263 datashaper.workflow.workflow INFO executing verb join
00:35:51,274 datashaper.workflow.workflow INFO executing verb join
00:35:51,285 datashaper.workflow.workflow INFO executing verb concat
00:35:51,294 datashaper.workflow.workflow INFO executing verb filter
00:35:51,313 datashaper.workflow.workflow INFO executing verb aggregate_override
00:35:51,326 datashaper.workflow.workflow INFO executing verb join
00:35:51,337 datashaper.workflow.workflow INFO executing verb filter
00:35:51,349 datashaper.workflow.workflow INFO executing verb fill
00:35:51,359 datashaper.workflow.workflow INFO executing verb merge
00:35:51,370 datashaper.workflow.workflow INFO executing verb copy
00:35:51,380 datashaper.workflow.workflow INFO executing verb select
00:35:51,381 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_communities.parquet
00:35:51,494 graphrag.index.run INFO Running workflow: join_text_units_to_entity_ids...
00:35:51,494 graphrag.index.run INFO dependencies for join_text_units_to_entity_ids: ['create_final_entities']
00:35:51,494 graphrag.index.run INFO read table from storage: create_final_entities.parquet
00:35:51,524 datashaper.workflow.workflow INFO executing verb select
00:35:51,533 datashaper.workflow.workflow INFO executing verb unroll
00:35:51,543 datashaper.workflow.workflow INFO executing verb aggregate_override
00:35:51,545 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_entity_ids.parquet
00:35:51,647 graphrag.index.run INFO Running workflow: create_final_relationships...
00:35:51,652 graphrag.index.run INFO dependencies for create_final_relationships: ['create_final_nodes', 'create_base_entity_graph']
00:35:51,652 graphrag.index.run INFO read table from storage: create_final_nodes.parquet
00:35:51,656 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
00:35:51,678 datashaper.workflow.workflow INFO executing verb unpack_graph
00:35:51,699 datashaper.workflow.workflow INFO executing verb filter
00:35:51,714 datashaper.workflow.workflow INFO executing verb rename
00:35:51,726 datashaper.workflow.workflow INFO executing verb filter
00:35:51,739 datashaper.workflow.workflow INFO executing verb drop
00:35:51,750 datashaper.workflow.workflow INFO executing verb compute_edge_combined_degree
00:35:51,763 datashaper.workflow.workflow INFO executing verb convert
00:35:51,774 datashaper.workflow.workflow INFO executing verb convert
00:35:51,775 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_relationships.parquet
00:35:51,879 graphrag.index.run INFO Running workflow: join_text_units_to_relationship_ids...
00:35:51,879 graphrag.index.run INFO dependencies for join_text_units_to_relationship_ids: ['create_final_relationships']
00:35:51,879 graphrag.index.run INFO read table from storage: create_final_relationships.parquet
00:35:51,904 datashaper.workflow.workflow INFO executing verb select
00:35:51,915 datashaper.workflow.workflow INFO executing verb unroll
00:35:51,927 datashaper.workflow.workflow INFO executing verb aggregate_override
00:35:51,940 datashaper.workflow.workflow INFO executing verb select
00:35:51,942 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_relationship_ids.parquet
00:35:52,45 graphrag.index.run INFO Running workflow: create_final_community_reports...
00:35:52,46 graphrag.index.run INFO dependencies for create_final_community_reports: ['create_final_nodes', 'create_final_relationships', 'create_final_covariates']
00:35:52,46 graphrag.index.run INFO read table from storage: create_final_nodes.parquet
00:35:52,49 graphrag.index.run INFO read table from storage: create_final_relationships.parquet
00:35:52,51 graphrag.index.run INFO read table from storage: create_final_covariates.parquet
00:35:52,75 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
00:35:52,90 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
00:35:52,104 datashaper.workflow.workflow INFO executing verb prepare_community_reports_claims
00:35:52,116 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
00:35:52,131 datashaper.workflow.workflow INFO executing verb prepare_community_reports
00:35:52,131 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=1 => 290
00:35:52,145 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 290
00:35:52,176 datashaper.workflow.workflow INFO executing verb create_community_reports
00:37:15,601 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:37:15,602 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': '', 'rating': 8.0, 'rating_explanation': '', 'findings': [{'summary': '', 'explanation': '[Data: 7980783716510311010410248189969088474939464042434445103110104102481]'}]}
00:37:15,602 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 83.42262551000749. input_tokens=5346, output_tokens=1320
00:42:37,27 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:42:37,27 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:42:37,28 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
00:42:37,28 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title"   	:	""	,      	"summary"	:	""	,      	"rating"	:	8.0	,      	"rating_explanation"	:	""	,      	"findings"	:	[              	{                  	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities36671646172]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities35363460]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities4837]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities6660]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities4836671646172]"	,          	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities594937]"	,          	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities600]"	,          	"summary"	:	""	,                  	"explanation"	:	"[Data: Relationships594937353634600]"	,          	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities600]"	,          	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities4836671646172594937353634600]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities4836671646172594937353634600]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities4836671646172594937353634600]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities4836671646172594937353634600]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities4836671646172594937353634600]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities4836671646172594937353634600]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities4836671646172594937353634600]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities4836671646172594937353634600]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities4836671646172594937353634600]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities4836671646172594937353634600]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities4836671646172594937353634600]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities4836671646172594937353634600]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities4836671646172594937353634600]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities4836671646172594937353634600]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities4836671646172594937353634600]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities4836671646172594937353634600]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities4836671646172594937353634600]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities4836671646172594937353634600]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities4836671646172594937353634600]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities4836671646172594937353634600]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities4836671646172594937353634600]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities4836671646172594937353634600]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities4836671646172594937353634600]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities4836671646172594937353634600]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities4836671646172594937353634600]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities4836671646172594937353634600]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities4836671646172594937353634600]"	,      	"summary"	:	""	,                  	"explanation"	:	"
00:42:37,30 graphrag.llm.openai.utils INFO success load json in step 3{'title': '', 'summary': '', 'rating': 8.0, 'rating_explanation': '', 'findings': [{'summary': '', 'explanation': ''}]}
00:42:37,30 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 404.8445553240017. input_tokens=4738, output_tokens=918
00:42:37,31 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
00:42:37,31 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title"  	:	""	,      	"summary"	:	""	,      	"rating"	:	8.5	,      	"rating_explanation"	:	""	,      	"findings"	:	[              	{                  	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities747072697576727576729582858397]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities748990919293959682858397]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities8996]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities95]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities749596]"	,          	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities747072697576729582858397]"	,      	"findings"	:	[              	{                  	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities747072697576729582858397]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities748990919293959682858397]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities8996]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities95]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities749596]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities747072697576729582858397]"	,          	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities749596]"	,      	"findings"	:	[              	{                  	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities747072697576729582858397]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities748990919293959682858397]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities8996]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities95]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities747072697576729582858397]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities749596]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities749596]"	,          	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities749596]"	,      	"findings"	:	[              	{                  	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities747072697576729582858397]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities748990919293959682858397]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities8996]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities95]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities747072697576729582858397]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities749596]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities749596]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities749596]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities749596]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities749596]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities749596]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities749596]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities749596]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities749596]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities749596]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities749596]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities749596]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities749596]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities749596]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities749596]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities749596]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities749596]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities749596]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities749596]"	,              	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities749596]"	,              	"summary"	:	""	,                  	"explanation"	:	"
00:42:37,33 graphrag.llm.openai.utils INFO success load json in step 3{'title': '', 'summary': '', 'rating': 8.5, 'rating_explanation': '', 'findings': [{'summary': '', 'explanation': '[Data: Entities747072697576729582858397]', 'findings': [{'summary': '', 'explanation': '[Data: Entities749596]', 'findings': [{'summary': '', 'explanation': '[Data: Entities749596]', 'findings': [{'summary': '', 'explanation': ''}]}]}]}]}
00:42:37,33 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 404.85024011800124. input_tokens=5182, output_tokens=1764
00:43:06,687 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:43:06,688 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
00:43:06,688 graphrag.llm.openai.utils INFO Error: JSONDecodeError{     "title"  	:	""	,     	"summary"	:	""	,     	"rating"	:	8.0	,     	"rating_explanation"	:	""	,     	"findings"	:	[            	{            		"summary"	:	""	,            		"explanation"	:	"9590109102103104108110"	,            		"data"	:	"90109110"	,            		"additional_data"	:	"+more"	,            		"impact"	:	""	,            		"recommendation"	:	""	,            		"conclusion"	:	""	,            		"implications"	:	""	,            		"future_research"	:	""	,            		"additional_notes"	:	""	,            		"references"	:	"9590109102103104108110"	,            		"additional_data_notes"	:	"9590109102103104108110"	,            		"additional_data_notes_2"	:	"9590109102103104108110ID9590109102103ID+more"	,            		"additional_data_notes_3"	:	"9590109102103104108110"	,            		"additional_data_notes_4"	:	"9590109102103104108110ID9590109102103104108110"	,            		"additional_data_notes_5"	:	"9590109102103104108110"	,            		"additional_data_notes_6"	:	"9590109102103104108110ID9590109102103104108110"	,            		"additional_data_notes_7"	:	"9590109102103104108110"	,            		"additional_data_notes_8"	:	"9590109102103104108110ID9590109102103104108110"	,            		"additional_data_notes_9"	:	"9590109102103104108110"	,            		"additional_data_notes_10"	:	"9590109102103104108110ID9590109102103104108110"	,            		"additional_data_notes_11"	:	"9590109102103104108110"	,            		"additional_data_notes_12"	:	"9590109102103104108110ID9590109102103104108110"	,            		"additional_data_notes_13"	:	"9590109102103104108110"	,            		"additional_data_notes_14"	:	"9590109102103104108110ID9590109102103104108110"	,            		"additional_data_notes_15"	:	"9590109102103104108110"	,            		"additional_data_notes_16"	:	"9590109102103104108110ID9590109102103104108110"	,            		"additional_data_notes_17"	:	"9590109102103104108110"	,            		"additional_data_notes_18"	:	"9590109102103104108110ID9590109102103104108110"	,            		"additional_data_notes_19"	:	"9590109102103104108110"	,            		"additional_data_notes_20"	:	"9590109102103104108110ID9590109102103104108110"	,            		"additional_data_notes_21"	:	"9590109102103104108110"	,            		"additional_data_notes_22"	:	"9590109102103104108110ID9590109102103104108110"	,            		"additional_data_notes_23"	:	"9590109102103104108110"	,            		"additional_data_notes_24"	:	"9590109102103104108110ID9590109102103104108110"	,            		"additional_data_notes_25"	:	"9590109102103104108110"	,            		"additional_data_notes_26"	:	"9590109102103104108110ID9590109102103104108110"	,            		"additional_data_notes_27"	:	"9590109102103104108110"	,            		"additional_data_notes_28"	:	"9590109102103104108110ID9590109102103104108110"	,            		"additional_data_notes_29"	:	"9590109102103104108110"	,            		"additional_data_notes_30"	:	"9590109102103104108110ID9590109102103104108110"	,            		"additional_data_notes_31"	:	"9590109102103104108110"	,            		"additional_data_notes_32"	:	"9590109102103104108110ID9590109102103104108110"	,            		"additional_data_notes_33"	:	"9590109102103104108110"	,            		"additional_data_notes_34"	:	"9590109102103104108110ID9590109102103104108110"	,            		"additional_data_notes_35"	:	"9590109102103104108110"	,            		"additional_data_notes_36"	:	"9590109102103104108110ID9590109102103104108110"	,            		"additional_data_notes_37"	:	"9590109102103104108110"	,            		"additional_data_notes_38"	:	"9590109102103104108110ID9590109102103104108110"	,            		"additional_data_notes_39"	:	"9590109102103104108110"	,            		"additional_data_notes_40"	:	"9590109102103104108110ID9590109102103104108110"	,            		"additional_data_notes_41"	:	"9590109102103104108110"	,            		"additional_data_notes_42"	:	"9590109102103104108110ID9590109102103104108110"	,            		"additional_data_notes_43"	:	"9590109102103104108110"	,            		"additional_data_notes_44"	:	"9590109102103104108110ID9590109102103104108110"	,            		"additional_data_notes_45"	:	"9590109102103104108110"	,            		"additional_data_notes_46"	:	"9590109102103104108110ID9590109102103104108110"	,            		"additional_data_notes_47"	:	"9590109102103104108110"	,            		"additional_data_notes_48"	:	"9590109102103104108110ID9590109102103104108110"	,            		"additional_data_notes_49"	:	"9590109102103104108110"	,            		"additional_data_notes_50"	:	"9590109102103104108110ID9590109102103104108110"	,            		"additional_data_notes_51"	:	"9590109102103104108110"	,            		"additional_data_notes_52"	:	"9590109102103104108110ID9590109102103104108110"	,            		"additional_data_notes_53"	:	"9590109102103104108110"	,            		"additional_data_notes_54"	:	"9590109102103104108110ID9590109102103104108110"	,            		"additional_data_notes_55"	:	"9590109102103104108110"	,            		"additional_data_notes_56"	:	"9590109102103104108110ID9590109102103104108110"	,            		"additional_data_notes_57"	:	"959010910210310410811
00:43:06,689 graphrag.llm.openai.utils INFO success load json in step 3{'title': '', 'summary': '', 'rating': 8.0, 'rating_explanation': '', 'findings': [{'summary': '', 'explanation': '9590109102103104108110', 'data': '90109110', 'additional_data': '+more', 'impact': '', 'recommendation': '', 'conclusion': '', 'implications': '', 'future_research': '', 'additional_notes': '', 'references': '9590109102103104108110', 'additional_data_notes': '9590109102103104108110', 'additional_data_notes_2': '9590109102103104108110ID9590109102103ID+more', 'additional_data_notes_3': '9590109102103104108110', 'additional_data_notes_4': '9590109102103104108110ID9590109102103104108110', 'additional_data_notes_5': '9590109102103104108110', 'additional_data_notes_6': '9590109102103104108110ID9590109102103104108110', 'additional_data_notes_7': '9590109102103104108110', 'additional_data_notes_8': '9590109102103104108110ID9590109102103104108110', 'additional_data_notes_9': '9590109102103104108110', 'additional_data_notes_10': '9590109102103104108110ID9590109102103104108110', 'additional_data_notes_11': '9590109102103104108110', 'additional_data_notes_12': '9590109102103104108110ID9590109102103104108110', 'additional_data_notes_13': '9590109102103104108110', 'additional_data_notes_14': '9590109102103104108110ID9590109102103104108110', 'additional_data_notes_15': '9590109102103104108110', 'additional_data_notes_16': '9590109102103104108110ID9590109102103104108110', 'additional_data_notes_17': '9590109102103104108110', 'additional_data_notes_18': '9590109102103104108110ID9590109102103104108110', 'additional_data_notes_19': '9590109102103104108110', 'additional_data_notes_20': '9590109102103104108110ID9590109102103104108110', 'additional_data_notes_21': '9590109102103104108110', 'additional_data_notes_22': '9590109102103104108110ID9590109102103104108110', 'additional_data_notes_23': '9590109102103104108110', 'additional_data_notes_24': '9590109102103104108110ID9590109102103104108110', 'additional_data_notes_25': '9590109102103104108110', 'additional_data_notes_26': '9590109102103104108110ID9590109102103104108110', 'additional_data_notes_27': '9590109102103104108110', 'additional_data_notes_28': '9590109102103104108110ID9590109102103104108110', 'additional_data_notes_29': '9590109102103104108110', 'additional_data_notes_30': '9590109102103104108110ID9590109102103104108110', 'additional_data_notes_31': '9590109102103104108110', 'additional_data_notes_32': '9590109102103104108110ID9590109102103104108110', 'additional_data_notes_33': '9590109102103104108110', 'additional_data_notes_34': '9590109102103104108110ID9590109102103104108110', 'additional_data_notes_35': '9590109102103104108110', 'additional_data_notes_36': '9590109102103104108110ID9590109102103104108110', 'additional_data_notes_37': '9590109102103104108110', 'additional_data_notes_38': '9590109102103104108110ID9590109102103104108110', 'additional_data_notes_39': '9590109102103104108110', 'additional_data_notes_40': '9590109102103104108110ID9590109102103104108110', 'additional_data_notes_41': '9590109102103104108110', 'additional_data_notes_42': '9590109102103104108110ID9590109102103104108110', 'additional_data_notes_43': '9590109102103104108110', 'additional_data_notes_44': '9590109102103104108110ID9590109102103104108110', 'additional_data_notes_45': '9590109102103104108110', 'additional_data_notes_46': '9590109102103104108110ID9590109102103104108110', 'additional_data_notes_47': '9590109102103104108110', 'additional_data_notes_48': '9590109102103104108110ID9590109102103104108110', 'additional_data_notes_49': '9590109102103104108110', 'additional_data_notes_50': '9590109102103104108110ID9590109102103104108110', 'additional_data_notes_51': '9590109102103104108110', 'additional_data_notes_52': '9590109102103104108110ID9590109102103104108110', 'additional_data_notes_53': '9590109102103104108110', 'additional_data_notes_54': '9590109102103104108110ID9590109102103104108110', 'additional_data_notes_55': '9590109102103104108110', 'additional_data_notes_56': '9590109102103104108110ID9590109102103104108110', 'additional_data_notes_57': '959010910210310410811'}]}
00:43:06,691 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 351.07231391199457. input_tokens=4425, output_tokens=9602
00:44:46,511 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:44:46,512 graphrag.llm.openai.utils INFO success load json in step 1{'title': '', 'summary': '', 'rating': 7.5, 'rating_explanation': '', 'findings': [{'summary': '', 'explanation': '[Data: Entities98140139141142Relationships47119115116120124571181171225612512358]'}]}
00:44:46,512 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 99.78534334099095. input_tokens=5229, output_tokens=1593
00:50:51,993 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:50:51,993 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:50:51,994 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
00:50:51,994 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title"  	: 	"" 	,      	"summary" 	: 	"" 	,      	"rating" 	: 	8.0 	,      	"rating_explanation" 	: 	"" 	,      	"findings" 	: 	[              	{                  	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Relationship (100, 179)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Relationship (137, 179)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179), Entity (195)]" 	,              	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,          	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179), Entity (195)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179), Entity (195)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179), Entity (195)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179), Entity (195)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179), Entity (195)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179), Entity (195)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179), Entity (195)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179), Entity (195)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179), Entity (195)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179), Entity (195)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179), Entity (195)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179), Entity (195)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"[Data: Entity (179)]" 	,      	"summary" 	: 	"" 	,                  	"explanation" 	: 	"
00:50:51,996 graphrag.llm.openai.utils INFO success load json in step 3{'title': '', 'summary': '', 'rating': 8.0, 'rating_explanation': '', 'findings': [{'summary': '', 'explanation': ''}]}
00:50:51,996 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 465.27267623700027. input_tokens=3788, output_tokens=647
00:50:51,997 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
00:50:51,997 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title"   	:	""	,      	"summary"	:	""	,      	"rating"	:	7.5	,      	"rating_explanation"	:	""	,      	"findings"	:	[              	{                  	"summary"	:	""	,                  	"explanation"	:	"X[Data: 733250145170171161173170171161173313210030126145170171161173313210030126]"	,              		"summary"	:	""	,                  	"explanation"	:	"[Data: 616263301261451701711611733132100]"	,              		"summary"	:	""	,                  	"explanation"	:	"[Data: 100]"	,              		"summary"	:	"X"	,                  	"explanation"	:	"XX[Data: 3332313231]"	,              		"summary"	:	""	,                  	"explanation"	:	"[Data: 616263313231]"	,          	"summary"	:	""	,                  	"explanation"	:	"[Data: 733250145170171161173170171161173313210030126145170171161173313210030126]"	,          	"summary"	:	""	,                  	"explanation"	:	"XCTMRI[Data: 3332313231]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: 733250145170171161173170171161173313210030126145170171161173313210030126]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: 733250145170171161173170171161173313210030126145170171161173313210030126]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: 733250145170171161173170171161173313210030126145170171161173313210030126]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: 733250145170171161173170171161173313210030126145170171161173313210030126]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: 733250145170171161173170171161173313210030126145170171161173313210030126]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: 733250145170171161173170171161173313210030126145170171161173313210030126]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: 733250145170171161173170171161173313210030126145170171161173313210030126]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: 733250145170171161173170171161173313210030126145170171161173313210030126]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: 733250145170171161173170171161173313210030126145170171161173313210030126]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: 733250145170171161173170171161173313210030126145170171161173313210030126]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: 733250145170171161173170171161173313210030126145170171161173313210030126]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: 733250145170171161173170171161173313210030126145170171161173313210030126]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: 733250145170171161173170171161173313210030126145170171161173313210030126]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: 733250145170171161173170171161173313210030126145170171161173313210030126]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: 733250145170171161173170171161173313210030126145170171161173313210030126]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: 733250145170171161173170171161173313210030126145170171161173313210030126]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: 733250145170171161173170171161173313210030126145170171161173313210030126]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: 733250145170171161173170171161173313210030126145170171161173313210030126]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: 733250145170171161173170171161173313210030126145170171161173313210030126]"	,      	"summary"	:	""	,                  	"explanation"	:	"[Data: 733250145170171161173170171161173313210030126145170171161173313210030126]"	,      	"summary"	:	""	,                  	"explanation"	:	"
00:50:51,998 graphrag.llm.openai.utils INFO success load json in step 3{'title': '', 'summary': '', 'rating': 7.5, 'rating_explanation': '', 'findings': [{'summary': '', 'explanation': ''}]}
00:50:51,999 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 465.27788068899827. input_tokens=4596, output_tokens=859
00:52:59,42 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:52:59,43 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
00:52:59,43 graphrag.llm.openai.utils INFO Error: JSONDecodeError{     "title"  	:	""	,     	"summary"	:	""	,     	"rating"	:	8.5	,     	"rating_explanation"	:	""	,     	"findings"	:	[            	{            		"summary"	:	""	,            		"explanation"	:	"[Data: Entities150163176174Relationships99131130]"	,            		"additional_data"	:	""	,            		"supporting_data"	:	"13113099"	,            		"impact"	:	""	,            		"recommendation"	:	""	,            		"next_steps"	:	""	,            		"potential_implications"	:	""	,            		"additional_notes"	:	""	,            		"references"	:	"13113099"	,            		"conclusion"	:	""	,            		"impact_level"	:	""	,            		"risk_factors"	:	""	,            		"mitigation_strategies"	:	""	,            		"future_trends"	:	""	,            		"additional_recommendations"	:	""	,            		"additional_notes_2"	:	""	,            		"additional_notes_3"	:	""	,            		"additional_notes_4"	:	""	,            		"additional_notes_5"	:	""	,            		"additional_notes_6"	:	""	,            		"additional_notes_7"	:	""	,            		"additional_notes_8"	:	""	,            		"additional_notes_9"	:	""	,            		"additional_notes_10"	:	""	,            		"additional_notes_11"	:	""	,            		"additional_notes_12"	:	""	,            		"additional_notes_13"	:	""	,            		"additional_notes_14"	:	""	,            		"additional_notes_15"	:	""	,            		"additional_notes_16"	:	""	,            		"additional_notes_17"	:	""	,            		"additional_notes_18"	:	""	,            		"additional_notes_19"	:	""	,            		"additional_notes_20"	:	""	,            		"additional_notes_21"	:	""	,            		"additional_notes_22"	:	""	,            		"additional_notes_23"	:	""	,            		"additional_notes_24"	:	""	,            		"additional_notes_25"	:	""	,            		"additional_notes_26"	:	""	,            		"additional_notes_27"	:	""	,            		"additional_notes_28"	:	""	,            		"additional_notes_29"	:	""	,            		"additional_notes_30"	:	""	,            		"additional_notes_31"	:	""	,            		"additional_notes_32"	:	""	,            		"additional_notes_33"	:	""	,            		"additional_notes_34"	:	""	,            		"additional_notes_35"	:	""	,            		"additional_notes_36"	:	""	,            		"additional_notes_37"	:	""	,            		"additional_notes_38"	:	""	,            		"additional_notes_39"	:	""	,            		"additional_notes_40"	:	""	,            		"additional_notes_41"	:	""	,            		"additional_notes_42"	:	""	,            		"additional_notes_43"	:	""	,            		"additional_notes_44"	:	""	,            		"additional_notes_45"	:	""	,            		"additional_notes_46"	:	""	,            		"additional_notes_47"	:	""	,            		"additional_notes_48"	:	""	,            		"additional_notes_49"	:	""	,            		"additional_notes_50"	:	""	,            		"additional_notes_51"	:	""	,            		"additional_notes_52"	:	""	,            		"additional_notes_53"	:	""	,            		"additional_notes_54"	:	""	,            		"additional_notes_55"	:	""	,            		"additional_notes_56"	:	""	,            		"additional_notes_57"	:	""	,            		"additional_notes_58"	:	""	,            		"additional_notes_59"	:	""	,            		"additional_notes_60"	:	""	,            		"additional_notes_61"	:	""	,            		"additional_notes_62"	:	""	,            		"additional_notes_63"	:	""	,            		"additional_notes_64"	:	""	,            		"additional_notes_65"	:	""	,            		"additional_notes_66"	:	""	,            		"additional_notes_67"	:	""	,            		"additional_notes_68"	:	""	,            		"additional_notes_69"	:	""	,            		"additional_notes_70"	:	""	,            		"additional_notes_71"	:	""	,            		"additional_notes_72"	:	""	,            		"additional_notes_73"	:	""	,            		"additional_notes_74"	:	""	,            		"additional_notes_75"	:	""	,            		"additional_notes_76"	:	""	,            		"additional_notes_77"	:	""	,            		"additional_notes_78"	:	""	,            		"additional_notes_79"	:	""	,            		"additional_notes_80"	:	""	,            		"additional_notes_81"	:	""	,            		"additional_notes_82"	:	""	,            		"additional_notes_83"	:	""	,            		"additional_notes_84"	:	""	,            		"additional_notes_85"	:	""	,            		"additional_notes_86"	:	""	,            		"additional_notes_87"	:	""	,            		"additional_notes_88"	:	""	,            		"additional_notes_89"	:	""	,            		"additional_notes_90"	:	""	,            		"additional_notes_91"	:	""	,            		"additional_notes_92"	:	""	,            		"additional_notes_93"	:	""	,            		"additional_notes_94"	:	""	,            		"additional_notes_95"	:	""	,            		"additional_notes_96"	:	""	,            		"additional_notes_97"	:	""	,            		"additional_notes_98"	:	""	,            		"additional_notes_99"	:	""	,            		"additional_notes_100"	:	""	,            		"additional_notes_101"	:	""	,            		"additional_notes_102"	:	""	,            		"additional_notes_103"	:	"
00:52:59,45 graphrag.llm.openai.utils INFO success load json in step 3{'title': '', 'summary': '', 'rating': 8.5, 'rating_explanation': '', 'findings': [{'summary': '', 'explanation': '[Data: Entities150163176174Relationships99131130]', 'additional_data': '', 'supporting_data': '13113099', 'impact': '', 'recommendation': '', 'next_steps': '', 'potential_implications': '', 'additional_notes': '', 'references': '13113099', 'conclusion': '', 'impact_level': '', 'risk_factors': '', 'mitigation_strategies': '', 'future_trends': '', 'additional_recommendations': '', 'additional_notes_2': '', 'additional_notes_3': '', 'additional_notes_4': '', 'additional_notes_5': '', 'additional_notes_6': '', 'additional_notes_7': '', 'additional_notes_8': '', 'additional_notes_9': '', 'additional_notes_10': '', 'additional_notes_11': '', 'additional_notes_12': '', 'additional_notes_13': '', 'additional_notes_14': '', 'additional_notes_15': '', 'additional_notes_16': '', 'additional_notes_17': '', 'additional_notes_18': '', 'additional_notes_19': '', 'additional_notes_20': '', 'additional_notes_21': '', 'additional_notes_22': '', 'additional_notes_23': '', 'additional_notes_24': '', 'additional_notes_25': '', 'additional_notes_26': '', 'additional_notes_27': '', 'additional_notes_28': '', 'additional_notes_29': '', 'additional_notes_30': '', 'additional_notes_31': '', 'additional_notes_32': '', 'additional_notes_33': '', 'additional_notes_34': '', 'additional_notes_35': '', 'additional_notes_36': '', 'additional_notes_37': '', 'additional_notes_38': '', 'additional_notes_39': '', 'additional_notes_40': '', 'additional_notes_41': '', 'additional_notes_42': '', 'additional_notes_43': '', 'additional_notes_44': '', 'additional_notes_45': '', 'additional_notes_46': '', 'additional_notes_47': '', 'additional_notes_48': '', 'additional_notes_49': '', 'additional_notes_50': '', 'additional_notes_51': '', 'additional_notes_52': '', 'additional_notes_53': '', 'additional_notes_54': '', 'additional_notes_55': '', 'additional_notes_56': '', 'additional_notes_57': '', 'additional_notes_58': '', 'additional_notes_59': '', 'additional_notes_60': '', 'additional_notes_61': '', 'additional_notes_62': '', 'additional_notes_63': '', 'additional_notes_64': '', 'additional_notes_65': '', 'additional_notes_66': '', 'additional_notes_67': '', 'additional_notes_68': '', 'additional_notes_69': '', 'additional_notes_70': '', 'additional_notes_71': '', 'additional_notes_72': '', 'additional_notes_73': '', 'additional_notes_74': '', 'additional_notes_75': '', 'additional_notes_76': '', 'additional_notes_77': '', 'additional_notes_78': '', 'additional_notes_79': '', 'additional_notes_80': '', 'additional_notes_81': '', 'additional_notes_82': '', 'additional_notes_83': '', 'additional_notes_84': '', 'additional_notes_85': '', 'additional_notes_86': '', 'additional_notes_87': '', 'additional_notes_88': '', 'additional_notes_89': '', 'additional_notes_90': '', 'additional_notes_91': '', 'additional_notes_92': '', 'additional_notes_93': '', 'additional_notes_94': '', 'additional_notes_95': '', 'additional_notes_96': '', 'additional_notes_97': '', 'additional_notes_98': '', 'additional_notes_99': '', 'additional_notes_100': '', 'additional_notes_101': '', 'additional_notes_102': '', 'additional_notes_103': ''}]}
00:52:59,48 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 492.518539754994. input_tokens=4383, output_tokens=18295
00:59:45,994 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:59:45,995 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
00:59:45,995 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
00:59:45,995 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title"   	:	""	,      	"summary"	:	""	,      	"rating"	:	7.5	,      	"rating_explanation"	:	""	,      	"findings"	:	[              	{                  	"summary"	:	""	,                  	"explanation"	:	"[Data: Entities7111182]"	,              		"Data: Entities7111182"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,              		"Data: Relationships111"	:	""	,              		"Data: Relationships82"	:	""	,
00:59:45,997 graphrag.llm.openai.utils INFO success load json in step 3{'title': '', 'summary': '', 'rating': 7.5, 'rating_explanation': '', 'findings': [{'summary': '', 'explanation': '[Data: Entities7111182]', 'Data: Entities7111182': '', 'Data: Relationships82': '', 'Data: Relationships111': ''}]}
00:59:45,998 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 533.9838644819974. input_tokens=4638, output_tokens=913
00:59:45,998 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
00:59:45,998 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title"   	:	""	,      	"summary"	:	""	,      	"rating"	:	7.5	,      	"rating_explanation"	:	""	,      	"findings"	:	[              	{                  	"summary"	:	""	,                  	"explanation"	:	"13613544"	,              	"Data"	:	"Entities13613544"	,              	"Data"	:	"Relationships11611551"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,              	"Data"	:	"Relationships505253"	,
00:59:46,1 graphrag.llm.openai.utils INFO success load json in step 3{'title': '', 'summary': '', 'rating': 7.5, 'rating_explanation': '', 'findings': [{'summary': '', 'explanation': '13613544', 'Data': 'Relationships505253'}]}
00:59:46,1 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 533.9840211949922. input_tokens=4061, output_tokens=1137
01:00:13,1 httpx INFO HTTP Request: POST http://192.168.0.245:5008/v1/chat/completions "HTTP/1.1 200 OK"
01:00:13,2 graphrag.llm.openai.utils WARNING Warning: fail to decoding faulty json, attempting repair, attempt to clean up input strings and Markdown frameworks
01:00:13,2 graphrag.llm.openai.utils INFO Error: JSONDecodeError{      "title"   	:	""	,      	"summary"	:	""	,      	"rating"	:	8.0	,      	"rating_explanation"	:	""	,      	"findings"	:	[              	{                  	"summary"	:	""	,                  	"explanation"	:	"[Data: 688459948889909192939596101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105
01:00:13,3 graphrag.llm.openai.utils INFO success load json in step 3{'title': '', 'summary': '', 'rating': 8.0, 'rating_explanation': '', 'findings': [{'summary': '', 'explanation': '[Data: 688459948889909192939596101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105102103104110107105104103102101828586878889909192939596108106109107105'}]}
01:00:13,4 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 433.93982049799524. input_tokens=7957, output_tokens=5830
01:00:13,31 datashaper.workflow.workflow INFO executing verb window
01:00:13,44 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_community_reports.parquet
01:00:13,158 graphrag.index.run INFO Running workflow: create_final_text_units...
01:00:13,158 graphrag.index.run INFO dependencies for create_final_text_units: ['create_base_text_units', 'join_text_units_to_entity_ids', 'join_text_units_to_relationship_ids', 'join_text_units_to_covariate_ids']
01:00:13,158 graphrag.index.run INFO read table from storage: create_base_text_units.parquet
01:00:13,161 graphrag.index.run INFO read table from storage: join_text_units_to_entity_ids.parquet
01:00:13,163 graphrag.index.run INFO read table from storage: join_text_units_to_relationship_ids.parquet
01:00:13,164 graphrag.index.run INFO read table from storage: join_text_units_to_covariate_ids.parquet
01:00:13,192 datashaper.workflow.workflow INFO executing verb select
01:00:13,205 datashaper.workflow.workflow INFO executing verb rename
01:00:13,218 datashaper.workflow.workflow INFO executing verb join
01:00:13,234 datashaper.workflow.workflow INFO executing verb join
01:00:13,250 datashaper.workflow.workflow INFO executing verb join
01:00:13,266 datashaper.workflow.workflow INFO executing verb aggregate_override
01:00:13,281 datashaper.workflow.workflow INFO executing verb select
01:00:13,282 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_text_units.parquet
01:00:13,392 graphrag.index.run INFO Running workflow: create_base_documents...
01:00:13,392 graphrag.index.run INFO dependencies for create_base_documents: ['create_final_text_units']
01:00:13,392 graphrag.index.run INFO read table from storage: create_final_text_units.parquet
01:00:13,422 datashaper.workflow.workflow INFO executing verb unroll
01:00:13,437 datashaper.workflow.workflow INFO executing verb select
01:00:13,452 datashaper.workflow.workflow INFO executing verb rename
01:00:13,466 datashaper.workflow.workflow INFO executing verb join
01:00:13,483 datashaper.workflow.workflow INFO executing verb aggregate_override
01:00:13,499 datashaper.workflow.workflow INFO executing verb join
01:00:13,516 datashaper.workflow.workflow INFO executing verb rename
01:00:13,531 datashaper.workflow.workflow INFO executing verb convert
01:00:13,532 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_documents.parquet
01:00:13,647 graphrag.index.run INFO Running workflow: create_final_documents...
01:00:13,647 graphrag.index.run INFO dependencies for create_final_documents: ['create_base_documents']
01:00:13,647 graphrag.index.run INFO read table from storage: create_base_documents.parquet
01:00:13,678 datashaper.workflow.workflow INFO executing verb rename
01:00:13,680 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_documents.parquet
01:00:13,729 graphrag.index.cli INFO All workflows completed successfully.
